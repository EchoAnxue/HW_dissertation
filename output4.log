nohup: ignoring input
/root/miniconda3/lib/python3.12/site-packages/torch_geometric/graphgym/config.py:19: UserWarning: Could not define global config object. Please install 'yacs' via 'pip install yacs' in order to use GraphGym
  warnings.warn("Could not define global config object. Please install "
/root/miniconda3/lib/python3.12/site-packages/torch_geometric/graphgym/imports.py:14: UserWarning: Please install 'pytorch_lightning' via  'pip install pytorch_lightning' in order to use GraphGym
  warnings.warn("Please install 'pytorch_lightning' via  "
/root/miniconda3/lib/python3.12/site-packages/torch_geometric/sampler/neighbor_sampler.py:61: UserWarning: Using 'NeighborSampler' without a 'pyg-lib' installation is deprecated and will be removed soon. Please install 'pyg-lib' for accelerated neighborhood sampling
  warnings.warn(f"Using '{self.__class__.__name__}' without a "
========== Running baseline 1/3 ==========
Training GCN with 2 layers...
可训练参数: 133385_GCN
不可训练参数: 0
batch size: (901, 901)
✅ Epoch 0: New best model saved with val_loss = 1.0749
/root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
Epoch 0, accuracy: 0.6416
Epoch 0, Train Loss: 1.3219, Val Loss: 1.0749
batch size: (911, 911)
✅ Epoch 1: New best model saved with val_loss = 1.0542
Epoch 1, accuracy: 0.6840
batch size: (893, 893)
✅ Epoch 2: New best model saved with val_loss = 1.0361
Epoch 2, accuracy: 0.6730
Epoch 2, Train Loss: 0.1807, Val Loss: 1.0361
batch size: (904, 904)
✅ Epoch 3: New best model saved with val_loss = 1.0217
Epoch 3, accuracy: 0.6501
batch size: (894, 894)
✅ Epoch 4: New best model saved with val_loss = 1.0085
Epoch 4, accuracy: 0.6523
Epoch 4, Train Loss: 0.0875, Val Loss: 1.0085
batch size: (899, 899)
✅ Epoch 5: New best model saved with val_loss = 0.9966
Epoch 5, accuracy: 0.6649
batch size: (890, 890)
✅ Epoch 6: New best model saved with val_loss = 0.9821
Epoch 6, accuracy: 0.6831
Epoch 6, Train Loss: 0.0308, Val Loss: 0.9821
batch size: (890, 890)
✅ Epoch 7: New best model saved with val_loss = 0.9697
Epoch 7, accuracy: 0.6999
batch size: (894, 894)
✅ Epoch 8: New best model saved with val_loss = 0.9579
Epoch 8, accuracy: 0.7145
Epoch 8, Train Loss: 0.0099, Val Loss: 0.9579
batch size: (885, 885)
✅ Epoch 9: New best model saved with val_loss = 0.9437
Epoch 9, accuracy: 0.7179
batch size: (882, 882)
✅ Epoch 10: New best model saved with val_loss = 0.9288
Epoch 10, accuracy: 0.7273
Epoch 10, Train Loss: 0.0091, Val Loss: 0.9288
batch size: (891, 891)
✅ Epoch 11: New best model saved with val_loss = 0.9137
Epoch 11, accuracy: 0.7328
batch size: (907, 907)
✅ Epoch 12: New best model saved with val_loss = 0.9028
Epoch 12, accuracy: 0.7347
Epoch 12, Train Loss: 0.0068, Val Loss: 0.9028
batch size: (903, 903)
✅ Epoch 13: New best model saved with val_loss = 0.8857
Epoch 13, accuracy: 0.7368
batch size: (920, 920)
✅ Epoch 14: New best model saved with val_loss = 0.8751
Epoch 14, accuracy: 0.7371
Epoch 14, Train Loss: 0.0063, Val Loss: 0.8751
batch size: (895, 895)
✅ Epoch 15: New best model saved with val_loss = 0.8582
Epoch 15, accuracy: 0.7384
batch size: (909, 909)
✅ Epoch 16: New best model saved with val_loss = 0.8462
Epoch 16, accuracy: 0.7382
Epoch 16, Train Loss: 0.0018, Val Loss: 0.8462
batch size: (884, 884)
✅ Epoch 17: New best model saved with val_loss = 0.8300
Epoch 17, accuracy: 0.7389
batch size: (901, 901)
✅ Epoch 18: New best model saved with val_loss = 0.8206
Epoch 18, accuracy: 0.7399
Epoch 18, Train Loss: 0.0017, Val Loss: 0.8206
batch size: (909, 909)
✅ Epoch 19: New best model saved with val_loss = 0.8072
Epoch 19, accuracy: 0.7387
batch size: (893, 893)
✅ Epoch 20: New best model saved with val_loss = 0.7940
Epoch 20, accuracy: 0.7382
Epoch 20, Train Loss: 0.0023, Val Loss: 0.7940
batch size: (895, 895)
✅ Epoch 21: New best model saved with val_loss = 0.7861
Epoch 21, accuracy: 0.7377
batch size: (907, 907)
✅ Epoch 22: New best model saved with val_loss = 0.7674
Epoch 22, accuracy: 0.7391
Epoch 22, Train Loss: 0.0019, Val Loss: 0.7674
batch size: (885, 885)
✅ Epoch 23: New best model saved with val_loss = 0.7522
Epoch 23, accuracy: 0.7377
batch size: (887, 887)
✅ Epoch 24: New best model saved with val_loss = 0.7459
Epoch 24, accuracy: 0.7381
Epoch 24, Train Loss: 0.0025, Val Loss: 0.7459
batch size: (912, 912)
✅ Epoch 25: New best model saved with val_loss = 0.7302
Epoch 25, accuracy: 0.7367
batch size: (917, 917)
✅ Epoch 26: New best model saved with val_loss = 0.7214
Epoch 26, accuracy: 0.7370
Epoch 26, Train Loss: 0.0011, Val Loss: 0.7214
batch size: (891, 891)
✅ Epoch 27: New best model saved with val_loss = 0.7100
Epoch 27, accuracy: 0.7322
batch size: (888, 888)
✅ Epoch 28: New best model saved with val_loss = 0.6949
Epoch 28, accuracy: 0.7310
Epoch 28, Train Loss: 0.0011, Val Loss: 0.6949
batch size: (890, 890)
✅ Epoch 29: New best model saved with val_loss = 0.6872
Epoch 29, accuracy: 0.7276
batch size: (898, 898)
✅ Epoch 30: New best model saved with val_loss = 0.6721
Epoch 30, accuracy: 0.7268
Epoch 30, Train Loss: 0.0011, Val Loss: 0.6721
batch size: (910, 910)
✅ Epoch 31: New best model saved with val_loss = 0.6598
Epoch 31, accuracy: 0.7248
batch size: (888, 888)
✅ Epoch 32: New best model saved with val_loss = 0.6578
Epoch 32, accuracy: 0.7252
Epoch 32, Train Loss: 0.0006, Val Loss: 0.6578
batch size: (902, 902)
✅ Epoch 33: New best model saved with val_loss = 0.6498
Epoch 33, accuracy: 0.7252
batch size: (904, 904)
✅ Epoch 34: New best model saved with val_loss = 0.6408
Epoch 34, accuracy: 0.7229
Epoch 34, Train Loss: 0.0014, Val Loss: 0.6408
batch size: (887, 887)
✅ Epoch 35: New best model saved with val_loss = 0.6281
Epoch 35, accuracy: 0.7199
batch size: (900, 900)
✅ Epoch 36: New best model saved with val_loss = 0.6201
Epoch 36, accuracy: 0.7243
Epoch 36, Train Loss: 0.0008, Val Loss: 0.6201
batch size: (908, 908)
✅ Epoch 37: New best model saved with val_loss = 0.6091
Epoch 37, accuracy: 0.7187
batch size: (897, 897)
✅ Epoch 38: New best model saved with val_loss = 0.6082
Epoch 38, accuracy: 0.7207
Epoch 38, Train Loss: 0.0006, Val Loss: 0.6082
batch size: (896, 896)
✅ Epoch 39: New best model saved with val_loss = 0.5938
Epoch 39, accuracy: 0.7201
batch size: (892, 892)
✅ Epoch 40: New best model saved with val_loss = 0.5929
Epoch 40, accuracy: 0.7189
Epoch 40, Train Loss: 0.0004, Val Loss: 0.5929
batch size: (892, 892)
Epoch 41, accuracy: 0.7211
batch size: (913, 913)
✅ Epoch 42: New best model saved with val_loss = 0.5788
Epoch 42, accuracy: 0.7207
Epoch 42, Train Loss: 0.0005, Val Loss: 0.5788
batch size: (886, 886)
Epoch 43, accuracy: 0.7223
batch size: (913, 913)
✅ Epoch 44: New best model saved with val_loss = 0.5662
Epoch 44, accuracy: 0.7223
Epoch 44, Train Loss: 0.0008, Val Loss: 0.5662
batch size: (899, 899)
Epoch 45, accuracy: 0.7221
batch size: (877, 877)
Epoch 46, accuracy: 0.7211
Epoch 46, Train Loss: 0.0013, Val Loss: 0.5731
batch size: (887, 887)
Epoch 47, accuracy: 0.7215
batch size: (905, 905)
Epoch 48, accuracy: 0.7204
Epoch 48, Train Loss: 0.0012, Val Loss: 0.5691
batch size: (896, 896)
✅ Epoch 49: New best model saved with val_loss = 0.5623
Epoch 49, accuracy: 0.7225
Loaded best model with val_loss = 0.5623301267623901
test :accuracy 0.7223, f1_macro: 0.7180, f1_micro: 0.7223, auc: 0.8766
Training GCN with 8 layers...
可训练参数: 532745_GCN
不可训练参数: 0
batch size: (896, 896)
✅ Epoch 0: New best model saved with val_loss = 1.1570
Epoch 0, accuracy: 0.1663
Epoch 0, Train Loss: 1.1924, Val Loss: 1.1570
batch size: (913, 913)
✅ Epoch 1: New best model saved with val_loss = 1.1362
Epoch 1, accuracy: 0.4274
batch size: (896, 896)
Epoch 2, accuracy: 0.4330
Epoch 2, Train Loss: 1.1686, Val Loss: 1.1724
batch size: (900, 900)
Epoch 3, accuracy: 0.4291
batch size: (904, 904)
Epoch 4, accuracy: 0.4307
Epoch 4, Train Loss: 0.9727, Val Loss: 1.3868
batch size: (893, 893)
Epoch 5, accuracy: 0.1651
batch size: (913, 913)
Epoch 6, accuracy: 0.1680
Epoch 6, Train Loss: 0.9743, Val Loss: 1.6279
batch size: (916, 916)
Epoch 7, accuracy: 0.1694
batch size: (886, 886)
Epoch 8, accuracy: 0.1713
Epoch 8, Train Loss: 0.7359, Val Loss: 1.7303
batch size: (894, 894)
Epoch 9, accuracy: 0.1674
batch size: (917, 917)
Epoch 10, accuracy: 0.1652
Epoch 10, Train Loss: 0.6763, Val Loss: 1.7217
batch size: (922, 922)
Epoch 11, accuracy: 0.1666
batch size: (906, 906)
Epoch 12, accuracy: 0.1665
Epoch 12, Train Loss: 0.6396, Val Loss: 1.7390
batch size: (905, 905)
Epoch 13, accuracy: 0.1684
batch size: (898, 898)
Epoch 14, accuracy: 0.1686
Epoch 14, Train Loss: 0.6497, Val Loss: 1.7098
batch size: (916, 916)
Epoch 15, accuracy: 0.1638
batch size: (904, 904)
Epoch 16, accuracy: 0.1664
Epoch 16, Train Loss: 0.5875, Val Loss: 1.7704
batch size: (891, 891)
Epoch 17, accuracy: 0.1690
batch size: (891, 891)
Epoch 18, accuracy: 0.1682
Epoch 18, Train Loss: 0.4499, Val Loss: 1.7458
batch size: (895, 895)
Epoch 19, accuracy: 0.1662
batch size: (910, 910)
Epoch 20, accuracy: 0.1688
Epoch 20, Train Loss: 0.6167, Val Loss: 1.7392
batch size: (893, 893)
Epoch 21, accuracy: 0.1655
batch size: (908, 908)
Epoch 22, accuracy: 0.1696
Epoch 22, Train Loss: 0.6088, Val Loss: 1.7427
batch size: (917, 917)
Epoch 23, accuracy: 0.1670
/root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
/root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
batch size: (893, 893)
Epoch 24, accuracy: 0.1651
Epoch 24, Train Loss: 0.5485, Val Loss: 1.7507
batch size: (901, 901)
Epoch 25, accuracy: 0.1693
batch size: (910, 910)
Epoch 26, accuracy: 0.1681
Epoch 26, Train Loss: 0.6728, Val Loss: 1.7566
batch size: (906, 906)
Epoch 27, accuracy: 0.1666
batch size: (906, 906)
Epoch 28, accuracy: 0.1677
Epoch 28, Train Loss: 0.6459, Val Loss: 1.7235
batch size: (870, 870)
Epoch 29, accuracy: 0.1667
batch size: (907, 907)
Epoch 30, accuracy: 0.1653
Epoch 30, Train Loss: 0.5704, Val Loss: 1.7135
batch size: (899, 899)
Epoch 31, accuracy: 0.1678
batch size: (890, 890)
Epoch 32, accuracy: 0.1705
Epoch 32, Train Loss: 0.5928, Val Loss: 1.7278
batch size: (879, 879)
Epoch 33, accuracy: 0.1652
batch size: (897, 897)
Epoch 34, accuracy: 0.1688
Epoch 34, Train Loss: 0.6616, Val Loss: 1.7351
batch size: (901, 901)
Epoch 35, accuracy: 0.1665
batch size: (891, 891)
Epoch 36, accuracy: 0.1695
Epoch 36, Train Loss: 0.5926, Val Loss: 1.7236
batch size: (904, 904)
Epoch 37, accuracy: 0.1689
batch size: (892, 892)
Epoch 38, accuracy: 0.1707
Epoch 38, Train Loss: 0.5263, Val Loss: 1.7581
batch size: (920, 920)
Epoch 39, accuracy: 0.1681
batch size: (892, 892)
Epoch 40, accuracy: 0.1682
Epoch 40, Train Loss: 0.6347, Val Loss: 1.7277
batch size: (901, 901)
Epoch 41, accuracy: 0.1641
batch size: (921, 921)
Epoch 42, accuracy: 0.1689
Epoch 42, Train Loss: 0.6462, Val Loss: 1.7378
batch size: (898, 898)
Epoch 43, accuracy: 0.1655
batch size: (887, 887)
Epoch 44, accuracy: 0.1689
Epoch 44, Train Loss: 0.6503, Val Loss: 1.6843
batch size: (897, 897)
Epoch 45, accuracy: 0.1664
batch size: (914, 914)
Epoch 46, accuracy: 0.1668
Epoch 46, Train Loss: 0.6916, Val Loss: 1.7122
batch size: (902, 902)
Epoch 47, accuracy: 0.1632
batch size: (887, 887)
Epoch 48, accuracy: 0.1699
Epoch 48, Train Loss: 0.5785, Val Loss: 1.7300
batch size: (900, 900)
Epoch 49, accuracy: 0.1671
Loaded best model with val_loss = 1.1361560821533203
test :accuracy 0.4286, f1_macro: 0.2000, f1_micro: 0.4286, auc: 0.5065
Training GCN with 32 layers...
可训练参数: 2130185_GCN
不可训练参数: 0
batch size: (906, 906)
✅ Epoch 0: New best model saved with val_loss = 1.1290
Epoch 0, accuracy: 0.1685
Epoch 0, Train Loss: 1.2072, Val Loss: 1.1290
batch size: (881, 881)
Epoch 1, accuracy: 0.1670
batch size: (915, 915)
Epoch 2, accuracy: 0.1658
Epoch 2, Train Loss: 1.2109, Val Loss: 1.1508
batch size: (915, 915)
Epoch 3, accuracy: 0.3593
batch size: (895, 895)
✅ Epoch 4: New best model saved with val_loss = 1.1220
Epoch 4, accuracy: 0.3583
Epoch 4, Train Loss: 1.0824, Val Loss: 1.1220
batch size: (897, 897)
Epoch 5, accuracy: 0.3576
batch size: (908, 908)
Epoch 6, accuracy: 0.3558
Epoch 6, Train Loss: 1.2283, Val Loss: 1.1245
batch size: (902, 902)
Epoch 7, accuracy: 0.1693
batch size: (878, 878)
Epoch 8, accuracy: 0.1684
Epoch 8, Train Loss: 1.1905, Val Loss: 1.1363
batch size: (889, 889)
Epoch 9, accuracy: 0.1708
batch size: (890, 890)
Epoch 10, accuracy: 0.1691
Epoch 10, Train Loss: 1.1602, Val Loss: 1.1246
batch size: (899, 899)
✅ Epoch 11: New best model saved with val_loss = 1.1200
Epoch 11, accuracy: 0.1697
batch size: (911, 911)
✅ Epoch 12: New best model saved with val_loss = 1.1156
Epoch 12, accuracy: 0.1661
Epoch 12, Train Loss: 1.1832, Val Loss: 1.1156
batch size: (907, 907)
Epoch 13, accuracy: 0.3563
batch size: (903, 903)
Epoch 14, accuracy: 0.1712
Epoch 14, Train Loss: 1.1968, Val Loss: 1.1204
batch size: (914, 914)
✅ Epoch 15: New best model saved with val_loss = 1.1097
Epoch 15, accuracy: 0.3539
batch size: (866, 866)
Epoch 16, accuracy: 0.3588
Epoch 16, Train Loss: 1.1662, Val Loss: 1.1107
batch size: (887, 887)
✅ Epoch 17: New best model saved with val_loss = 1.1087
Epoch 17, accuracy: 0.3581
batch size: (893, 893)
✅ Epoch 18: New best model saved with val_loss = 1.1075
Epoch 18, accuracy: 0.3567
Epoch 18, Train Loss: 1.1325, Val Loss: 1.1075
batch size: (905, 905)
Epoch 19, accuracy: 0.3589
batch size: (901, 901)
Epoch 20, accuracy: 0.1683
Epoch 20, Train Loss: 0.9803, Val Loss: 1.1127
batch size: (889, 889)
Epoch 21, accuracy: 0.3748
batch size: (910, 910)
Epoch 22, accuracy: 0.1658
Epoch 22, Train Loss: 1.2177, Val Loss: 1.1131
batch size: (913, 913)
Epoch 23, accuracy: 0.3567
batch size: (904, 904)
Epoch 24, accuracy: 0.3576
Epoch 24, Train Loss: 1.1367, Val Loss: 1.1102
batch size: (897, 897)
Epoch 25, accuracy: 0.3539
batch size: (913, 913)
Epoch 26, accuracy: 0.3716
Epoch 26, Train Loss: 1.0774, Val Loss: 1.1081
batch size: (894, 894)
Epoch 27, accuracy: 0.3627
batch size: (880, 880)
Epoch 28, accuracy: 0.3546
Epoch 28, Train Loss: 1.2141, Val Loss: 1.1108
batch size: (905, 905)
✅ Epoch 29: New best model saved with val_loss = 1.1074
Epoch 29, accuracy: 0.3594
batch size: (898, 898)
Epoch 30, accuracy: 0.3563
Epoch 30, Train Loss: 1.1817, Val Loss: 1.1097
batch size: (893, 893)
Epoch 31, accuracy: 0.1685
batch size: (906, 906)
Epoch 32, accuracy: 0.3581
Epoch 32, Train Loss: 1.0843, Val Loss: 1.1103
batch size: (908, 908)
Epoch 33, accuracy: 0.1677
batch size: (894, 894)
Epoch 34, accuracy: 0.1667
Epoch 34, Train Loss: 1.1625, Val Loss: 1.1101
batch size: (909, 909)
✅ Epoch 35: New best model saved with val_loss = 1.1061
Epoch 35, accuracy: 0.3719
batch size: (906, 906)
Epoch 36, accuracy: 0.1683
Epoch 36, Train Loss: 1.1503, Val Loss: 1.1136
batch size: (903, 903)
Epoch 37, accuracy: 0.1655
batch size: (895, 895)
Epoch 38, accuracy: 0.1668
Epoch 38, Train Loss: 1.2111, Val Loss: 1.1159
batch size: (900, 900)
Epoch 39, accuracy: 0.3547
batch size: (918, 918)
Epoch 40, accuracy: 0.3552
Epoch 40, Train Loss: 1.1266, Val Loss: 1.1126
batch size: (909, 909)
Epoch 41, accuracy: 0.3534
batch size: (907, 907)
Epoch 42, accuracy: 0.3574
Epoch 42, Train Loss: 1.0933, Val Loss: 1.1073
batch size: (917, 917)
Epoch 43, accuracy: 0.3517
batch size: (901, 901)
Epoch 44, accuracy: 0.3612
Epoch 44, Train Loss: 1.1345, Val Loss: 1.1087
batch size: (903, 903)
✅ Epoch 45: New best model saved with val_loss = 1.1056
Epoch 45, accuracy: 0.3564
batch size: (908, 908)
Epoch 46, accuracy: 0.3533
Epoch 46, Train Loss: 1.0466, Val Loss: 1.1095
batch size: (893, 893)
Epoch 47, accuracy: 0.3538
batch size: (918, 918)
Epoch 48, accuracy: 0.3573
Epoch 48, Train Loss: 1.0270, Val Loss: 1.1126
batch size: (917, 917)
Epoch 49, accuracy: 0.3550
Loaded best model with val_loss = 1.1056421995162964
test :accuracy 0.3555, f1_macro: 0.2426, f1_micro: 0.3555, auc: 0.5003
Training GraphSAGE with 2 layers...
可训练参数: 262153_GraphSAGE
不可训练参数: 0
batch size: (899, 899)
✅ Epoch 0: New best model saved with val_loss = 1.0935
Epoch 0, accuracy: 0.4458
Epoch 0, Train Loss: 1.1671, Val Loss: 1.0935
batch size: (895, 895)
✅ Epoch 1: New best model saved with val_loss = 1.0864
Epoch 1, accuracy: 0.5399
batch size: (906, 906)
✅ Epoch 2: New best model saved with val_loss = 1.0755
Epoch 2, accuracy: 0.6133
Epoch 2, Train Loss: 0.3386, Val Loss: 1.0755
batch size: (897, 897)
✅ Epoch 3: New best model saved with val_loss = 1.0645
Epoch 3, accuracy: 0.6479
batch size: (905, 905)
✅ Epoch 4: New best model saved with val_loss = 1.0538
Epoch 4, accuracy: 0.6690
Epoch 4, Train Loss: 0.1017, Val Loss: 1.0538
batch size: (888, 888)
✅ Epoch 5: New best model saved with val_loss = 1.0421
Epoch 5, accuracy: 0.6810
batch size: (893, 893)
✅ Epoch 6: New best model saved with val_loss = 1.0285
Epoch 6, accuracy: 0.6873
Epoch 6, Train Loss: 0.0379, Val Loss: 1.0285
batch size: (904, 904)
✅ Epoch 7: New best model saved with val_loss = 1.0158
Epoch 7, accuracy: 0.6898
batch size: (893, 893)
✅ Epoch 8: New best model saved with val_loss = 1.0021
Epoch 8, accuracy: 0.6852
Epoch 8, Train Loss: 0.0084, Val Loss: 1.0021
batch size: (887, 887)
✅ Epoch 9: New best model saved with val_loss = 0.9901
Epoch 9, accuracy: 0.6845
batch size: (893, 893)
✅ Epoch 10: New best model saved with val_loss = 0.9765
Epoch 10, accuracy: 0.6855
Epoch 10, Train Loss: 0.0016, Val Loss: 0.9765
batch size: (909, 909)
✅ Epoch 11: New best model saved with val_loss = 0.9638
Epoch 11, accuracy: 0.6868
batch size: (906, 906)
/root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
✅ Epoch 12: New best model saved with val_loss = 0.9509
Epoch 12, accuracy: 0.6864
Epoch 12, Train Loss: 0.0006, Val Loss: 0.9509
batch size: (904, 904)
✅ Epoch 13: New best model saved with val_loss = 0.9371
Epoch 13, accuracy: 0.6893
batch size: (896, 896)
✅ Epoch 14: New best model saved with val_loss = 0.9238
Epoch 14, accuracy: 0.6915
Epoch 14, Train Loss: 0.0008, Val Loss: 0.9238
batch size: (903, 903)
✅ Epoch 15: New best model saved with val_loss = 0.9113
Epoch 15, accuracy: 0.7014
batch size: (893, 893)
✅ Epoch 16: New best model saved with val_loss = 0.8975
Epoch 16, accuracy: 0.6980
Epoch 16, Train Loss: 0.0004, Val Loss: 0.8975
batch size: (910, 910)
✅ Epoch 17: New best model saved with val_loss = 0.8844
Epoch 17, accuracy: 0.7038
batch size: (892, 892)
✅ Epoch 18: New best model saved with val_loss = 0.8693
Epoch 18, accuracy: 0.7059
Epoch 18, Train Loss: 0.0003, Val Loss: 0.8693
batch size: (910, 910)
✅ Epoch 19: New best model saved with val_loss = 0.8574
Epoch 19, accuracy: 0.7051
batch size: (907, 907)
✅ Epoch 20: New best model saved with val_loss = 0.8415
Epoch 20, accuracy: 0.7069
Epoch 20, Train Loss: 0.0011, Val Loss: 0.8415
batch size: (907, 907)
✅ Epoch 21: New best model saved with val_loss = 0.8319
Epoch 21, accuracy: 0.7106
batch size: (900, 900)
✅ Epoch 22: New best model saved with val_loss = 0.8190
Epoch 22, accuracy: 0.7108
Epoch 22, Train Loss: 0.0008, Val Loss: 0.8190
batch size: (894, 894)
✅ Epoch 23: New best model saved with val_loss = 0.8040
Epoch 23, accuracy: 0.7084
batch size: (878, 878)
✅ Epoch 24: New best model saved with val_loss = 0.7912
Epoch 24, accuracy: 0.7097
Epoch 24, Train Loss: 0.0001, Val Loss: 0.7912
batch size: (895, 895)
✅ Epoch 25: New best model saved with val_loss = 0.7828
Epoch 25, accuracy: 0.7115
batch size: (896, 896)
✅ Epoch 26: New best model saved with val_loss = 0.7694
Epoch 26, accuracy: 0.7114
Epoch 26, Train Loss: 0.0001, Val Loss: 0.7694
batch size: (899, 899)
✅ Epoch 27: New best model saved with val_loss = 0.7561
Epoch 27, accuracy: 0.7118
batch size: (916, 916)
✅ Epoch 28: New best model saved with val_loss = 0.7458
Epoch 28, accuracy: 0.7088
Epoch 28, Train Loss: 0.0001, Val Loss: 0.7458
batch size: (894, 894)
✅ Epoch 29: New best model saved with val_loss = 0.7324
Epoch 29, accuracy: 0.7092
batch size: (886, 886)
✅ Epoch 30: New best model saved with val_loss = 0.7231
Epoch 30, accuracy: 0.7086
Epoch 30, Train Loss: 0.0004, Val Loss: 0.7231
batch size: (893, 893)
✅ Epoch 31: New best model saved with val_loss = 0.7089
Epoch 31, accuracy: 0.7066
batch size: (894, 894)
✅ Epoch 32: New best model saved with val_loss = 0.6994
Epoch 32, accuracy: 0.7064
Epoch 32, Train Loss: 0.0001, Val Loss: 0.6994
batch size: (891, 891)
✅ Epoch 33: New best model saved with val_loss = 0.6876
Epoch 33, accuracy: 0.7075
batch size: (910, 910)
✅ Epoch 34: New best model saved with val_loss = 0.6781
Epoch 34, accuracy: 0.7098
Epoch 34, Train Loss: 0.0001, Val Loss: 0.6781
batch size: (892, 892)
✅ Epoch 35: New best model saved with val_loss = 0.6707
Epoch 35, accuracy: 0.7110
batch size: (889, 889)
✅ Epoch 36: New best model saved with val_loss = 0.6632
Epoch 36, accuracy: 0.7085
Epoch 36, Train Loss: 0.0000, Val Loss: 0.6632
batch size: (885, 885)
✅ Epoch 37: New best model saved with val_loss = 0.6531
Epoch 37, accuracy: 0.7104
batch size: (903, 903)
✅ Epoch 38: New best model saved with val_loss = 0.6457
Epoch 38, accuracy: 0.7107
Epoch 38, Train Loss: 0.0001, Val Loss: 0.6457
batch size: (928, 928)
✅ Epoch 39: New best model saved with val_loss = 0.6361
Epoch 39, accuracy: 0.7099
batch size: (895, 895)
✅ Epoch 40: New best model saved with val_loss = 0.6273
Epoch 40, accuracy: 0.7114
Epoch 40, Train Loss: 0.0000, Val Loss: 0.6273
batch size: (907, 907)
✅ Epoch 41: New best model saved with val_loss = 0.6235
Epoch 41, accuracy: 0.7103
batch size: (898, 898)
✅ Epoch 42: New best model saved with val_loss = 0.6216
Epoch 42, accuracy: 0.7106
Epoch 42, Train Loss: 0.0001, Val Loss: 0.6216
batch size: (893, 893)
✅ Epoch 43: New best model saved with val_loss = 0.6155
Epoch 43, accuracy: 0.7097
batch size: (894, 894)
✅ Epoch 44: New best model saved with val_loss = 0.6073
Epoch 44, accuracy: 0.7101
Epoch 44, Train Loss: 0.0001, Val Loss: 0.6073
batch size: (901, 901)
✅ Epoch 45: New best model saved with val_loss = 0.6049
Epoch 45, accuracy: 0.7107
batch size: (912, 912)
✅ Epoch 46: New best model saved with val_loss = 0.6022
Epoch 46, accuracy: 0.7114
Epoch 46, Train Loss: 0.0001, Val Loss: 0.6022
batch size: (902, 902)
✅ Epoch 47: New best model saved with val_loss = 0.6001
Epoch 47, accuracy: 0.7113
batch size: (887, 887)
Epoch 48, accuracy: 0.7100
Epoch 48, Train Loss: 0.0002, Val Loss: 0.6011
batch size: (913, 913)
Epoch 49, accuracy: 0.7119
Loaded best model with val_loss = 0.6000510454177856
test :accuracy 0.7112, f1_macro: 0.7105, f1_micro: 0.7112, auc: 0.8606
Training GraphSAGE with 8 layers...
可训练参数: 1054729_GraphSAGE
不可训练参数: 0
batch size: (884, 884)
✅ Epoch 0: New best model saved with val_loss = 1.0986
Epoch 0, accuracy: 0.3805
Epoch 0, Train Loss: 1.0823, Val Loss: 1.0986
batch size: (905, 905)
Epoch 1, accuracy: 0.3752
batch size: (893, 893)
Epoch 2, accuracy: 0.3694
Epoch 2, Train Loss: 1.1479, Val Loss: 1.0986
batch size: (897, 897)
Epoch 3, accuracy: 0.3714
batch size: (916, 916)
Epoch 4, accuracy: 0.3712
Epoch 4, Train Loss: 1.0989, Val Loss: 1.0986
batch size: (897, 897)
Epoch 5, accuracy: 0.3725
batch size: (911, 911)
Epoch 6, accuracy: 0.3706
Epoch 6, Train Loss: 1.0978, Val Loss: 1.0986
batch size: (896, 896)
Epoch 7, accuracy: 0.3754
batch size: (883, 883)
Epoch 8, accuracy: 0.3777
Epoch 8, Train Loss: 1.1053, Val Loss: 1.0986
batch size: (922, 922)
Epoch 9, accuracy: 0.3736
batch size: (910, 910)
Epoch 10, accuracy: 0.3770
Epoch 10, Train Loss: 1.0968, Val Loss: 1.0986
batch size: (902, 902)
Epoch 11, accuracy: 0.3743
batch size: (898, 898)
Epoch 12, accuracy: 0.3713
Epoch 12, Train Loss: 1.0981, Val Loss: 1.0986
batch size: (906, 906)
Epoch 13, accuracy: 0.3717
batch size: (886, 886)
Epoch 14, accuracy: 0.3721
Epoch 14, Train Loss: 1.0901, Val Loss: 1.0986
batch size: (908, 908)
Epoch 15, accuracy: 0.3733
batch size: (914, 914)
Epoch 16, accuracy: 0.3715
Epoch 16, Train Loss: 1.0843, Val Loss: 1.0986
batch size: (906, 906)
Epoch 17, accuracy: 0.3748
batch size: (906, 906)
Epoch 18, accuracy: 0.3736
Epoch 18, Train Loss: 1.1033, Val Loss: 1.0986
batch size: (892, 892)
Epoch 19, accuracy: 0.3714
batch size: (897, 897)
Epoch 20, accuracy: 0.3696
Epoch 20, Train Loss: 1.1014, Val Loss: 1.0986
batch size: (918, 918)
Epoch 21, accuracy: 0.3748
batch size: (884, 884)
Epoch 22, accuracy: 0.3747
Epoch 22, Train Loss: 1.0935, Val Loss: 1.0986
batch size: (886, 886)
Epoch 23, accuracy: 0.3762
batch size: (892, 892)
Epoch 24, accuracy: 0.3740
Epoch 24, Train Loss: 1.0810, Val Loss: 1.0986
batch size: (923, 923)
Epoch 25, accuracy: 0.3741
batch size: (905, 905)
Epoch 26, accuracy: 0.3701
Epoch 26, Train Loss: 1.0756, Val Loss: 1.0986
batch size: (886, 886)
Epoch 27, accuracy: 0.3722
batch size: (883, 883)
Epoch 28, accuracy: 0.3733
Epoch 28, Train Loss: 1.1036, Val Loss: 1.0986
batch size: (903, 903)
Epoch 29, accuracy: 0.3725
batch size: (875, 875)
Epoch 30, accuracy: 0.3734
Epoch 30, Train Loss: 1.0978, Val Loss: 1.0986
batch size: (884, 884)
Epoch 31, accuracy: 0.3781
batch size: (882, 882)
Epoch 32, accuracy: 0.3712
Epoch 32, Train Loss: 1.0945, Val Loss: 1.0986
batch size: (898, 898)
Epoch 33, accuracy: 0.3758
batch size: (892, 892)
Epoch 34, accuracy: 0.3743
Epoch 34, Train Loss: 1.1014, Val Loss: 1.0986
batch size: (918, 918)
Epoch 35, accuracy: 0.3774
batch size: (902, 902)
Epoch 36, accuracy: 0.3744
Epoch 36, Train Loss: 1.0876, Val Loss: 1.0986
batch size: (896, 896)
Epoch 37, accuracy: 0.3715
batch size: (906, 906)
Epoch 38, accuracy: 0.3718
Epoch 38, Train Loss: 1.0975, Val Loss: 1.0986
batch size: (900, 900)
Epoch 39, accuracy: 0.3761
batch size: (891, 891)
Epoch 40, accuracy: 0.3723
Epoch 40, Train Loss: 1.0972, Val Loss: 1.0986
batch size: (893, 893)
/root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
/root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
Epoch 41, accuracy: 0.3747
batch size: (899, 899)
Epoch 42, accuracy: 0.3745
Epoch 42, Train Loss: 1.0937, Val Loss: 1.0986
batch size: (905, 905)
Epoch 43, accuracy: 0.3725
batch size: (900, 900)
Epoch 44, accuracy: 0.3705
Epoch 44, Train Loss: 1.0946, Val Loss: 1.0986
batch size: (898, 898)
Epoch 45, accuracy: 0.3718
batch size: (883, 883)
Epoch 46, accuracy: 0.3721
Epoch 46, Train Loss: 1.1048, Val Loss: 1.0986
batch size: (913, 913)
Epoch 47, accuracy: 0.3722
batch size: (888, 888)
Epoch 48, accuracy: 0.3695
Epoch 48, Train Loss: 1.0962, Val Loss: 1.0986
batch size: (910, 910)
Epoch 49, accuracy: 0.3752
Loaded best model with val_loss = 1.0986120700836182
test :accuracy 0.3819, f1_macro: 0.2444, f1_micro: 0.3819, auc: 0.4546
Training GraphSAGE with 32 layers...
可训练参数: 4225033_GraphSAGE
不可训练参数: 0
batch size: (898, 898)
✅ Epoch 0: New best model saved with val_loss = 1.0933
Epoch 0, accuracy: 0.4161
Epoch 0, Train Loss: 1.3121, Val Loss: 1.0933
batch size: (899, 899)
Epoch 1, accuracy: 0.4106
batch size: (901, 901)
Epoch 2, accuracy: 0.4143
Epoch 2, Train Loss: 1.3973, Val Loss: 1.0985
batch size: (898, 898)
Epoch 3, accuracy: 0.3733
batch size: (929, 929)
Epoch 4, accuracy: 0.3937
Epoch 4, Train Loss: 1.1155, Val Loss: 1.0981
batch size: (889, 889)
Epoch 5, accuracy: 0.4015
batch size: (882, 882)
Epoch 6, accuracy: 0.4041
Epoch 6, Train Loss: 1.0971, Val Loss: 1.0971
batch size: (904, 904)
Epoch 7, accuracy: 0.4015
batch size: (883, 883)
Epoch 8, accuracy: 0.3986
Epoch 8, Train Loss: 1.1058, Val Loss: 1.0965
batch size: (905, 905)
Epoch 9, accuracy: 0.4025
batch size: (892, 892)
Epoch 10, accuracy: 0.4049
Epoch 10, Train Loss: 1.0803, Val Loss: 1.0966
batch size: (913, 913)
Epoch 11, accuracy: 0.4026
batch size: (900, 900)
Epoch 12, accuracy: 0.4015
Epoch 12, Train Loss: 1.1134, Val Loss: 1.0972
batch size: (902, 902)
Epoch 13, accuracy: 0.4027
batch size: (897, 897)
Epoch 14, accuracy: 0.3992
Epoch 14, Train Loss: 1.1005, Val Loss: 1.0967
batch size: (911, 911)
Epoch 15, accuracy: 0.4046
batch size: (899, 899)
Epoch 16, accuracy: 0.4074
Epoch 16, Train Loss: 1.1041, Val Loss: 1.0967
batch size: (897, 897)
Epoch 17, accuracy: 0.3993
batch size: (887, 887)
Epoch 18, accuracy: 0.4044
Epoch 18, Train Loss: 1.1035, Val Loss: 1.0971
batch size: (892, 892)
Epoch 19, accuracy: 0.4063
batch size: (908, 908)
Epoch 20, accuracy: 0.4045
Epoch 20, Train Loss: 1.1062, Val Loss: 1.0969
batch size: (884, 884)
Epoch 21, accuracy: 0.4020
batch size: (915, 915)
Epoch 22, accuracy: 0.4028
Epoch 22, Train Loss: 1.0973, Val Loss: 1.0970
batch size: (911, 911)
Epoch 23, accuracy: 0.3994
batch size: (886, 886)
Epoch 24, accuracy: 0.4017
Epoch 24, Train Loss: 1.0973, Val Loss: 1.0970
batch size: (896, 896)
Epoch 25, accuracy: 0.4036
batch size: (895, 895)
Epoch 26, accuracy: 0.4022
Epoch 26, Train Loss: 1.1037, Val Loss: 1.0969
batch size: (922, 922)
Epoch 27, accuracy: 0.4057
batch size: (901, 901)
Epoch 28, accuracy: 0.4002
Epoch 28, Train Loss: 1.1276, Val Loss: 1.0971
batch size: (904, 904)
Epoch 29, accuracy: 0.4007
batch size: (908, 908)
Epoch 30, accuracy: 0.4030
Epoch 30, Train Loss: 1.0977, Val Loss: 1.0970
batch size: (913, 913)
Epoch 31, accuracy: 0.4016
batch size: (891, 891)
Epoch 32, accuracy: 0.4022
Epoch 32, Train Loss: 1.1058, Val Loss: 1.0968
batch size: (916, 916)
Epoch 33, accuracy: 0.4005
batch size: (889, 889)
Epoch 34, accuracy: 0.4009
Epoch 34, Train Loss: 1.0968, Val Loss: 1.0969
batch size: (897, 897)
Epoch 35, accuracy: 0.4030
batch size: (910, 910)
Epoch 36, accuracy: 0.4016
Epoch 36, Train Loss: 1.0809, Val Loss: 1.0970
batch size: (916, 916)
Epoch 37, accuracy: 0.4029
batch size: (894, 894)
Epoch 38, accuracy: 0.4040
Epoch 38, Train Loss: 1.0860, Val Loss: 1.0969
batch size: (892, 892)
Epoch 39, accuracy: 0.4057
batch size: (904, 904)
Epoch 40, accuracy: 0.4045
Epoch 40, Train Loss: 1.0930, Val Loss: 1.0966
batch size: (887, 887)
Epoch 41, accuracy: 0.4024
batch size: (887, 887)
Epoch 42, accuracy: 0.4056
Epoch 42, Train Loss: 1.1214, Val Loss: 1.0970
batch size: (887, 887)
Epoch 43, accuracy: 0.4055
batch size: (911, 911)
Epoch 44, accuracy: 0.4024
Epoch 44, Train Loss: 1.0972, Val Loss: 1.0969
batch size: (910, 910)
Epoch 45, accuracy: 0.4054
batch size: (882, 882)
Epoch 46, accuracy: 0.4036
Epoch 46, Train Loss: 1.0891, Val Loss: 1.0968
batch size: (909, 909)
Epoch 47, accuracy: 0.4008
batch size: (900, 900)
Epoch 48, accuracy: 0.4023
Epoch 48, Train Loss: 1.0900, Val Loss: 1.0969
batch size: (891, 891)
Epoch 49, accuracy: 0.3996
Loaded best model with val_loss = 1.0933140516281128
test :accuracy 0.4063, f1_macro: 0.2738, f1_micro: 0.4063, auc: 0.5016
Training GAT with 2 layers...
可训练参数: 196495_GAT
不可训练参数: 0
batch size: (910, 910)
✅ Epoch 0: New best model saved with val_loss = 1.0791
Epoch 0, accuracy: 0.6514
Epoch 0, Train Loss: 1.0981, Val Loss: 1.0791
batch size: (898, 898)
✅ Epoch 1: New best model saved with val_loss = 1.0570
Epoch 1, accuracy: 0.6996
batch size: (887, 887)
✅ Epoch 2: New best model saved with val_loss = 1.0314
Epoch 2, accuracy: 0.7080
Epoch 2, Train Loss: 1.0253, Val Loss: 1.0314
batch size: (909, 909)
✅ Epoch 3: New best model saved with val_loss = 1.0025
Epoch 3, accuracy: 0.7132
batch size: (891, 891)
✅ Epoch 4: New best model saved with val_loss = 0.9698
Epoch 4, accuracy: 0.7160
Epoch 4, Train Loss: 0.9377, Val Loss: 0.9698
batch size: (910, 910)
✅ Epoch 5: New best model saved with val_loss = 0.9344
Epoch 5, accuracy: 0.7191
batch size: (899, 899)
✅ Epoch 6: New best model saved with val_loss = 0.8980
Epoch 6, accuracy: 0.7227
Epoch 6, Train Loss: 0.8264, Val Loss: 0.8980
batch size: (904, 904)
✅ Epoch 7: New best model saved with val_loss = 0.8583
Epoch 7, accuracy: 0.7228
batch size: (891, 891)
✅ Epoch 8: New best model saved with val_loss = 0.8251
Epoch 8, accuracy: 0.7266
Epoch 8, Train Loss: 0.7071, Val Loss: 0.8251
batch size: (896, 896)
✅ Epoch 9: New best model saved with val_loss = 0.7923
Epoch 9, accuracy: 0.7255
batch size: (896, 896)
✅ Epoch 10: New best model saved with val_loss = 0.7528
Epoch 10, accuracy: 0.7306
Epoch 10, Train Loss: 0.5911, Val Loss: 0.7528
batch size: (908, 908)
✅ Epoch 11: New best model saved with val_loss = 0.7214
Epoch 11, accuracy: 0.7327
batch size: (887, 887)
✅ Epoch 12: New best model saved with val_loss = 0.6892
Epoch 12, accuracy: 0.7344
Epoch 12, Train Loss: 0.4829, Val Loss: 0.6892
batch size: (899, 899)
✅ Epoch 13: New best model saved with val_loss = 0.6662
Epoch 13, accuracy: 0.7367
batch size: (898, 898)
✅ Epoch 14: New best model saved with val_loss = 0.6518
Epoch 14, accuracy: 0.7391
Epoch 14, Train Loss: 0.3900, Val Loss: 0.6518
batch size: (890, 890)
✅ Epoch 15: New best model saved with val_loss = 0.6307
Epoch 15, accuracy: 0.7410
batch size: (890, 890)
✅ Epoch 16: New best model saved with val_loss = 0.6051
Epoch 16, accuracy: 0.7403
Epoch 16, Train Loss: 0.3005, Val Loss: 0.6051
batch size: (895, 895)
✅ Epoch 17: New best model saved with val_loss = 0.5992
Epoch 17, accuracy: 0.7420
batch size: (890, 890)
✅ Epoch 18: New best model saved with val_loss = 0.5913
Epoch 18, accuracy: 0.7409
Epoch 18, Train Loss: 0.2361, Val Loss: 0.5913
batch size: (893, 893)
✅ Epoch 19: New best model saved with val_loss = 0.5841
Epoch 19, accuracy: 0.7419
batch size: (891, 891)
✅ Epoch 20: New best model saved with val_loss = 0.5682
Epoch 20, accuracy: 0.7400
Epoch 20, Train Loss: 0.1822, Val Loss: 0.5682
batch size: (895, 895)
Epoch 21, accuracy: 0.7361
batch size: (894, 894)
✅ Epoch 22: New best model saved with val_loss = 0.5603
Epoch 22, accuracy: 0.7370
Epoch 22, Train Loss: 0.1507, Val Loss: 0.5603
batch size: (914, 914)
Epoch 23, accuracy: 0.7331
batch size: (894, 894)
Epoch 24, accuracy: 0.7322
Epoch 24, Train Loss: 0.1281, Val Loss: 0.5720
batch size: (897, 897)
Epoch 25, accuracy: 0.7236
batch size: (896, 896)
Epoch 26, accuracy: 0.7201
Epoch 26, Train Loss: 0.1022, Val Loss: 0.5791
batch size: (884, 884)
Epoch 27, accuracy: 0.7143
batch size: (905, 905)
Epoch 28, accuracy: 0.7084
Epoch 28, Train Loss: 0.0754, Val Loss: 0.5960
batch size: (900, 900)
/root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
/root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
Epoch 29, accuracy: 0.7120
batch size: (905, 905)
Epoch 30, accuracy: 0.7091
Epoch 30, Train Loss: 0.0776, Val Loss: 0.5912
batch size: (925, 925)
Epoch 31, accuracy: 0.7131
batch size: (907, 907)
Epoch 32, accuracy: 0.7107
Epoch 32, Train Loss: 0.0686, Val Loss: 0.5916
batch size: (909, 909)
Epoch 33, accuracy: 0.7122
batch size: (912, 912)
Epoch 34, accuracy: 0.7106
Epoch 34, Train Loss: 0.0816, Val Loss: 0.5818
batch size: (891, 891)
Epoch 35, accuracy: 0.7104
batch size: (907, 907)
Epoch 36, accuracy: 0.7099
Epoch 36, Train Loss: 0.0728, Val Loss: 0.5901
batch size: (888, 888)
Epoch 37, accuracy: 0.7127
batch size: (910, 910)
Epoch 38, accuracy: 0.7112
Epoch 38, Train Loss: 0.0731, Val Loss: 0.5849
batch size: (901, 901)
Epoch 39, accuracy: 0.7115
batch size: (905, 905)
Epoch 40, accuracy: 0.7091
Epoch 40, Train Loss: 0.0669, Val Loss: 0.5895
batch size: (890, 890)
Epoch 41, accuracy: 0.7100
batch size: (899, 899)
Epoch 42, accuracy: 0.7121
Epoch 42, Train Loss: 0.0801, Val Loss: 0.5815
batch size: (903, 903)
Epoch 43, accuracy: 0.7097
batch size: (908, 908)
Epoch 44, accuracy: 0.7130
Epoch 44, Train Loss: 0.0757, Val Loss: 0.5846
batch size: (904, 904)
Epoch 45, accuracy: 0.7130
batch size: (916, 916)
Epoch 46, accuracy: 0.7091
Epoch 46, Train Loss: 0.0752, Val Loss: 0.5820
batch size: (890, 890)
Epoch 47, accuracy: 0.7131
batch size: (909, 909)
Epoch 48, accuracy: 0.7114
Epoch 48, Train Loss: 0.0635, Val Loss: 0.5935
batch size: (904, 904)
Epoch 49, accuracy: 0.7101
Loaded best model with val_loss = 0.5603402256965637
test :accuracy 0.7377, f1_macro: 0.7333, f1_micro: 0.7377, auc: 0.8940
Training GAT with 8 layers...
可训练参数: 1090447_GAT
不可训练参数: 0
batch size: (891, 891)
✅ Epoch 0: New best model saved with val_loss = 1.1007
Epoch 0, accuracy: 0.1696
Epoch 0, Train Loss: 1.0991, Val Loss: 1.1007
batch size: (905, 905)
✅ Epoch 1: New best model saved with val_loss = 1.0995
Epoch 1, accuracy: 0.4290
batch size: (910, 910)
✅ Epoch 2: New best model saved with val_loss = 1.0990
Epoch 2, accuracy: 0.1782
Epoch 2, Train Loss: 1.1025, Val Loss: 1.0990
batch size: (893, 893)
Epoch 3, accuracy: 0.1665
batch size: (910, 910)
✅ Epoch 4: New best model saved with val_loss = 1.0838
Epoch 4, accuracy: 0.4310
Epoch 4, Train Loss: 1.0987, Val Loss: 1.0838
batch size: (879, 879)
Epoch 5, accuracy: 0.1644
batch size: (905, 905)
✅ Epoch 6: New best model saved with val_loss = 1.0687
Epoch 6, accuracy: 0.5005
Epoch 6, Train Loss: 1.0772, Val Loss: 1.0687
batch size: (867, 867)
✅ Epoch 7: New best model saved with val_loss = 1.0464
Epoch 7, accuracy: 0.3729
batch size: (902, 902)
✅ Epoch 8: New best model saved with val_loss = 1.0376
Epoch 8, accuracy: 0.4594
Epoch 8, Train Loss: 0.9500, Val Loss: 1.0376
batch size: (911, 911)
✅ Epoch 9: New best model saved with val_loss = 0.9304
Epoch 9, accuracy: 0.5421
batch size: (900, 900)
✅ Epoch 10: New best model saved with val_loss = 0.8642
Epoch 10, accuracy: 0.6376
Epoch 10, Train Loss: 0.8709, Val Loss: 0.8642
batch size: (899, 899)
✅ Epoch 11: New best model saved with val_loss = 0.8163
Epoch 11, accuracy: 0.6441
batch size: (906, 906)
✅ Epoch 12: New best model saved with val_loss = 0.7662
Epoch 12, accuracy: 0.6848
Epoch 12, Train Loss: 0.6784, Val Loss: 0.7662
batch size: (892, 892)
✅ Epoch 13: New best model saved with val_loss = 0.7024
Epoch 13, accuracy: 0.7088
batch size: (895, 895)
Epoch 14, accuracy: 0.6941
Epoch 14, Train Loss: 0.5191, Val Loss: 0.8032
batch size: (896, 896)
Epoch 15, accuracy: 0.6953
batch size: (896, 896)
Epoch 16, accuracy: 0.6773
Epoch 16, Train Loss: 0.3237, Val Loss: 1.0514
batch size: (904, 904)
Epoch 17, accuracy: 0.7309
batch size: (911, 911)
Epoch 18, accuracy: 0.7022
Epoch 18, Train Loss: 0.3124, Val Loss: 0.9270
batch size: (906, 906)
Epoch 19, accuracy: 0.6835
batch size: (901, 901)
Epoch 20, accuracy: 0.6860
Epoch 20, Train Loss: 0.2405, Val Loss: 0.9700
batch size: (900, 900)
Epoch 21, accuracy: 0.6916
batch size: (895, 895)
Epoch 22, accuracy: 0.6943
Epoch 22, Train Loss: 0.1463, Val Loss: 0.9162
batch size: (905, 905)
Epoch 23, accuracy: 0.6979
batch size: (891, 891)
Epoch 24, accuracy: 0.7039
Epoch 24, Train Loss: 0.0882, Val Loss: 0.8301
batch size: (892, 892)
Epoch 25, accuracy: 0.7072
batch size: (888, 888)
Epoch 26, accuracy: 0.7074
Epoch 26, Train Loss: 0.1564, Val Loss: 0.8236
batch size: (898, 898)
Epoch 27, accuracy: 0.7065
batch size: (882, 882)
Epoch 28, accuracy: 0.7071
Epoch 28, Train Loss: 0.1624, Val Loss: 0.8088
batch size: (893, 893)
Epoch 29, accuracy: 0.7067
batch size: (884, 884)
Epoch 30, accuracy: 0.7049
Epoch 30, Train Loss: 0.1310, Val Loss: 0.8377
batch size: (909, 909)
Epoch 31, accuracy: 0.7070
batch size: (911, 911)
Epoch 32, accuracy: 0.7063
Epoch 32, Train Loss: 0.0810, Val Loss: 0.8114
batch size: (899, 899)
Epoch 33, accuracy: 0.7083
batch size: (893, 893)
Epoch 34, accuracy: 0.7067
Epoch 34, Train Loss: 0.0794, Val Loss: 0.8384
batch size: (918, 918)
Epoch 35, accuracy: 0.7072
batch size: (890, 890)
Epoch 36, accuracy: 0.7055
Epoch 36, Train Loss: 0.1870, Val Loss: 0.8604
batch size: (897, 897)
Epoch 37, accuracy: 0.7077
batch size: (905, 905)
Epoch 38, accuracy: 0.7065
Epoch 38, Train Loss: 0.0568, Val Loss: 0.7937
batch size: (909, 909)
Epoch 39, accuracy: 0.7083
batch size: (905, 905)
Epoch 40, accuracy: 0.7059
Epoch 40, Train Loss: 0.1280, Val Loss: 0.8285
batch size: (892, 892)
Epoch 41, accuracy: 0.7078
batch size: (904, 904)
Epoch 42, accuracy: 0.7057
Epoch 42, Train Loss: 0.1883, Val Loss: 0.8338
batch size: (905, 905)
Epoch 43, accuracy: 0.7078
batch size: (914, 914)
Epoch 44, accuracy: 0.7067
Epoch 44, Train Loss: 0.0765, Val Loss: 0.8469
batch size: (898, 898)
Epoch 45, accuracy: 0.7053
batch size: (884, 884)
Epoch 46, accuracy: 0.7068
Epoch 46, Train Loss: 0.1173, Val Loss: 0.8328
batch size: (904, 904)
Epoch 47, accuracy: 0.7058
batch size: (888, 888)
Epoch 48, accuracy: 0.7057
Epoch 48, Train Loss: 0.1530, Val Loss: 0.8693
batch size: (899, 899)
Epoch 49, accuracy: 0.7077
Loaded best model with val_loss = 0.7023716568946838
test :accuracy 0.7102, f1_macro: 0.7043, f1_micro: 0.7102, auc: 0.8537
Training GAT with 32 layers...
可训练参数: 4666255_GAT
不可训练参数: 0
batch size: (901, 901)
✅ Epoch 0: New best model saved with val_loss = 1.1003
Epoch 0, accuracy: 0.4304
Epoch 0, Train Loss: 1.0989, Val Loss: 1.1003
batch size: (909, 909)
✅ Epoch 1: New best model saved with val_loss = 1.0872
Epoch 1, accuracy: 0.4060
batch size: (890, 890)
Epoch 2, accuracy: 0.1680
Epoch 2, Train Loss: 1.0977, Val Loss: 1.1218
batch size: (897, 897)
✅ Epoch 3: New best model saved with val_loss = 1.0723
Epoch 3, accuracy: 0.4302
batch size: (905, 905)
✅ Epoch 4: New best model saved with val_loss = 1.0688
Epoch 4, accuracy: 0.4300
Epoch 4, Train Loss: 1.1092, Val Loss: 1.0688
batch size: (898, 898)
Epoch 5, accuracy: 0.4329
batch size: (904, 904)
Epoch 6, accuracy: 0.4314
Epoch 6, Train Loss: 1.1076, Val Loss: 1.0861
batch size: (888, 888)
Epoch 7, accuracy: 0.4324
batch size: (892, 892)
Epoch 8, accuracy: 0.1662
Epoch 8, Train Loss: 1.1021, Val Loss: 1.1061
batch size: (914, 914)
Epoch 9, accuracy: 0.1688
batch size: (893, 893)
Epoch 10, accuracy: 0.1676
Epoch 10, Train Loss: 1.0971, Val Loss: 1.1148
batch size: (886, 886)
Epoch 11, accuracy: 0.1672
batch size: (912, 912)
Epoch 12, accuracy: 0.1659
Epoch 12, Train Loss: 1.1003, Val Loss: 1.1144
batch size: (912, 912)
Epoch 13, accuracy: 0.1648
batch size: (903, 903)
Epoch 14, accuracy: 0.1673
Epoch 14, Train Loss: 1.0976, Val Loss: 1.1135
batch size: (892, 892)
Epoch 15, accuracy: 0.1664
batch size: (923, 923)
Epoch 16, accuracy: 0.1677
Epoch 16, Train Loss: 1.0996, Val Loss: 1.1122
batch size: (897, 897)
Epoch 17, accuracy: 0.1674
batch size: (926, 926)
Epoch 18, accuracy: 0.1670
Epoch 18, Train Loss: 1.1039, Val Loss: 1.1120
batch size: (917, 917)
Epoch 19, accuracy: 0.1671
batch size: (904, 904)
Epoch 20, accuracy: 0.1655
Epoch 20, Train Loss: 1.0948, Val Loss: 1.1118
batch size: (906, 906)
Epoch 21, accuracy: 0.1683
batch size: (915, 915)
Epoch 22, accuracy: 0.1674
Epoch 22, Train Loss: 1.0981, Val Loss: 1.1117
/root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
/root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
batch size: (901, 901)
Epoch 23, accuracy: 0.1685
batch size: (897, 897)
Epoch 24, accuracy: 0.1652
Epoch 24, Train Loss: 1.1001, Val Loss: 1.1117
batch size: (899, 899)
Epoch 25, accuracy: 0.1687
batch size: (919, 919)
Epoch 26, accuracy: 0.1684
Epoch 26, Train Loss: 1.0980, Val Loss: 1.1116
batch size: (907, 907)
Epoch 27, accuracy: 0.1696
batch size: (909, 909)
Epoch 28, accuracy: 0.1677
Epoch 28, Train Loss: 1.1020, Val Loss: 1.1116
batch size: (900, 900)
Epoch 29, accuracy: 0.1711
batch size: (900, 900)
Epoch 30, accuracy: 0.1664
Epoch 30, Train Loss: 1.0989, Val Loss: 1.1116
batch size: (892, 892)
Epoch 31, accuracy: 0.1677
batch size: (905, 905)
Epoch 32, accuracy: 0.1657
Epoch 32, Train Loss: 1.0969, Val Loss: 1.1116
batch size: (907, 907)
Epoch 33, accuracy: 0.1685
batch size: (897, 897)
Epoch 34, accuracy: 0.1667
Epoch 34, Train Loss: 1.0974, Val Loss: 1.1116
batch size: (903, 903)
Epoch 35, accuracy: 0.1670
batch size: (915, 915)
Epoch 36, accuracy: 0.1672
Epoch 36, Train Loss: 1.1029, Val Loss: 1.1116
batch size: (883, 883)
Epoch 37, accuracy: 0.1700
batch size: (910, 910)
Epoch 38, accuracy: 0.1646
Epoch 38, Train Loss: 1.1006, Val Loss: 1.1116
batch size: (904, 904)
Epoch 39, accuracy: 0.1658
batch size: (905, 905)
Epoch 40, accuracy: 0.1687
Epoch 40, Train Loss: 1.1053, Val Loss: 1.1116
batch size: (917, 917)
Epoch 41, accuracy: 0.1660
batch size: (910, 910)
Epoch 42, accuracy: 0.1702
Epoch 42, Train Loss: 1.0964, Val Loss: 1.1116
batch size: (889, 889)
Epoch 43, accuracy: 0.1657
batch size: (892, 892)
Epoch 44, accuracy: 0.1689
Epoch 44, Train Loss: 1.0959, Val Loss: 1.1116
batch size: (894, 894)
Epoch 45, accuracy: 0.1678
batch size: (887, 887)
Epoch 46, accuracy: 0.1684
Epoch 46, Train Loss: 1.0988, Val Loss: 1.1116
batch size: (889, 889)
Epoch 47, accuracy: 0.1667
batch size: (888, 888)
Epoch 48, accuracy: 0.1655
Epoch 48, Train Loss: 1.0967, Val Loss: 1.1116
batch size: (898, 898)
Epoch 49, accuracy: 0.1661
Loaded best model with val_loss = 1.0687743425369263
test :accuracy 0.4302, f1_macro: 0.2005, f1_micro: 0.4302, auc: 0.4992
Training JKNet with 2 layers...
可训练参数: 391942_JKNet
不可训练参数: 0
batch size: (908, 908)
✅ Epoch 0: New best model saved with val_loss = 1.0842
Epoch 0, accuracy: 0.4310
Epoch 0, Train Loss: 1.3372, Val Loss: 1.0842
batch size: (909, 909)
✅ Epoch 1: New best model saved with val_loss = 1.0810
Epoch 1, accuracy: 0.4353
batch size: (898, 898)
Epoch 2, accuracy: 0.4510
Epoch 2, Train Loss: 0.1684, Val Loss: 1.0829
batch size: (906, 906)
Epoch 3, accuracy: 0.4179
batch size: (910, 910)
Epoch 4, accuracy: 0.4185
Epoch 4, Train Loss: 0.0197, Val Loss: 1.0845
batch size: (919, 919)
Epoch 5, accuracy: 0.4102
batch size: (887, 887)
Epoch 6, accuracy: 0.4122
Epoch 6, Train Loss: 0.0207, Val Loss: 1.0889
batch size: (896, 896)
Epoch 7, accuracy: 0.4140
batch size: (909, 909)
Epoch 8, accuracy: 0.4097
Epoch 8, Train Loss: 0.0012, Val Loss: 1.0886
batch size: (889, 889)
Epoch 9, accuracy: 0.4024
batch size: (902, 902)
Epoch 10, accuracy: 0.3966
Epoch 10, Train Loss: 0.0008, Val Loss: 1.0869
batch size: (907, 907)
Epoch 11, accuracy: 0.3977
batch size: (900, 900)
Epoch 12, accuracy: 0.3981
Epoch 12, Train Loss: 0.0011, Val Loss: 1.0834
batch size: (897, 897)
Epoch 13, accuracy: 0.4015
batch size: (912, 912)
Epoch 14, accuracy: 0.3973
Epoch 14, Train Loss: 0.0005, Val Loss: 1.0836
batch size: (892, 892)
Epoch 15, accuracy: 0.3996
batch size: (903, 903)
Epoch 16, accuracy: 0.4026
Epoch 16, Train Loss: 0.0008, Val Loss: 1.0845
batch size: (888, 888)
Epoch 17, accuracy: 0.4030
batch size: (895, 895)
Epoch 18, accuracy: 0.4043
Epoch 18, Train Loss: 0.0004, Val Loss: 1.0862
batch size: (880, 880)
Epoch 19, accuracy: 0.4043
batch size: (908, 908)
Epoch 20, accuracy: 0.4055
Epoch 20, Train Loss: 0.0005, Val Loss: 1.0844
batch size: (900, 900)
Epoch 21, accuracy: 0.4019
batch size: (907, 907)
Epoch 22, accuracy: 0.4027
Epoch 22, Train Loss: 0.0009, Val Loss: 1.0842
batch size: (903, 903)
Epoch 23, accuracy: 0.4073
batch size: (909, 909)
Epoch 24, accuracy: 0.4095
Epoch 24, Train Loss: 0.0004, Val Loss: 1.0847
batch size: (888, 888)
Epoch 25, accuracy: 0.4019
batch size: (898, 898)
Epoch 26, accuracy: 0.4064
Epoch 26, Train Loss: 0.0004, Val Loss: 1.0818
batch size: (893, 893)
Epoch 27, accuracy: 0.4076
batch size: (910, 910)
Epoch 28, accuracy: 0.4069
Epoch 28, Train Loss: 0.0007, Val Loss: 1.0841
batch size: (896, 896)
Epoch 29, accuracy: 0.4106
batch size: (895, 895)
Epoch 30, accuracy: 0.4041
Epoch 30, Train Loss: 0.0003, Val Loss: 1.0817
batch size: (907, 907)
Epoch 31, accuracy: 0.4065
batch size: (903, 903)
Epoch 32, accuracy: 0.4091
Epoch 32, Train Loss: 0.0003, Val Loss: 1.0831
batch size: (891, 891)
Epoch 33, accuracy: 0.4063
batch size: (916, 916)
Epoch 34, accuracy: 0.4058
Epoch 34, Train Loss: 0.0007, Val Loss: 1.0832
batch size: (888, 888)
Epoch 35, accuracy: 0.4061
batch size: (888, 888)
Epoch 36, accuracy: 0.4094
Epoch 36, Train Loss: 0.0006, Val Loss: 1.0816
batch size: (899, 899)
Epoch 37, accuracy: 0.4138
batch size: (898, 898)
Epoch 38, accuracy: 0.4200
Epoch 38, Train Loss: 0.0161, Val Loss: 1.0821
batch size: (879, 879)
Epoch 39, accuracy: 0.4188
batch size: (899, 899)
✅ Epoch 40: New best model saved with val_loss = 1.0799
Epoch 40, accuracy: 0.4192
Epoch 40, Train Loss: 0.0013, Val Loss: 1.0799
batch size: (882, 882)
Epoch 41, accuracy: 0.4127
batch size: (903, 903)
Epoch 42, accuracy: 0.4145
Epoch 42, Train Loss: 0.0006, Val Loss: 1.0829
batch size: (885, 885)
Epoch 43, accuracy: 0.4246
batch size: (901, 901)
Epoch 44, accuracy: 0.4118
Epoch 44, Train Loss: 0.0004, Val Loss: 1.0811
batch size: (887, 887)
Epoch 45, accuracy: 0.4172
batch size: (899, 899)
Epoch 46, accuracy: 0.4159
Epoch 46, Train Loss: 0.0005, Val Loss: 1.0851
batch size: (896, 896)
Epoch 47, accuracy: 0.4180
batch size: (897, 897)
Epoch 48, accuracy: 0.4187
Epoch 48, Train Loss: 0.0004, Val Loss: 1.0862
batch size: (900, 900)
Epoch 49, accuracy: 0.4224
Loaded best model with val_loss = 1.079896092414856
test :accuracy 0.4180, f1_macro: 0.3279, f1_micro: 0.4180, auc: 0.7602
Training JKNet with 8 layers...
可训练参数: 1184518_JKNet
不可训练参数: 0
batch size: (886, 886)
✅ Epoch 0: New best model saved with val_loss = 1.1424
Epoch 0, accuracy: 0.4169
Epoch 0, Train Loss: 1.2094, Val Loss: 1.1424
batch size: (902, 902)
Epoch 1, accuracy: 0.2401
batch size: (892, 892)
Epoch 2, accuracy: 0.4279
Epoch 2, Train Loss: 1.5902, Val Loss: 1.1953
batch size: (902, 902)
✅ Epoch 3: New best model saved with val_loss = 1.0448
Epoch 3, accuracy: 0.4282
batch size: (901, 901)
Epoch 4, accuracy: 0.4120
Epoch 4, Train Loss: 0.4498, Val Loss: 1.0738
batch size: (917, 917)
Epoch 5, accuracy: 0.3728
batch size: (891, 891)
Epoch 6, accuracy: 0.3557
Epoch 6, Train Loss: 0.2918, Val Loss: 1.2664
batch size: (914, 914)
Epoch 7, accuracy: 0.3540
batch size: (888, 888)
Epoch 8, accuracy: 0.3559
Epoch 8, Train Loss: 0.1010, Val Loss: 1.2987
batch size: (907, 907)
Epoch 9, accuracy: 0.3545
batch size: (896, 896)
Epoch 10, accuracy: 0.3547
Epoch 10, Train Loss: 0.0411, Val Loss: 1.2403
batch size: (905, 905)
Epoch 11, accuracy: 0.3559
batch size: (900, 900)
Epoch 12, accuracy: 0.3573
Epoch 12, Train Loss: 0.0376, Val Loss: 1.2065
batch size: (896, 896)
Epoch 13, accuracy: 0.3567
batch size: (890, 890)
Epoch 14, accuracy: 0.3559
Epoch 14, Train Loss: 0.0447, Val Loss: 1.2017
batch size: (934, 934)
Epoch 15, accuracy: 0.3556
batch size: (906, 906)
Epoch 16, accuracy: 0.3586
Epoch 16, Train Loss: 0.0214, Val Loss: 1.1785
batch size: (888, 888)
Epoch 17, accuracy: 0.3540
batch size: (913, 913)
Epoch 18, accuracy: 0.3528
Epoch 18, Train Loss: 0.0179, Val Loss: 1.1966
batch size: (913, 913)
Epoch 19, accuracy: 0.3564
batch size: (905, 905)
Epoch 20, accuracy: 0.3550
Epoch 20, Train Loss: 0.0504, Val Loss: 1.2008
batch size: (877, 877)
Epoch 21, accuracy: 0.3542
batch size: (888, 888)
Epoch 22, accuracy: 0.3544
Epoch 22, Train Loss: 0.0560, Val Loss: 1.2163
batch size: (894, 894)
Epoch 23, accuracy: 0.3562
batch size: (908, 908)
Epoch 24, accuracy: 0.3561
Epoch 24, Train Loss: 0.0478, Val Loss: 1.1965
batch size: (884, 884)
/root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
/root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
Epoch 25, accuracy: 0.3586
batch size: (886, 886)
Epoch 26, accuracy: 0.3561
Epoch 26, Train Loss: 0.0320, Val Loss: 1.2307
batch size: (881, 881)
Epoch 27, accuracy: 0.3543
batch size: (900, 900)
Epoch 28, accuracy: 0.3557
Epoch 28, Train Loss: 0.0584, Val Loss: 1.2645
batch size: (906, 906)
Epoch 29, accuracy: 0.3539
batch size: (910, 910)
Epoch 30, accuracy: 0.3569
Epoch 30, Train Loss: 0.0221, Val Loss: 1.2221
batch size: (902, 902)
Epoch 31, accuracy: 0.3573
batch size: (886, 886)
Epoch 32, accuracy: 0.3569
Epoch 32, Train Loss: 0.0292, Val Loss: 1.1926
batch size: (909, 909)
Epoch 33, accuracy: 0.3515
batch size: (899, 899)
Epoch 34, accuracy: 0.3583
Epoch 34, Train Loss: 0.0333, Val Loss: 1.2295
batch size: (906, 906)
Epoch 35, accuracy: 0.3579
batch size: (901, 901)
Epoch 36, accuracy: 0.3559
Epoch 36, Train Loss: 0.0284, Val Loss: 1.1969
batch size: (892, 892)
Epoch 37, accuracy: 0.3555
batch size: (903, 903)
Epoch 38, accuracy: 0.3562
Epoch 38, Train Loss: 0.0205, Val Loss: 1.2056
batch size: (893, 893)
Epoch 39, accuracy: 0.3601
batch size: (909, 909)
Epoch 40, accuracy: 0.3551
Epoch 40, Train Loss: 0.0459, Val Loss: 1.2227
batch size: (889, 889)
Epoch 41, accuracy: 0.3530
batch size: (882, 882)
Epoch 42, accuracy: 0.3544
Epoch 42, Train Loss: 0.0739, Val Loss: 1.1983
batch size: (896, 896)
Epoch 43, accuracy: 0.3532
batch size: (898, 898)
Epoch 44, accuracy: 0.3592
Epoch 44, Train Loss: 0.0275, Val Loss: 1.2204
batch size: (936, 936)
Epoch 45, accuracy: 0.3584
batch size: (934, 934)
Epoch 46, accuracy: 0.3552
Epoch 46, Train Loss: 0.0333, Val Loss: 1.1863
batch size: (895, 895)
Epoch 47, accuracy: 0.3534
batch size: (905, 905)
Epoch 48, accuracy: 0.3576
Epoch 48, Train Loss: 0.0500, Val Loss: 1.2150
batch size: (900, 900)
Epoch 49, accuracy: 0.3581
Loaded best model with val_loss = 1.0448298454284668
test :accuracy 0.4318, f1_macro: 0.2010, f1_micro: 0.4318, auc: 0.7275
Training JKNet with 32 layers...
可训练参数: 4354822_JKNet
不可训练参数: 0
batch size: (887, 887)
✅ Epoch 0: New best model saved with val_loss = 2.6767
Epoch 0, accuracy: 0.1678
Epoch 0, Train Loss: 1.4827, Val Loss: 2.6767
batch size: (881, 881)
✅ Epoch 1: New best model saved with val_loss = 1.5190
Epoch 1, accuracy: 0.4001
batch size: (903, 903)
✅ Epoch 2: New best model saved with val_loss = 1.0656
Epoch 2, accuracy: 0.4286
Epoch 2, Train Loss: 5.2558, Val Loss: 1.0656
batch size: (888, 888)
Epoch 3, accuracy: 0.4395
batch size: (902, 902)
Epoch 4, accuracy: 0.4031
Epoch 4, Train Loss: 1.6850, Val Loss: 1.1137
batch size: (890, 890)
Epoch 5, accuracy: 0.3571
batch size: (888, 888)
Epoch 6, accuracy: 0.4059
Epoch 6, Train Loss: 2.3564, Val Loss: 1.1092
batch size: (915, 915)
Epoch 7, accuracy: 0.4030
batch size: (900, 900)
Epoch 8, accuracy: 0.4026
Epoch 8, Train Loss: 0.6068, Val Loss: 1.0994
batch size: (914, 914)
Epoch 9, accuracy: 0.4029
batch size: (901, 901)
Epoch 10, accuracy: 0.4019
Epoch 10, Train Loss: 0.3264, Val Loss: 1.0973
batch size: (886, 886)
Epoch 11, accuracy: 0.3993
batch size: (888, 888)
Epoch 12, accuracy: 0.4053
Epoch 12, Train Loss: 0.2034, Val Loss: 1.0983
batch size: (896, 896)
Epoch 13, accuracy: 0.3982
batch size: (911, 911)
Epoch 14, accuracy: 0.4057
Epoch 14, Train Loss: 0.3062, Val Loss: 1.0967
batch size: (906, 906)
Epoch 15, accuracy: 0.4025
batch size: (913, 913)
Epoch 16, accuracy: 0.4028
Epoch 16, Train Loss: 0.2253, Val Loss: 1.0975
batch size: (885, 885)
Epoch 17, accuracy: 0.3979
batch size: (890, 890)
Epoch 18, accuracy: 0.4000
Epoch 18, Train Loss: 0.2404, Val Loss: 1.0972
batch size: (897, 897)
Epoch 19, accuracy: 0.4015
batch size: (879, 879)
Epoch 20, accuracy: 0.4050
Epoch 20, Train Loss: 0.2239, Val Loss: 1.0966
batch size: (906, 906)
Epoch 21, accuracy: 0.4029
batch size: (901, 901)
Epoch 22, accuracy: 0.4010
Epoch 22, Train Loss: 0.1740, Val Loss: 1.0967
batch size: (895, 895)
Epoch 23, accuracy: 0.4062
batch size: (901, 901)
Epoch 24, accuracy: 0.4012
Epoch 24, Train Loss: 0.2297, Val Loss: 1.0964
batch size: (893, 893)
Epoch 25, accuracy: 0.4028
batch size: (891, 891)
Epoch 26, accuracy: 0.4056
Epoch 26, Train Loss: 0.3455, Val Loss: 1.0962
batch size: (900, 900)
Epoch 27, accuracy: 0.4007
batch size: (888, 888)
Epoch 28, accuracy: 0.4006
Epoch 28, Train Loss: 0.1918, Val Loss: 1.0963
batch size: (906, 906)
Epoch 29, accuracy: 0.4029
batch size: (916, 916)
Epoch 30, accuracy: 0.4020
Epoch 30, Train Loss: 0.2240, Val Loss: 1.0962
batch size: (906, 906)
Epoch 31, accuracy: 0.4013
batch size: (900, 900)
Epoch 32, accuracy: 0.3979
Epoch 32, Train Loss: 0.2965, Val Loss: 1.0962
batch size: (909, 909)
Epoch 33, accuracy: 0.4003
batch size: (894, 894)
Epoch 34, accuracy: 0.3989
Epoch 34, Train Loss: 0.1828, Val Loss: 1.0952
batch size: (877, 877)
Epoch 35, accuracy: 0.4014
batch size: (895, 895)
Epoch 36, accuracy: 0.4030
Epoch 36, Train Loss: 0.1912, Val Loss: 1.0969
batch size: (893, 893)
Epoch 37, accuracy: 0.4015
batch size: (899, 899)
Epoch 38, accuracy: 0.4029
Epoch 38, Train Loss: 0.2160, Val Loss: 1.0969
batch size: (906, 906)
Epoch 39, accuracy: 0.4015
batch size: (912, 912)
Epoch 40, accuracy: 0.4035
Epoch 40, Train Loss: 0.1821, Val Loss: 1.0953
batch size: (876, 876)
Epoch 41, accuracy: 0.4029
batch size: (891, 891)
Epoch 42, accuracy: 0.4024
Epoch 42, Train Loss: 0.1369, Val Loss: 1.0963
batch size: (885, 885)
Epoch 43, accuracy: 0.4023
batch size: (902, 902)
Epoch 44, accuracy: 0.3987
Epoch 44, Train Loss: 0.3379, Val Loss: 1.0961
batch size: (883, 883)
Epoch 45, accuracy: 0.3999
batch size: (897, 897)
Epoch 46, accuracy: 0.4045
Epoch 46, Train Loss: 0.2980, Val Loss: 1.0968
batch size: (921, 921)
Epoch 47, accuracy: 0.4043
batch size: (898, 898)
Epoch 48, accuracy: 0.3997
Epoch 48, Train Loss: 0.6470, Val Loss: 1.0967
batch size: (899, 899)
Epoch 49, accuracy: 0.4027
Loaded best model with val_loss = 1.0656324625015259
test :accuracy 0.4292, f1_macro: 0.2002, f1_micro: 0.4292, auc: 0.6179
Training resGCN with 2 layers...
可训练参数: 132626_resGCN
不可训练参数: 0
batch size: (893, 893)
✅ Epoch 0: New best model saved with val_loss = 1.0877
Epoch 0, accuracy: 0.4036
Epoch 0, Train Loss: 1.0999, Val Loss: 1.0877
batch size: (904, 904)
✅ Epoch 1: New best model saved with val_loss = 1.0807
Epoch 1, accuracy: 0.4695
batch size: (879, 879)
✅ Epoch 2: New best model saved with val_loss = 1.0666
Epoch 2, accuracy: 0.4796
Epoch 2, Train Loss: 1.0819, Val Loss: 1.0666
batch size: (899, 899)
✅ Epoch 3: New best model saved with val_loss = 1.0521
Epoch 3, accuracy: 0.4472
batch size: (891, 891)
✅ Epoch 4: New best model saved with val_loss = 1.0352
Epoch 4, accuracy: 0.4328
Epoch 4, Train Loss: 1.0543, Val Loss: 1.0352
batch size: (909, 909)
✅ Epoch 5: New best model saved with val_loss = 1.0184
Epoch 5, accuracy: 0.4302
batch size: (914, 914)
✅ Epoch 6: New best model saved with val_loss = 1.0032
Epoch 6, accuracy: 0.4445
Epoch 6, Train Loss: 1.0280, Val Loss: 1.0032
batch size: (904, 904)
✅ Epoch 7: New best model saved with val_loss = 0.9879
Epoch 7, accuracy: 0.4862
batch size: (900, 900)
✅ Epoch 8: New best model saved with val_loss = 0.9758
Epoch 8, accuracy: 0.5301
Epoch 8, Train Loss: 0.9996, Val Loss: 0.9758
batch size: (919, 919)
✅ Epoch 9: New best model saved with val_loss = 0.9615
Epoch 9, accuracy: 0.5551
batch size: (893, 893)
✅ Epoch 10: New best model saved with val_loss = 0.9472
Epoch 10, accuracy: 0.5669
Epoch 10, Train Loss: 0.9496, Val Loss: 0.9472
batch size: (888, 888)
✅ Epoch 11: New best model saved with val_loss = 0.9328
Epoch 11, accuracy: 0.5660
batch size: (913, 913)
✅ Epoch 12: New best model saved with val_loss = 0.9187
Epoch 12, accuracy: 0.5677
Epoch 12, Train Loss: 0.9462, Val Loss: 0.9187
batch size: (909, 909)
✅ Epoch 13: New best model saved with val_loss = 0.9078
Epoch 13, accuracy: 0.5652
batch size: (884, 884)
✅ Epoch 14: New best model saved with val_loss = 0.8976
Epoch 14, accuracy: 0.5741
Epoch 14, Train Loss: 0.9358, Val Loss: 0.8976
batch size: (902, 902)
✅ Epoch 15: New best model saved with val_loss = 0.8859
Epoch 15, accuracy: 0.5984
batch size: (905, 905)
/root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
/root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
✅ Epoch 16: New best model saved with val_loss = 0.8787
Epoch 16, accuracy: 0.6230
Epoch 16, Train Loss: 0.8701, Val Loss: 0.8787
batch size: (895, 895)
✅ Epoch 17: New best model saved with val_loss = 0.8641
Epoch 17, accuracy: 0.6483
batch size: (912, 912)
✅ Epoch 18: New best model saved with val_loss = 0.8585
Epoch 18, accuracy: 0.6591
Epoch 18, Train Loss: 0.8137, Val Loss: 0.8585
batch size: (907, 907)
✅ Epoch 19: New best model saved with val_loss = 0.8512
Epoch 19, accuracy: 0.6676
batch size: (904, 904)
✅ Epoch 20: New best model saved with val_loss = 0.8477
Epoch 20, accuracy: 0.6725
Epoch 20, Train Loss: 0.8178, Val Loss: 0.8477
batch size: (925, 925)
✅ Epoch 21: New best model saved with val_loss = 0.8387
Epoch 21, accuracy: 0.6719
batch size: (901, 901)
✅ Epoch 22: New best model saved with val_loss = 0.8329
Epoch 22, accuracy: 0.6695
Epoch 22, Train Loss: 0.7839, Val Loss: 0.8329
batch size: (906, 906)
✅ Epoch 23: New best model saved with val_loss = 0.8235
Epoch 23, accuracy: 0.6689
batch size: (917, 917)
Epoch 24, accuracy: 0.6711
Epoch 24, Train Loss: 0.7856, Val Loss: 0.8238
batch size: (928, 928)
✅ Epoch 25: New best model saved with val_loss = 0.8208
Epoch 25, accuracy: 0.6727
batch size: (906, 906)
✅ Epoch 26: New best model saved with val_loss = 0.8096
Epoch 26, accuracy: 0.6743
Epoch 26, Train Loss: 0.7190, Val Loss: 0.8096
batch size: (920, 920)
Epoch 27, accuracy: 0.6746
batch size: (894, 894)
✅ Epoch 28: New best model saved with val_loss = 0.8053
Epoch 28, accuracy: 0.6769
Epoch 28, Train Loss: 0.7158, Val Loss: 0.8053
batch size: (900, 900)
✅ Epoch 29: New best model saved with val_loss = 0.7936
Epoch 29, accuracy: 0.6752
batch size: (901, 901)
Epoch 30, accuracy: 0.6785
Epoch 30, Train Loss: 0.6923, Val Loss: 0.7946
batch size: (897, 897)
✅ Epoch 31: New best model saved with val_loss = 0.7860
Epoch 31, accuracy: 0.6804
batch size: (901, 901)
Epoch 32, accuracy: 0.6810
Epoch 32, Train Loss: 0.6817, Val Loss: 0.7916
batch size: (911, 911)
✅ Epoch 33: New best model saved with val_loss = 0.7810
Epoch 33, accuracy: 0.6742
batch size: (901, 901)
Epoch 34, accuracy: 0.6826
Epoch 34, Train Loss: 0.7066, Val Loss: 0.7835
batch size: (910, 910)
✅ Epoch 35: New best model saved with val_loss = 0.7630
Epoch 35, accuracy: 0.6868
batch size: (893, 893)
Epoch 36, accuracy: 0.6896
Epoch 36, Train Loss: 0.6361, Val Loss: 0.7682
batch size: (922, 922)
✅ Epoch 37: New best model saved with val_loss = 0.7550
Epoch 37, accuracy: 0.6892
batch size: (896, 896)
Epoch 38, accuracy: 0.6889
Epoch 38, Train Loss: 0.5861, Val Loss: 0.7574
batch size: (896, 896)
Epoch 39, accuracy: 0.6839
batch size: (912, 912)
✅ Epoch 40: New best model saved with val_loss = 0.7471
Epoch 40, accuracy: 0.6860
Epoch 40, Train Loss: 0.5984, Val Loss: 0.7471
batch size: (897, 897)
✅ Epoch 41: New best model saved with val_loss = 0.7397
Epoch 41, accuracy: 0.6950
batch size: (906, 906)
✅ Epoch 42: New best model saved with val_loss = 0.7341
Epoch 42, accuracy: 0.7016
Epoch 42, Train Loss: 0.6280, Val Loss: 0.7341
batch size: (907, 907)
Epoch 43, accuracy: 0.7008
batch size: (888, 888)
✅ Epoch 44: New best model saved with val_loss = 0.7302
Epoch 44, accuracy: 0.7041
Epoch 44, Train Loss: 0.5756, Val Loss: 0.7302
batch size: (897, 897)
✅ Epoch 45: New best model saved with val_loss = 0.7286
Epoch 45, accuracy: 0.7056
batch size: (897, 897)
Epoch 46, accuracy: 0.6982
Epoch 46, Train Loss: 0.5766, Val Loss: 0.7334
batch size: (899, 899)
Epoch 47, accuracy: 0.7016
batch size: (892, 892)
✅ Epoch 48: New best model saved with val_loss = 0.7246
Epoch 48, accuracy: 0.7068
Epoch 48, Train Loss: 0.5091, Val Loss: 0.7246
batch size: (903, 903)
✅ Epoch 49: New best model saved with val_loss = 0.7205
Epoch 49, accuracy: 0.7067
Loaded best model with val_loss = 0.7204803228378296
test :accuracy 0.7063, f1_macro: 0.6889, f1_micro: 0.7063, auc: 0.8463
Training resGCN with 8 layers...
可训练参数: 531986_resGCN
不可训练参数: 0
batch size: (900, 900)
✅ Epoch 0: New best model saved with val_loss = 1.0684
Epoch 0, accuracy: 0.4036
Epoch 0, Train Loss: 1.0976, Val Loss: 1.0684
batch size: (902, 902)
Epoch 1, accuracy: 0.1690
batch size: (904, 904)
Epoch 2, accuracy: 0.1706
Epoch 2, Train Loss: 1.0880, Val Loss: 1.1338
batch size: (904, 904)
Epoch 3, accuracy: 0.1657
batch size: (910, 910)
Epoch 4, accuracy: 0.4304
Epoch 4, Train Loss: 1.1013, Val Loss: 1.0978
batch size: (905, 905)
Epoch 5, accuracy: 0.4277
batch size: (897, 897)
Epoch 6, accuracy: 0.4320
Epoch 6, Train Loss: 1.0987, Val Loss: 1.0972
batch size: (887, 887)
Epoch 7, accuracy: 0.4350
batch size: (909, 909)
Epoch 8, accuracy: 0.4295
Epoch 8, Train Loss: 1.0987, Val Loss: 1.0971
batch size: (900, 900)
Epoch 9, accuracy: 0.4297
batch size: (891, 891)
Epoch 10, accuracy: 0.4285
Epoch 10, Train Loss: 1.0987, Val Loss: 1.0971
batch size: (888, 888)
Epoch 11, accuracy: 0.4272
batch size: (893, 893)
Epoch 12, accuracy: 0.4302
Epoch 12, Train Loss: 1.0987, Val Loss: 1.0971
batch size: (887, 887)
Epoch 13, accuracy: 0.4290
batch size: (922, 922)
Epoch 14, accuracy: 0.4277
Epoch 14, Train Loss: 1.0987, Val Loss: 1.0971
batch size: (923, 923)
Epoch 15, accuracy: 0.4304
batch size: (890, 890)
Epoch 16, accuracy: 0.4317
Epoch 16, Train Loss: 1.0987, Val Loss: 1.0971
batch size: (887, 887)
Epoch 17, accuracy: 0.4305
batch size: (894, 894)
Epoch 18, accuracy: 0.4292
Epoch 18, Train Loss: 1.0987, Val Loss: 1.0971
batch size: (912, 912)
Epoch 19, accuracy: 0.4340
batch size: (908, 908)
Epoch 20, accuracy: 0.4298
Epoch 20, Train Loss: 1.0987, Val Loss: 1.0971
batch size: (883, 883)
Epoch 21, accuracy: 0.4281
batch size: (891, 891)
Epoch 22, accuracy: 0.4296
Epoch 22, Train Loss: 1.0987, Val Loss: 1.0971
batch size: (905, 905)
Epoch 23, accuracy: 0.4316
batch size: (903, 903)
Epoch 24, accuracy: 0.4290
Epoch 24, Train Loss: 1.0987, Val Loss: 1.0971
batch size: (902, 902)
Epoch 25, accuracy: 0.4312
batch size: (889, 889)
Epoch 26, accuracy: 0.4327
Epoch 26, Train Loss: 1.0987, Val Loss: 1.0971
batch size: (907, 907)
Epoch 27, accuracy: 0.4304
batch size: (908, 908)
Epoch 28, accuracy: 0.4290
Epoch 28, Train Loss: 1.0987, Val Loss: 1.0971
batch size: (905, 905)
Epoch 29, accuracy: 0.4267
batch size: (889, 889)
Epoch 30, accuracy: 0.4284
Epoch 30, Train Loss: 1.0987, Val Loss: 1.0971
batch size: (886, 886)
Epoch 31, accuracy: 0.4287
batch size: (900, 900)
Epoch 32, accuracy: 0.4288
Epoch 32, Train Loss: 1.0987, Val Loss: 1.0971
batch size: (893, 893)
Epoch 33, accuracy: 0.4324
batch size: (887, 887)
Epoch 34, accuracy: 0.4341
Epoch 34, Train Loss: 1.0987, Val Loss: 1.0971
batch size: (893, 893)
Epoch 35, accuracy: 0.4305
batch size: (910, 910)
Epoch 36, accuracy: 0.4271
Epoch 36, Train Loss: 1.0987, Val Loss: 1.0971
batch size: (908, 908)
Epoch 37, accuracy: 0.4298
batch size: (903, 903)
Epoch 38, accuracy: 0.4300
Epoch 38, Train Loss: 1.0987, Val Loss: 1.0971
batch size: (915, 915)
Epoch 39, accuracy: 0.4288
batch size: (906, 906)
Epoch 40, accuracy: 0.4287
Epoch 40, Train Loss: 1.0987, Val Loss: 1.0971
batch size: (879, 879)
Epoch 41, accuracy: 0.4323
batch size: (910, 910)
Epoch 42, accuracy: 0.4295
Epoch 42, Train Loss: 1.0987, Val Loss: 1.0971
batch size: (882, 882)
Epoch 43, accuracy: 0.4295
batch size: (902, 902)
Epoch 44, accuracy: 0.4328
Epoch 44, Train Loss: 1.0987, Val Loss: 1.0971
batch size: (882, 882)
Epoch 45, accuracy: 0.4290
batch size: (903, 903)
Epoch 46, accuracy: 0.4277
Epoch 46, Train Loss: 1.0987, Val Loss: 1.0971
batch size: (904, 904)
Epoch 47, accuracy: 0.4299
batch size: (911, 911)
Epoch 48, accuracy: 0.4343
Epoch 48, Train Loss: 1.0987, Val Loss: 1.0971
batch size: (915, 915)
Epoch 49, accuracy: 0.4307
Loaded best model with val_loss = 1.0684417486190796
test :accuracy 0.4038, f1_macro: 0.1918, f1_micro: 0.4038, auc: 0.4737
Training resGCN with 32 layers...
可训练参数: 2129426_resGCN
不可训练参数: 0
batch size: (905, 905)
✅ Epoch 0: New best model saved with val_loss = 1.0978
Epoch 0, accuracy: 0.4289
Epoch 0, Train Loss: 96247.1562, Val Loss: 1.0978
batch size: (901, 901)
✅ Epoch 1: New best model saved with val_loss = 1.0973
/root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
Epoch 1, accuracy: 0.4296
batch size: (898, 898)
✅ Epoch 2: New best model saved with val_loss = 1.0969
Epoch 2, accuracy: 0.4273
Epoch 2, Train Loss: 1.0986, Val Loss: 1.0969
batch size: (909, 909)
✅ Epoch 3: New best model saved with val_loss = 1.0965
Epoch 3, accuracy: 0.4325
batch size: (913, 913)
✅ Epoch 4: New best model saved with val_loss = 1.0963
Epoch 4, accuracy: 0.4335
Epoch 4, Train Loss: 1.0987, Val Loss: 1.0963
batch size: (902, 902)
✅ Epoch 5: New best model saved with val_loss = 1.0960
Epoch 5, accuracy: 0.4319
batch size: (896, 896)
✅ Epoch 6: New best model saved with val_loss = 1.0958
Epoch 6, accuracy: 0.4268
Epoch 6, Train Loss: 1.0987, Val Loss: 1.0958
batch size: (885, 885)
✅ Epoch 7: New best model saved with val_loss = 1.0957
Epoch 7, accuracy: 0.4311
batch size: (907, 907)
✅ Epoch 8: New best model saved with val_loss = 1.0955
Epoch 8, accuracy: 0.4329
Epoch 8, Train Loss: 1.0988, Val Loss: 1.0955
batch size: (894, 894)
✅ Epoch 9: New best model saved with val_loss = 1.0954
Epoch 9, accuracy: 0.4303
batch size: (910, 910)
✅ Epoch 10: New best model saved with val_loss = 1.0953
Epoch 10, accuracy: 0.4259
Epoch 10, Train Loss: 1.0988, Val Loss: 1.0953
batch size: (910, 910)
✅ Epoch 11: New best model saved with val_loss = 1.0952
Epoch 11, accuracy: 0.4314
batch size: (896, 896)
✅ Epoch 12: New best model saved with val_loss = 1.0951
Epoch 12, accuracy: 0.4322
Epoch 12, Train Loss: 1.0988, Val Loss: 1.0951
batch size: (898, 898)
✅ Epoch 13: New best model saved with val_loss = 1.0950
Epoch 13, accuracy: 0.4303
batch size: (886, 886)
✅ Epoch 14: New best model saved with val_loss = 1.0950
Epoch 14, accuracy: 0.4310
Epoch 14, Train Loss: 1.0988, Val Loss: 1.0950
batch size: (907, 907)
✅ Epoch 15: New best model saved with val_loss = 1.0949
Epoch 15, accuracy: 0.4302
batch size: (886, 886)
✅ Epoch 16: New best model saved with val_loss = 1.0949
Epoch 16, accuracy: 0.4262
Epoch 16, Train Loss: 1.0988, Val Loss: 1.0949
batch size: (897, 897)
✅ Epoch 17: New best model saved with val_loss = 1.0948
Epoch 17, accuracy: 0.4318
batch size: (910, 910)
✅ Epoch 18: New best model saved with val_loss = 1.0948
Epoch 18, accuracy: 0.4286
Epoch 18, Train Loss: 1.0988, Val Loss: 1.0948
batch size: (878, 878)
✅ Epoch 19: New best model saved with val_loss = 1.0948
Epoch 19, accuracy: 0.4311
batch size: (899, 899)
✅ Epoch 20: New best model saved with val_loss = 1.0948
Epoch 20, accuracy: 0.4295
Epoch 20, Train Loss: 1.0988, Val Loss: 1.0948
batch size: (889, 889)
Epoch 21, accuracy: 0.4321
batch size: (925, 925)
Epoch 22, accuracy: 0.4332
Epoch 22, Train Loss: 1.0988, Val Loss: 1.0948
batch size: (904, 904)
Epoch 23, accuracy: 0.4306
batch size: (875, 875)
Epoch 24, accuracy: 0.4337
Epoch 24, Train Loss: 1.0987, Val Loss: 1.0949
batch size: (899, 899)
Epoch 25, accuracy: 0.4281
batch size: (918, 918)
Epoch 26, accuracy: 0.4302
Epoch 26, Train Loss: 1.0987, Val Loss: 1.0949
batch size: (903, 903)
Epoch 27, accuracy: 0.4266
batch size: (898, 898)
Epoch 28, accuracy: 0.4283
Epoch 28, Train Loss: 1.0987, Val Loss: 1.0949
batch size: (905, 905)
Epoch 29, accuracy: 0.4314
batch size: (922, 922)
Epoch 30, accuracy: 0.4299
Epoch 30, Train Loss: 1.0987, Val Loss: 1.0949
batch size: (885, 885)
Epoch 31, accuracy: 0.4333
batch size: (918, 918)
Epoch 32, accuracy: 0.4304
Epoch 32, Train Loss: 1.0987, Val Loss: 1.0949
batch size: (898, 898)
Epoch 33, accuracy: 0.4332
batch size: (918, 918)
Epoch 34, accuracy: 0.4302
Epoch 34, Train Loss: 1.0987, Val Loss: 1.0949
batch size: (895, 895)
Epoch 35, accuracy: 0.4303
batch size: (893, 893)
Epoch 36, accuracy: 0.4343
Epoch 36, Train Loss: 1.0987, Val Loss: 1.0949
batch size: (900, 900)
Epoch 37, accuracy: 0.4280
batch size: (918, 918)
Epoch 38, accuracy: 0.4324
Epoch 38, Train Loss: 1.0987, Val Loss: 1.0949
batch size: (885, 885)
Epoch 39, accuracy: 0.4344
batch size: (906, 906)
Epoch 40, accuracy: 0.4285
Epoch 40, Train Loss: 1.0987, Val Loss: 1.0949
batch size: (900, 900)
Epoch 41, accuracy: 0.4278
batch size: (878, 878)
Epoch 42, accuracy: 0.4273
Epoch 42, Train Loss: 1.0987, Val Loss: 1.0949
batch size: (894, 894)
Epoch 43, accuracy: 0.4297
batch size: (896, 896)
Epoch 44, accuracy: 0.4333
Epoch 44, Train Loss: 1.0987, Val Loss: 1.0949
batch size: (901, 901)
Epoch 45, accuracy: 0.4300
batch size: (898, 898)
Epoch 46, accuracy: 0.4320
Epoch 46, Train Loss: 1.0987, Val Loss: 1.0949
batch size: (900, 900)
Epoch 47, accuracy: 0.4313
batch size: (904, 904)
Epoch 48, accuracy: 0.4317
Epoch 48, Train Loss: 1.0987, Val Loss: 1.0949
batch size: (903, 903)
Epoch 49, accuracy: 0.4287
Loaded best model with val_loss = 1.0948169231414795
test :accuracy 0.4313, f1_macro: 0.2009, f1_micro: 0.4313, auc: 0.5000
Training GINConv with 2 layers...
可训练参数: 99979_GINConv
不可训练参数: 0
batch size: (905, 905)
✅ Epoch 0: New best model saved with val_loss = 1.1194
Epoch 0, accuracy: 0.1652
Epoch 0, Train Loss: 1.3998, Val Loss: 1.1194
batch size: (870, 870)
✅ Epoch 1: New best model saved with val_loss = 1.0900
Epoch 1, accuracy: 0.2588
batch size: (896, 896)
✅ Epoch 2: New best model saved with val_loss = 1.0708
Epoch 2, accuracy: 0.2822
Epoch 2, Train Loss: 0.4694, Val Loss: 1.0708
batch size: (896, 896)
✅ Epoch 3: New best model saved with val_loss = 1.0564
Epoch 3, accuracy: 0.2792
batch size: (891, 891)
✅ Epoch 4: New best model saved with val_loss = 1.0406
Epoch 4, accuracy: 0.2756
Epoch 4, Train Loss: 0.2268, Val Loss: 1.0406
batch size: (917, 917)
✅ Epoch 5: New best model saved with val_loss = 1.0184
Epoch 5, accuracy: 0.3690
batch size: (906, 906)
✅ Epoch 6: New best model saved with val_loss = 0.9907
Epoch 6, accuracy: 0.5761
Epoch 6, Train Loss: 0.1683, Val Loss: 0.9907
batch size: (895, 895)
✅ Epoch 7: New best model saved with val_loss = 0.9599
Epoch 7, accuracy: 0.6971
batch size: (897, 897)
✅ Epoch 8: New best model saved with val_loss = 0.9222
Epoch 8, accuracy: 0.7363
Epoch 8, Train Loss: 0.0699, Val Loss: 0.9222
batch size: (899, 899)
✅ Epoch 9: New best model saved with val_loss = 0.8921
Epoch 9, accuracy: 0.7360
batch size: (886, 886)
✅ Epoch 10: New best model saved with val_loss = 0.8624
Epoch 10, accuracy: 0.7326
Epoch 10, Train Loss: 0.0515, Val Loss: 0.8624
batch size: (908, 908)
✅ Epoch 11: New best model saved with val_loss = 0.8457
Epoch 11, accuracy: 0.7361
batch size: (909, 909)
Epoch 12, accuracy: 0.7066
Epoch 12, Train Loss: 0.0267, Val Loss: 0.8509
batch size: (897, 897)
Epoch 13, accuracy: 0.6826
batch size: (885, 885)
Epoch 14, accuracy: 0.6678
Epoch 14, Train Loss: 0.0129, Val Loss: 0.8850
batch size: (891, 891)
Epoch 15, accuracy: 0.6589
batch size: (896, 896)
Epoch 16, accuracy: 0.6625
Epoch 16, Train Loss: 0.0173, Val Loss: 0.9055
batch size: (893, 893)
Epoch 17, accuracy: 0.6666
batch size: (903, 903)
Epoch 18, accuracy: 0.6748
Epoch 18, Train Loss: 0.0195, Val Loss: 0.9148
batch size: (905, 905)
Epoch 19, accuracy: 0.6831
batch size: (905, 905)
Epoch 20, accuracy: 0.6844
Epoch 20, Train Loss: 0.0270, Val Loss: 0.8657
batch size: (893, 893)
Epoch 21, accuracy: 0.6837
batch size: (887, 887)
✅ Epoch 22: New best model saved with val_loss = 0.8354
Epoch 22, accuracy: 0.6855
Epoch 22, Train Loss: 0.0040, Val Loss: 0.8354
batch size: (881, 881)
✅ Epoch 23: New best model saved with val_loss = 0.8095
Epoch 23, accuracy: 0.6832
batch size: (911, 911)
✅ Epoch 24: New best model saved with val_loss = 0.7905
Epoch 24, accuracy: 0.6788
Epoch 24, Train Loss: 0.0045, Val Loss: 0.7905
batch size: (899, 899)
✅ Epoch 25: New best model saved with val_loss = 0.7905
Epoch 25, accuracy: 0.6785
batch size: (884, 884)
✅ Epoch 26: New best model saved with val_loss = 0.7854
Epoch 26, accuracy: 0.6715
Epoch 26, Train Loss: 0.0025, Val Loss: 0.7854
batch size: (891, 891)
✅ Epoch 27: New best model saved with val_loss = 0.7744
Epoch 27, accuracy: 0.6651
batch size: (892, 892)
✅ Epoch 28: New best model saved with val_loss = 0.7722
Epoch 28, accuracy: 0.6603
Epoch 28, Train Loss: 0.0024, Val Loss: 0.7722
batch size: (908, 908)
✅ Epoch 29: New best model saved with val_loss = 0.7645
Epoch 29, accuracy: 0.6572
/root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
/root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
batch size: (904, 904)
Epoch 30, accuracy: 0.6548
Epoch 30, Train Loss: 0.0011, Val Loss: 0.7751
batch size: (897, 897)
✅ Epoch 31: New best model saved with val_loss = 0.7623
Epoch 31, accuracy: 0.6521
batch size: (900, 900)
Epoch 32, accuracy: 0.6505
Epoch 32, Train Loss: 0.0026, Val Loss: 0.7913
batch size: (887, 887)
✅ Epoch 33: New best model saved with val_loss = 0.7618
Epoch 33, accuracy: 0.6487
batch size: (890, 890)
Epoch 34, accuracy: 0.6475
Epoch 34, Train Loss: 0.0013, Val Loss: 0.7818
batch size: (896, 896)
Epoch 35, accuracy: 0.6473
batch size: (898, 898)
Epoch 36, accuracy: 0.6466
Epoch 36, Train Loss: 0.0006, Val Loss: 0.8009
batch size: (902, 902)
Epoch 37, accuracy: 0.6449
batch size: (892, 892)
Epoch 38, accuracy: 0.6465
Epoch 38, Train Loss: 0.0012, Val Loss: 0.8241
batch size: (882, 882)
Epoch 39, accuracy: 0.6457
batch size: (903, 903)
Epoch 40, accuracy: 0.6437
Epoch 40, Train Loss: 0.0010, Val Loss: 0.8870
batch size: (902, 902)
Epoch 41, accuracy: 0.6447
batch size: (900, 900)
Epoch 42, accuracy: 0.6442
Epoch 42, Train Loss: 0.0014, Val Loss: 0.9027
batch size: (902, 902)
Epoch 43, accuracy: 0.6403
batch size: (909, 909)
Epoch 44, accuracy: 0.6431
Epoch 44, Train Loss: 0.0014, Val Loss: 0.9377
batch size: (884, 884)
Epoch 45, accuracy: 0.6454
batch size: (901, 901)
Epoch 46, accuracy: 0.6451
Epoch 46, Train Loss: 0.0008, Val Loss: 0.9769
batch size: (896, 896)
Epoch 47, accuracy: 0.6423
batch size: (888, 888)
Epoch 48, accuracy: 0.6438
Epoch 48, Train Loss: 0.0010, Val Loss: 1.0426
batch size: (899, 899)
Epoch 49, accuracy: 0.6422
Loaded best model with val_loss = 0.7618400454521179
test :accuracy 0.6499, f1_macro: 0.6294, f1_micro: 0.6499, auc: 0.8384
Training GINConv with 8 layers...
可训练参数: 300427_GINConv
不可训练参数: 0
batch size: (899, 899)
✅ Epoch 0: New best model saved with val_loss = 1.1849
Epoch 0, accuracy: 0.2149
Epoch 0, Train Loss: 1.4664, Val Loss: 1.1849
batch size: (924, 924)
Epoch 1, accuracy: 0.2228
batch size: (882, 882)
Epoch 2, accuracy: 0.2133
Epoch 2, Train Loss: 1.4833, Val Loss: 1.4272
batch size: (909, 909)
Epoch 3, accuracy: 0.2127
batch size: (901, 901)
✅ Epoch 4: New best model saved with val_loss = 1.1269
Epoch 4, accuracy: 0.2177
Epoch 4, Train Loss: 1.1010, Val Loss: 1.1269
batch size: (883, 883)
✅ Epoch 5: New best model saved with val_loss = 1.1218
Epoch 5, accuracy: 0.2160
batch size: (892, 892)
Epoch 6, accuracy: 0.2140
Epoch 6, Train Loss: 1.0205, Val Loss: 1.1258
batch size: (907, 907)
Epoch 7, accuracy: 0.2150
batch size: (880, 880)
✅ Epoch 8: New best model saved with val_loss = 1.1151
Epoch 8, accuracy: 0.2124
Epoch 8, Train Loss: 0.9825, Val Loss: 1.1151
batch size: (910, 910)
Epoch 9, accuracy: 0.2112
batch size: (884, 884)
Epoch 10, accuracy: 0.2147
Epoch 10, Train Loss: 1.0131, Val Loss: 1.1204
batch size: (886, 886)
Epoch 11, accuracy: 0.2138
batch size: (922, 922)
Epoch 12, accuracy: 0.2138
Epoch 12, Train Loss: 0.9710, Val Loss: 1.1286
batch size: (892, 892)
Epoch 13, accuracy: 0.2149
batch size: (884, 884)
Epoch 14, accuracy: 0.2141
Epoch 14, Train Loss: 0.9316, Val Loss: 1.1193
batch size: (917, 917)
Epoch 15, accuracy: 0.2143
batch size: (892, 892)
Epoch 16, accuracy: 0.2144
Epoch 16, Train Loss: 0.9035, Val Loss: 1.1159
batch size: (884, 884)
Epoch 17, accuracy: 0.2127
batch size: (904, 904)
Epoch 18, accuracy: 0.2136
Epoch 18, Train Loss: 0.9240, Val Loss: 1.1195
batch size: (919, 919)
Epoch 19, accuracy: 0.2141
batch size: (899, 899)
Epoch 20, accuracy: 0.2138
Epoch 20, Train Loss: 0.9159, Val Loss: 1.1164
batch size: (901, 901)
Epoch 21, accuracy: 0.2147
batch size: (872, 872)
Epoch 22, accuracy: 0.2128
Epoch 22, Train Loss: 0.9231, Val Loss: 1.1152
batch size: (902, 902)
Epoch 23, accuracy: 0.2125
batch size: (908, 908)
✅ Epoch 24: New best model saved with val_loss = 1.1136
Epoch 24, accuracy: 0.2125
Epoch 24, Train Loss: 0.8994, Val Loss: 1.1136
batch size: (877, 877)
Epoch 25, accuracy: 0.2159
batch size: (902, 902)
Epoch 26, accuracy: 0.2126
Epoch 26, Train Loss: 0.9419, Val Loss: 1.1142
batch size: (899, 899)
Epoch 27, accuracy: 0.2133
batch size: (901, 901)
Epoch 28, accuracy: 0.2142
Epoch 28, Train Loss: 0.9128, Val Loss: 1.1146
batch size: (910, 910)
Epoch 29, accuracy: 0.2110
batch size: (890, 890)
Epoch 30, accuracy: 0.2160
Epoch 30, Train Loss: 0.8871, Val Loss: 1.1157
batch size: (896, 896)
Epoch 31, accuracy: 0.2161
batch size: (885, 885)
Epoch 32, accuracy: 0.2163
Epoch 32, Train Loss: 0.9007, Val Loss: 1.1205
batch size: (903, 903)
Epoch 33, accuracy: 0.2114
batch size: (900, 900)
Epoch 34, accuracy: 0.2128
Epoch 34, Train Loss: 0.8731, Val Loss: 1.1172
batch size: (895, 895)
Epoch 35, accuracy: 0.2155
batch size: (892, 892)
Epoch 36, accuracy: 0.2163
Epoch 36, Train Loss: 0.9206, Val Loss: 1.1155
batch size: (902, 902)
Epoch 37, accuracy: 0.2145
batch size: (896, 896)
Epoch 38, accuracy: 0.2135
Epoch 38, Train Loss: 0.9084, Val Loss: 1.1146
batch size: (888, 888)
Epoch 39, accuracy: 0.2162
batch size: (903, 903)
Epoch 40, accuracy: 0.2144
Epoch 40, Train Loss: 0.8827, Val Loss: 1.1146
batch size: (910, 910)
Epoch 41, accuracy: 0.2127
batch size: (888, 888)
Epoch 42, accuracy: 0.2136
Epoch 42, Train Loss: 0.8765, Val Loss: 1.1167
batch size: (909, 909)
Epoch 43, accuracy: 0.2122
batch size: (892, 892)
Epoch 44, accuracy: 0.2163
Epoch 44, Train Loss: 0.8572, Val Loss: 1.1183
batch size: (917, 917)
Epoch 45, accuracy: 0.2155
batch size: (896, 896)
Epoch 46, accuracy: 0.2125
Epoch 46, Train Loss: 0.8946, Val Loss: 1.1149
batch size: (889, 889)
Epoch 47, accuracy: 0.2140
batch size: (891, 891)
Epoch 48, accuracy: 0.2142
Epoch 48, Train Loss: 0.9339, Val Loss: 1.1165
batch size: (883, 883)
Epoch 49, accuracy: 0.2155
Loaded best model with val_loss = 1.1135838031768799
test :accuracy 0.2148, f1_macro: 0.1806, f1_micro: 0.2148, auc: 0.5027
Training GINConv with 32 layers...
可训练参数: 1102219_GINConv
不可训练参数: 0
batch size: (895, 895)
✅ Epoch 0: New best model saved with val_loss = 789.3588
Epoch 0, accuracy: 0.4212
Epoch 0, Train Loss: 1.6875, Val Loss: 789.3588
batch size: (883, 883)
✅ Epoch 1: New best model saved with val_loss = 621.6207
Epoch 1, accuracy: 0.4201
batch size: (901, 901)
✅ Epoch 2: New best model saved with val_loss = 22.6260
Epoch 2, accuracy: 0.1693
Epoch 2, Train Loss: 1.3216, Val Loss: 22.6260
batch size: (906, 906)
✅ Epoch 3: New best model saved with val_loss = 4.2341
Epoch 3, accuracy: 0.1680
batch size: (919, 919)
✅ Epoch 4: New best model saved with val_loss = 2.5985
Epoch 4, accuracy: 0.1671
Epoch 4, Train Loss: 1.1346, Val Loss: 2.5985
batch size: (924, 924)
✅ Epoch 5: New best model saved with val_loss = 2.0289
Epoch 5, accuracy: 0.1691
batch size: (894, 894)
Epoch 6, accuracy: 0.1698
Epoch 6, Train Loss: 1.0526, Val Loss: 2.3705
batch size: (905, 905)
✅ Epoch 7: New best model saved with val_loss = 1.1607
Epoch 7, accuracy: 0.1674
batch size: (892, 892)
Epoch 8, accuracy: 0.1653
Epoch 8, Train Loss: 1.1612, Val Loss: 1.2049
batch size: (902, 902)
Epoch 9, accuracy: 0.3708
batch size: (895, 895)
✅ Epoch 10: New best model saved with val_loss = 1.1245
Epoch 10, accuracy: 0.3745
Epoch 10, Train Loss: 1.2134, Val Loss: 1.1245
batch size: (915, 915)
✅ Epoch 11: New best model saved with val_loss = 1.1214
Epoch 11, accuracy: 0.3748
batch size: (898, 898)
Epoch 12, accuracy: 0.3746
Epoch 12, Train Loss: 1.1845, Val Loss: 1.1489
batch size: (902, 902)
Epoch 13, accuracy: 0.3774
batch size: (901, 901)
Epoch 14, accuracy: 0.3583
Epoch 14, Train Loss: 1.1031, Val Loss: 1.1400
batch size: (897, 897)
Epoch 15, accuracy: 0.3587
batch size: (908, 908)
Epoch 16, accuracy: 0.3582
Epoch 16, Train Loss: 1.1134, Val Loss: 1.1378
batch size: (897, 897)
✅ Epoch 17: New best model saved with val_loss = 1.1173
Epoch 17, accuracy: 0.3587
batch size: (889, 889)
✅ Epoch 18: New best model saved with val_loss = 1.1140
Epoch 18, accuracy: 0.3737
Epoch 18, Train Loss: 1.0719, Val Loss: 1.1140
batch size: (886, 886)
Epoch 19, accuracy: 0.3711
batch size: (891, 891)
Epoch 20, accuracy: 0.3757
Epoch 20, Train Loss: 1.0674, Val Loss: 1.1361
batch size: (898, 898)
/root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
/root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
Epoch 21, accuracy: 0.3745
batch size: (890, 890)
Epoch 22, accuracy: 0.3772
Epoch 22, Train Loss: 1.0818, Val Loss: 1.1175
batch size: (901, 901)
Epoch 23, accuracy: 0.3705
batch size: (912, 912)
Epoch 24, accuracy: 0.3715
Epoch 24, Train Loss: 1.0850, Val Loss: 1.1254
batch size: (881, 881)
Epoch 25, accuracy: 0.3726
batch size: (925, 925)
Epoch 26, accuracy: 0.3765
Epoch 26, Train Loss: 1.0632, Val Loss: 1.1229
batch size: (881, 881)
Epoch 27, accuracy: 0.3754
batch size: (905, 905)
Epoch 28, accuracy: 0.3777
Epoch 28, Train Loss: 1.0729, Val Loss: 1.1241
batch size: (911, 911)
Epoch 29, accuracy: 0.3753
batch size: (908, 908)
Epoch 30, accuracy: 0.3776
Epoch 30, Train Loss: 1.0977, Val Loss: 1.1293
batch size: (906, 906)
Epoch 31, accuracy: 0.3773
batch size: (898, 898)
Epoch 32, accuracy: 0.3734
Epoch 32, Train Loss: 1.0677, Val Loss: 1.1195
batch size: (896, 896)
Epoch 33, accuracy: 0.3745
batch size: (917, 917)
Epoch 34, accuracy: 0.3712
Epoch 34, Train Loss: 1.0928, Val Loss: 1.1248
batch size: (878, 878)
Epoch 35, accuracy: 0.3788
batch size: (920, 920)
Epoch 36, accuracy: 0.3704
Epoch 36, Train Loss: 1.0638, Val Loss: 1.1312
batch size: (911, 911)
Epoch 37, accuracy: 0.3792
batch size: (904, 904)
Epoch 38, accuracy: 0.3744
Epoch 38, Train Loss: 1.0699, Val Loss: 1.1223
batch size: (917, 917)
Epoch 39, accuracy: 0.3747
batch size: (908, 908)
Epoch 40, accuracy: 0.3740
Epoch 40, Train Loss: 1.0582, Val Loss: 1.1254
batch size: (891, 891)
Epoch 41, accuracy: 0.3749
batch size: (891, 891)
Epoch 42, accuracy: 0.3743
Epoch 42, Train Loss: 1.0669, Val Loss: 1.1371
batch size: (896, 896)
✅ Epoch 43: New best model saved with val_loss = 1.1099
Epoch 43, accuracy: 0.3732
batch size: (905, 905)
Epoch 44, accuracy: 0.3765
Epoch 44, Train Loss: 1.0574, Val Loss: 1.1168
batch size: (890, 890)
Epoch 45, accuracy: 0.3738
batch size: (915, 915)
Epoch 46, accuracy: 0.3738
Epoch 46, Train Loss: 1.0694, Val Loss: 1.1198
batch size: (904, 904)
Epoch 47, accuracy: 0.3701
batch size: (912, 912)
Epoch 48, accuracy: 0.3720
Epoch 48, Train Loss: 1.0718, Val Loss: 1.1119
batch size: (910, 910)
Epoch 49, accuracy: 0.3741
Loaded best model with val_loss = 1.1098687648773193
test :accuracy 0.3719, f1_macro: 0.2510, f1_micro: 0.3719, auc: 0.5010
Training mlp with 2 layers...
可训练参数: 83209_mlp
不可训练参数: 0
batch size: (886, 886)
✅ Epoch 0: New best model saved with val_loss = 1.1086
Epoch 0, accuracy: 0.1661
Epoch 0, Train Loss: 1.1012, Val Loss: 1.1086
batch size: (921, 921)
✅ Epoch 1: New best model saved with val_loss = 1.0973
Epoch 1, accuracy: 0.2213
batch size: (886, 886)
✅ Epoch 2: New best model saved with val_loss = 1.0863
Epoch 2, accuracy: 0.6738
Epoch 2, Train Loss: 1.0857, Val Loss: 1.0863
batch size: (900, 900)
✅ Epoch 3: New best model saved with val_loss = 1.0757
Epoch 3, accuracy: 0.6077
batch size: (896, 896)
✅ Epoch 4: New best model saved with val_loss = 1.0650
Epoch 4, accuracy: 0.6395
Epoch 4, Train Loss: 1.0536, Val Loss: 1.0650
batch size: (898, 898)
✅ Epoch 5: New best model saved with val_loss = 1.0525
Epoch 5, accuracy: 0.6773
batch size: (915, 915)
✅ Epoch 6: New best model saved with val_loss = 1.0367
Epoch 6, accuracy: 0.6937
Epoch 6, Train Loss: 0.9924, Val Loss: 1.0367
batch size: (896, 896)
✅ Epoch 7: New best model saved with val_loss = 1.0164
Epoch 7, accuracy: 0.6982
batch size: (891, 891)
✅ Epoch 8: New best model saved with val_loss = 0.9906
Epoch 8, accuracy: 0.7057
Epoch 8, Train Loss: 0.8981, Val Loss: 0.9906
batch size: (900, 900)
✅ Epoch 9: New best model saved with val_loss = 0.9598
Epoch 9, accuracy: 0.7053
batch size: (891, 891)
✅ Epoch 10: New best model saved with val_loss = 0.9252
Epoch 10, accuracy: 0.7071
Epoch 10, Train Loss: 0.7641, Val Loss: 0.9252
batch size: (898, 898)
✅ Epoch 11: New best model saved with val_loss = 0.8880
Epoch 11, accuracy: 0.7091
batch size: (890, 890)
✅ Epoch 12: New best model saved with val_loss = 0.8498
Epoch 12, accuracy: 0.7104
Epoch 12, Train Loss: 0.5915, Val Loss: 0.8498
batch size: (883, 883)
✅ Epoch 13: New best model saved with val_loss = 0.8128
Epoch 13, accuracy: 0.7141
batch size: (890, 890)
✅ Epoch 14: New best model saved with val_loss = 0.7793
Epoch 14, accuracy: 0.7145
Epoch 14, Train Loss: 0.3998, Val Loss: 0.7793
batch size: (906, 906)
✅ Epoch 15: New best model saved with val_loss = 0.7517
Epoch 15, accuracy: 0.7126
batch size: (902, 902)
✅ Epoch 16: New best model saved with val_loss = 0.7316
Epoch 16, accuracy: 0.7115
Epoch 16, Train Loss: 0.2265, Val Loss: 0.7316
batch size: (906, 906)
✅ Epoch 17: New best model saved with val_loss = 0.7202
Epoch 17, accuracy: 0.7129
batch size: (908, 908)
✅ Epoch 18: New best model saved with val_loss = 0.7168
Epoch 18, accuracy: 0.7144
Epoch 18, Train Loss: 0.1058, Val Loss: 0.7168
batch size: (912, 912)
Epoch 19, accuracy: 0.7132
batch size: (898, 898)
Epoch 20, accuracy: 0.7119
Epoch 20, Train Loss: 0.0418, Val Loss: 0.7298
batch size: (911, 911)
Epoch 21, accuracy: 0.7121
batch size: (896, 896)
Epoch 22, accuracy: 0.7113
Epoch 22, Train Loss: 0.0150, Val Loss: 0.7630
batch size: (871, 871)
Epoch 23, accuracy: 0.7106
batch size: (904, 904)
Epoch 24, accuracy: 0.7113
Epoch 24, Train Loss: 0.0054, Val Loss: 0.8069
batch size: (900, 900)
Epoch 25, accuracy: 0.7097
batch size: (896, 896)
Epoch 26, accuracy: 0.7095
Epoch 26, Train Loss: 0.0032, Val Loss: 0.8109
batch size: (907, 907)
Epoch 27, accuracy: 0.7133
batch size: (901, 901)
Epoch 28, accuracy: 0.7098
Epoch 28, Train Loss: 0.0030, Val Loss: 0.8139
batch size: (893, 893)
Epoch 29, accuracy: 0.7087
batch size: (877, 877)
Epoch 30, accuracy: 0.7112
Epoch 30, Train Loss: 0.0028, Val Loss: 0.8159
batch size: (892, 892)
Epoch 31, accuracy: 0.7091
batch size: (900, 900)
Epoch 32, accuracy: 0.7098
Epoch 32, Train Loss: 0.0027, Val Loss: 0.8160
batch size: (885, 885)
Epoch 33, accuracy: 0.7085
batch size: (893, 893)
Epoch 34, accuracy: 0.7107
Epoch 34, Train Loss: 0.0027, Val Loss: 0.8161
batch size: (919, 919)
Epoch 35, accuracy: 0.7098
batch size: (882, 882)
Epoch 36, accuracy: 0.7088
Epoch 36, Train Loss: 0.0027, Val Loss: 0.8161
batch size: (906, 906)
Epoch 37, accuracy: 0.7102
batch size: (891, 891)
Epoch 38, accuracy: 0.7098
Epoch 38, Train Loss: 0.0027, Val Loss: 0.8161
batch size: (922, 922)
Epoch 39, accuracy: 0.7092
batch size: (910, 910)
Epoch 40, accuracy: 0.7106
Epoch 40, Train Loss: 0.0027, Val Loss: 0.8161
batch size: (921, 921)
Epoch 41, accuracy: 0.7111
batch size: (888, 888)
Epoch 42, accuracy: 0.7098
Epoch 42, Train Loss: 0.0027, Val Loss: 0.8161
batch size: (905, 905)
Epoch 43, accuracy: 0.7098
batch size: (883, 883)
Epoch 44, accuracy: 0.7092
Epoch 44, Train Loss: 0.0027, Val Loss: 0.8161
batch size: (889, 889)
Epoch 45, accuracy: 0.7106
batch size: (889, 889)
Epoch 46, accuracy: 0.7125
Epoch 46, Train Loss: 0.0027, Val Loss: 0.8161
batch size: (885, 885)
Epoch 47, accuracy: 0.7129
batch size: (923, 923)
Epoch 48, accuracy: 0.7113
Epoch 48, Train Loss: 0.0027, Val Loss: 0.8161
batch size: (906, 906)
Epoch 49, accuracy: 0.7116
Loaded best model with val_loss = 0.7167749404907227
test :accuracy 0.7140, f1_macro: 0.7104, f1_micro: 0.7140, auc: 0.8571
Training mlp with 8 layers...
可训练参数: 184585_mlp
不可训练参数: 0
batch size: (907, 907)
✅ Epoch 0: New best model saved with val_loss = 1.1044
Epoch 0, accuracy: 0.1672
Epoch 0, Train Loss: 1.0987, Val Loss: 1.1044
batch size: (890, 890)
✅ Epoch 1: New best model saved with val_loss = 1.0992
Epoch 1, accuracy: 0.4026
batch size: (908, 908)
✅ Epoch 2: New best model saved with val_loss = 1.0964
Epoch 2, accuracy: 0.4329
Epoch 2, Train Loss: 1.0987, Val Loss: 1.0964
batch size: (884, 884)
✅ Epoch 3: New best model saved with val_loss = 1.0963
Epoch 3, accuracy: 0.4277
batch size: (896, 896)
Epoch 4, accuracy: 0.4310
Epoch 4, Train Loss: 1.0987, Val Loss: 1.0973
batch size: (893, 893)
Epoch 5, accuracy: 0.4296
batch size: (907, 907)
Epoch 6, accuracy: 0.1678
Epoch 6, Train Loss: 1.0986, Val Loss: 1.0990
batch size: (893, 893)
Epoch 7, accuracy: 0.4016
batch size: (906, 906)
Epoch 8, accuracy: 0.4038
/root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
/root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
Epoch 8, Train Loss: 1.0986, Val Loss: 1.0993
batch size: (881, 881)
Epoch 9, accuracy: 0.3995
batch size: (899, 899)
Epoch 10, accuracy: 0.4018
Epoch 10, Train Loss: 1.0986, Val Loss: 1.0993
batch size: (888, 888)
Epoch 11, accuracy: 0.3987
batch size: (893, 893)
Epoch 12, accuracy: 0.4026
Epoch 12, Train Loss: 1.0986, Val Loss: 1.0992
batch size: (887, 887)
Epoch 13, accuracy: 0.4084
batch size: (901, 901)
Epoch 14, accuracy: 0.4032
Epoch 14, Train Loss: 1.0986, Val Loss: 1.0991
batch size: (901, 901)
Epoch 15, accuracy: 0.3999
batch size: (917, 917)
Epoch 16, accuracy: 0.4031
Epoch 16, Train Loss: 1.0986, Val Loss: 1.0991
batch size: (910, 910)
Epoch 17, accuracy: 0.4033
batch size: (893, 893)
Epoch 18, accuracy: 0.4032
Epoch 18, Train Loss: 1.0986, Val Loss: 1.0991
batch size: (906, 906)
Epoch 19, accuracy: 0.3989
batch size: (892, 892)
Epoch 20, accuracy: 0.4055
Epoch 20, Train Loss: 1.0986, Val Loss: 1.0991
batch size: (897, 897)
Epoch 21, accuracy: 0.4004
batch size: (888, 888)
Epoch 22, accuracy: 0.3999
Epoch 22, Train Loss: 1.0986, Val Loss: 1.0991
batch size: (887, 887)
Epoch 23, accuracy: 0.4048
batch size: (911, 911)
Epoch 24, accuracy: 0.4011
Epoch 24, Train Loss: 1.0986, Val Loss: 1.0991
batch size: (899, 899)
Epoch 25, accuracy: 0.4000
batch size: (899, 899)
Epoch 26, accuracy: 0.4048
Epoch 26, Train Loss: 1.0986, Val Loss: 1.0991
batch size: (916, 916)
Epoch 27, accuracy: 0.4024
batch size: (885, 885)
Epoch 28, accuracy: 0.4016
Epoch 28, Train Loss: 1.0986, Val Loss: 1.0991
batch size: (906, 906)
Epoch 29, accuracy: 0.4055
batch size: (919, 919)
Epoch 30, accuracy: 0.4023
Epoch 30, Train Loss: 1.0986, Val Loss: 1.0991
batch size: (892, 892)
Epoch 31, accuracy: 0.3996
batch size: (888, 888)
Epoch 32, accuracy: 0.4029
Epoch 32, Train Loss: 1.0986, Val Loss: 1.0991
batch size: (897, 897)
Epoch 33, accuracy: 0.4016
batch size: (888, 888)
Epoch 34, accuracy: 0.4025
Epoch 34, Train Loss: 1.0986, Val Loss: 1.0991
batch size: (908, 908)
Epoch 35, accuracy: 0.4031
batch size: (905, 905)
Epoch 36, accuracy: 0.4035
Epoch 36, Train Loss: 1.0986, Val Loss: 1.0991
batch size: (907, 907)
Epoch 37, accuracy: 0.4017
batch size: (906, 906)
Epoch 38, accuracy: 0.4017
Epoch 38, Train Loss: 1.0986, Val Loss: 1.0991
batch size: (895, 895)
Epoch 39, accuracy: 0.3974
batch size: (898, 898)
Epoch 40, accuracy: 0.3997
Epoch 40, Train Loss: 1.0986, Val Loss: 1.0991
batch size: (895, 895)
Epoch 41, accuracy: 0.4015
batch size: (903, 903)
Epoch 42, accuracy: 0.4022
Epoch 42, Train Loss: 1.0986, Val Loss: 1.0991
batch size: (914, 914)
Epoch 43, accuracy: 0.4020
batch size: (907, 907)
Epoch 44, accuracy: 0.4032
Epoch 44, Train Loss: 1.0986, Val Loss: 1.0991
batch size: (887, 887)
Epoch 45, accuracy: 0.4013
batch size: (907, 907)
Epoch 46, accuracy: 0.4022
Epoch 46, Train Loss: 1.0986, Val Loss: 1.0991
batch size: (901, 901)
Epoch 47, accuracy: 0.4006
batch size: (882, 882)
Epoch 48, accuracy: 0.4033
Epoch 48, Train Loss: 1.0986, Val Loss: 1.0991
batch size: (896, 896)
Epoch 49, accuracy: 0.4003
Loaded best model with val_loss = 1.0963499546051025
test :accuracy 0.4312, f1_macro: 0.2009, f1_micro: 0.4312, auc: 0.5620
Training mlp with 32 layers...
可训练参数: 590089_mlp
不可训练参数: 0
batch size: (894, 894)
✅ Epoch 0: New best model saved with val_loss = 1.0971
Epoch 0, accuracy: 0.4025
Epoch 0, Train Loss: 1.0994, Val Loss: 1.0971
batch size: (885, 885)
Epoch 1, accuracy: 0.4013
batch size: (903, 903)
Epoch 2, accuracy: 0.4052
Epoch 2, Train Loss: 1.0990, Val Loss: 1.1002
batch size: (882, 882)
Epoch 3, accuracy: 0.4296
batch size: (893, 893)
✅ Epoch 4: New best model saved with val_loss = 1.0970
Epoch 4, accuracy: 0.4308
Epoch 4, Train Loss: 1.0986, Val Loss: 1.0970
batch size: (894, 894)
Epoch 5, accuracy: 0.4306
batch size: (904, 904)
Epoch 6, accuracy: 0.4287
Epoch 6, Train Loss: 1.0987, Val Loss: 1.0986
batch size: (903, 903)
Epoch 7, accuracy: 0.4293
batch size: (897, 897)
Epoch 8, accuracy: 0.1675
Epoch 8, Train Loss: 1.0987, Val Loss: 1.0994
batch size: (904, 904)
Epoch 9, accuracy: 0.1651
batch size: (901, 901)
Epoch 10, accuracy: 0.4060
Epoch 10, Train Loss: 1.0986, Val Loss: 1.0984
batch size: (902, 902)
Epoch 11, accuracy: 0.4033
batch size: (904, 904)
Epoch 12, accuracy: 0.4017
Epoch 12, Train Loss: 1.0986, Val Loss: 1.0984
batch size: (903, 903)
Epoch 13, accuracy: 0.4035
batch size: (884, 884)
Epoch 14, accuracy: 0.4030
Epoch 14, Train Loss: 1.0986, Val Loss: 1.0984
batch size: (903, 903)
Epoch 15, accuracy: 0.4039
batch size: (898, 898)
Epoch 16, accuracy: 0.4019
Epoch 16, Train Loss: 1.0986, Val Loss: 1.0985
batch size: (901, 901)
Epoch 17, accuracy: 0.4044
batch size: (899, 899)
Epoch 18, accuracy: 0.4041
Epoch 18, Train Loss: 1.0986, Val Loss: 1.0985
batch size: (910, 910)
Epoch 19, accuracy: 0.4041
batch size: (913, 913)
Epoch 20, accuracy: 0.4046
Epoch 20, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (872, 872)
Epoch 21, accuracy: 0.4036
batch size: (907, 907)
Epoch 22, accuracy: 0.3998
Epoch 22, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (902, 902)
Epoch 23, accuracy: 0.4031
batch size: (915, 915)
Epoch 24, accuracy: 0.4053
Epoch 24, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (911, 911)
Epoch 25, accuracy: 0.4017
batch size: (901, 901)
Epoch 26, accuracy: 0.4013
Epoch 26, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (903, 903)
Epoch 27, accuracy: 0.4042
batch size: (911, 911)
Epoch 28, accuracy: 0.4014
Epoch 28, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (913, 913)
Epoch 29, accuracy: 0.4026
batch size: (893, 893)
Epoch 30, accuracy: 0.4013
Epoch 30, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (896, 896)
Epoch 31, accuracy: 0.4046
batch size: (889, 889)
Epoch 32, accuracy: 0.4068
Epoch 32, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (914, 914)
Epoch 33, accuracy: 0.3992
batch size: (875, 875)
Epoch 34, accuracy: 0.4053
Epoch 34, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (881, 881)
Epoch 35, accuracy: 0.4023
batch size: (905, 905)
Epoch 36, accuracy: 0.4011
Epoch 36, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (894, 894)
Epoch 37, accuracy: 0.4019
batch size: (887, 887)
Epoch 38, accuracy: 0.4054
Epoch 38, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (908, 908)
Epoch 39, accuracy: 0.4008
batch size: (906, 906)
Epoch 40, accuracy: 0.4048
Epoch 40, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (899, 899)
Epoch 41, accuracy: 0.4036
batch size: (906, 906)
Epoch 42, accuracy: 0.4030
Epoch 42, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (898, 898)
Epoch 43, accuracy: 0.4021
batch size: (879, 879)
Epoch 44, accuracy: 0.4021
Epoch 44, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (911, 911)
Epoch 45, accuracy: 0.4025
batch size: (897, 897)
Epoch 46, accuracy: 0.4020
Epoch 46, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (885, 885)
Epoch 47, accuracy: 0.4045
batch size: (910, 910)
Epoch 48, accuracy: 0.4018
Epoch 48, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (902, 902)
Epoch 49, accuracy: 0.3999
Loaded best model with val_loss = 1.096991777420044
test :accuracy 0.4322, f1_macro: 0.2012, f1_micro: 0.4322, auc: 0.5000
Final Results: /root/miniconda3/lib/python3.12/site-packages/torch_geometric/sampler/neighbor_sampler.py:61: UserWarning: Using 'NeighborSampler' without a 'pyg-lib' installation is deprecated and will be removed soon. Please install 'pyg-lib' for accelerated neighborhood sampling
  warnings.warn(f"Using '{self.__class__.__name__}' without a "
{'GCN_2_Pubmed': np.float64(0.7223451327433629), 'GCN_8_Pubmed': np.float64(0.4285650284485462), 'GCN_32_Pubmed': np.float64(0.35547994269340977), 'GraphSAGE_2_Pubmed': np.float64(0.7112434979771485), 'GraphSAGE_8_Pubmed': np.float64(0.3819395332390382), 'GraphSAGE_32_Pubmed': np.float64(0.4062871483291507), 'GAT_2_Pubmed': np.float64(0.7376903214317514), 'GAT_8_Pubmed': np.float64(0.7101709363363093), 'GAT_32_Pubmed': np.float64(0.4302211082266583), 'JKNet_2_Pubmed': np.float64(0.4179832609765922), 'JKNet_8_Pubmed': np.float64(0.4317817014446228), 'JKNet_32_Pubmed': np.float64(0.42922536776143283), 'resGCN_2_Pubmed': np.float64(0.7062896710905944), 'resGCN_8_Pubmed': np.float64(0.40379994660496576), 'resGCN_32_Pubmed': np.float64(0.4313243315747116), 'GINConv_2_Pubmed': np.float64(0.6499049975697053), 'GINConv_8_Pubmed': np.float64(0.2147537330064631), 'GINConv_32_Pubmed': np.float64(0.37190563588343256), 'mlp_2_Pubmed': np.float64(0.71395431834404), 'mlp_8_Pubmed': np.float64(0.43123961747407175), 'mlp_32_Pubmed': np.float64(0.4321535258441206)} ['133385_GCN_0', '532745_GCN_0', '2130185_GCN_0', '262153_GraphSAGE_0', '1054729_GraphSAGE_0', '4225033_GraphSAGE_0', '196495_GAT_0', '1090447_GAT_0', '4666255_GAT_0', '391942_JKNet_0', '1184518_JKNet_0', '4354822_JKNet_0', '132626_resGCN_0', '531986_resGCN_0', '2129426_resGCN_0', '99979_GINConv_0', '300427_GINConv_0', '1102219_GINConv_0', '83209_mlp_0', '184585_mlp_0', '590089_mlp_0']
========== Running baseline 2/3 ==========
Training GCN with 2 layers...
可训练参数: 133385_GCN
不可训练参数: 0
batch size: (914, 914)
✅ Epoch 0: New best model saved with val_loss = 1.0811
/root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
Epoch 0, accuracy: 0.5503
Epoch 0, Train Loss: 1.1700, Val Loss: 1.0811
batch size: (908, 908)
✅ Epoch 1: New best model saved with val_loss = 1.0714
Epoch 1, accuracy: 0.5302
batch size: (905, 905)
✅ Epoch 2: New best model saved with val_loss = 1.0617
Epoch 2, accuracy: 0.5321
Epoch 2, Train Loss: 0.1930, Val Loss: 1.0617
batch size: (894, 894)
✅ Epoch 3: New best model saved with val_loss = 1.0508
Epoch 3, accuracy: 0.5520
batch size: (910, 910)
✅ Epoch 4: New best model saved with val_loss = 1.0366
Epoch 4, accuracy: 0.5742
Epoch 4, Train Loss: 0.0487, Val Loss: 1.0366
batch size: (900, 900)
✅ Epoch 5: New best model saved with val_loss = 1.0235
Epoch 5, accuracy: 0.6069
batch size: (886, 886)
✅ Epoch 6: New best model saved with val_loss = 1.0111
Epoch 6, accuracy: 0.6323
Epoch 6, Train Loss: 0.0216, Val Loss: 1.0111
batch size: (890, 890)
✅ Epoch 7: New best model saved with val_loss = 0.9966
Epoch 7, accuracy: 0.6518
batch size: (906, 906)
✅ Epoch 8: New best model saved with val_loss = 0.9842
Epoch 8, accuracy: 0.6677
Epoch 8, Train Loss: 0.0115, Val Loss: 0.9842
batch size: (922, 922)
✅ Epoch 9: New best model saved with val_loss = 0.9698
Epoch 9, accuracy: 0.6766
batch size: (915, 915)
✅ Epoch 10: New best model saved with val_loss = 0.9633
Epoch 10, accuracy: 0.6783
Epoch 10, Train Loss: 0.0216, Val Loss: 0.9633
batch size: (903, 903)
✅ Epoch 11: New best model saved with val_loss = 0.9506
Epoch 11, accuracy: 0.6761
batch size: (899, 899)
✅ Epoch 12: New best model saved with val_loss = 0.9417
Epoch 12, accuracy: 0.6756
Epoch 12, Train Loss: 0.0028, Val Loss: 0.9417
batch size: (899, 899)
✅ Epoch 13: New best model saved with val_loss = 0.9301
Epoch 13, accuracy: 0.6739
batch size: (887, 887)
✅ Epoch 14: New best model saved with val_loss = 0.9191
Epoch 14, accuracy: 0.6733
Epoch 14, Train Loss: 0.0032, Val Loss: 0.9191
batch size: (900, 900)
✅ Epoch 15: New best model saved with val_loss = 0.9109
Epoch 15, accuracy: 0.6758
batch size: (898, 898)
✅ Epoch 16: New best model saved with val_loss = 0.8977
Epoch 16, accuracy: 0.6800
Epoch 16, Train Loss: 0.0033, Val Loss: 0.8977
batch size: (900, 900)
✅ Epoch 17: New best model saved with val_loss = 0.8831
Epoch 17, accuracy: 0.6793
batch size: (887, 887)
✅ Epoch 18: New best model saved with val_loss = 0.8735
Epoch 18, accuracy: 0.6824
Epoch 18, Train Loss: 0.0021, Val Loss: 0.8735
batch size: (902, 902)
✅ Epoch 19: New best model saved with val_loss = 0.8564
Epoch 19, accuracy: 0.6835
batch size: (887, 887)
✅ Epoch 20: New best model saved with val_loss = 0.8468
Epoch 20, accuracy: 0.6865
Epoch 20, Train Loss: 0.0048, Val Loss: 0.8468
batch size: (894, 894)
✅ Epoch 21: New best model saved with val_loss = 0.8350
Epoch 21, accuracy: 0.6872
batch size: (904, 904)
✅ Epoch 22: New best model saved with val_loss = 0.8226
Epoch 22, accuracy: 0.6928
Epoch 22, Train Loss: 0.0025, Val Loss: 0.8226
batch size: (910, 910)
✅ Epoch 23: New best model saved with val_loss = 0.8055
Epoch 23, accuracy: 0.6959
batch size: (905, 905)
✅ Epoch 24: New best model saved with val_loss = 0.7944
Epoch 24, accuracy: 0.6976
Epoch 24, Train Loss: 0.0015, Val Loss: 0.7944
batch size: (896, 896)
✅ Epoch 25: New best model saved with val_loss = 0.7788
Epoch 25, accuracy: 0.6993
batch size: (893, 893)
✅ Epoch 26: New best model saved with val_loss = 0.7578
Epoch 26, accuracy: 0.7022
Epoch 26, Train Loss: 0.0009, Val Loss: 0.7578
batch size: (883, 883)
✅ Epoch 27: New best model saved with val_loss = 0.7459
Epoch 27, accuracy: 0.7067
batch size: (910, 910)
✅ Epoch 28: New best model saved with val_loss = 0.7364
Epoch 28, accuracy: 0.7070
Epoch 28, Train Loss: 0.0006, Val Loss: 0.7364
batch size: (915, 915)
✅ Epoch 29: New best model saved with val_loss = 0.7329
Epoch 29, accuracy: 0.7074
batch size: (882, 882)
✅ Epoch 30: New best model saved with val_loss = 0.7142
Epoch 30, accuracy: 0.7081
Epoch 30, Train Loss: 0.0011, Val Loss: 0.7142
batch size: (877, 877)
✅ Epoch 31: New best model saved with val_loss = 0.7042
Epoch 31, accuracy: 0.7116
batch size: (905, 905)
✅ Epoch 32: New best model saved with val_loss = 0.6905
Epoch 32, accuracy: 0.7118
Epoch 32, Train Loss: 0.0012, Val Loss: 0.6905
batch size: (912, 912)
✅ Epoch 33: New best model saved with val_loss = 0.6798
Epoch 33, accuracy: 0.7126
batch size: (908, 908)
✅ Epoch 34: New best model saved with val_loss = 0.6642
Epoch 34, accuracy: 0.7118
Epoch 34, Train Loss: 0.0017, Val Loss: 0.6642
batch size: (900, 900)
✅ Epoch 35: New best model saved with val_loss = 0.6605
Epoch 35, accuracy: 0.7143
batch size: (888, 888)
✅ Epoch 36: New best model saved with val_loss = 0.6400
Epoch 36, accuracy: 0.7149
Epoch 36, Train Loss: 0.0006, Val Loss: 0.6400
batch size: (893, 893)
✅ Epoch 37: New best model saved with val_loss = 0.6356
Epoch 37, accuracy: 0.7146
batch size: (914, 914)
Epoch 38, accuracy: 0.7120
Epoch 38, Train Loss: 0.0006, Val Loss: 0.6369
batch size: (918, 918)
✅ Epoch 39: New best model saved with val_loss = 0.6321
Epoch 39, accuracy: 0.7136
batch size: (898, 898)
✅ Epoch 40: New best model saved with val_loss = 0.6147
Epoch 40, accuracy: 0.7135
Epoch 40, Train Loss: 0.0006, Val Loss: 0.6147
batch size: (895, 895)
✅ Epoch 41: New best model saved with val_loss = 0.6071
Epoch 41, accuracy: 0.7116
batch size: (921, 921)
Epoch 42, accuracy: 0.7139
Epoch 42, Train Loss: 0.0009, Val Loss: 0.6119
batch size: (919, 919)
Epoch 43, accuracy: 0.7128
batch size: (903, 903)
Epoch 44, accuracy: 0.7126
Epoch 44, Train Loss: 0.0012, Val Loss: 0.6141
batch size: (900, 900)
Epoch 45, accuracy: 0.7143
batch size: (907, 907)
✅ Epoch 46: New best model saved with val_loss = 0.6047
Epoch 46, accuracy: 0.7101
Epoch 46, Train Loss: 0.0007, Val Loss: 0.6047
batch size: (904, 904)
✅ Epoch 47: New best model saved with val_loss = 0.5962
Epoch 47, accuracy: 0.7093
batch size: (902, 902)
Epoch 48, accuracy: 0.7137
Epoch 48, Train Loss: 0.0008, Val Loss: 0.6098
batch size: (904, 904)
Epoch 49, accuracy: 0.7094
Loaded best model with val_loss = 0.5961513519287109
test :accuracy 0.7112, f1_macro: 0.7078, f1_micro: 0.7112, auc: 0.8722
Training GCN with 8 layers...
可训练参数: 532745_GCN
不可训练参数: 0
batch size: (901, 901)
✅ Epoch 0: New best model saved with val_loss = 1.1571
Epoch 0, accuracy: 0.1664
Epoch 0, Train Loss: 1.1642, Val Loss: 1.1571
batch size: (901, 901)
Epoch 1, accuracy: 0.4295
batch size: (896, 896)
✅ Epoch 2: New best model saved with val_loss = 1.1434
Epoch 2, accuracy: 0.4316
Epoch 2, Train Loss: 1.2067, Val Loss: 1.1434
batch size: (914, 914)
✅ Epoch 3: New best model saved with val_loss = 1.1315
Epoch 3, accuracy: 0.4299
batch size: (914, 914)
Epoch 4, accuracy: 0.3900
Epoch 4, Train Loss: 0.9635, Val Loss: 1.2176
batch size: (914, 914)
Epoch 5, accuracy: 0.1664
batch size: (906, 906)
Epoch 6, accuracy: 0.1700
Epoch 6, Train Loss: 0.8966, Val Loss: 1.7089
batch size: (896, 896)
Epoch 7, accuracy: 0.1679
batch size: (916, 916)
Epoch 8, accuracy: 0.1672
Epoch 8, Train Loss: 0.6429, Val Loss: 2.5472
batch size: (899, 899)
Epoch 9, accuracy: 0.1681
batch size: (903, 903)
Epoch 10, accuracy: 0.1692
Epoch 10, Train Loss: 0.7040, Val Loss: 2.8131
batch size: (904, 904)
Epoch 11, accuracy: 0.1665
batch size: (897, 897)
Epoch 12, accuracy: 0.1672
Epoch 12, Train Loss: 0.5308, Val Loss: 2.7659
batch size: (886, 886)
Epoch 13, accuracy: 0.1685
batch size: (882, 882)
Epoch 14, accuracy: 0.1668
Epoch 14, Train Loss: 0.5760, Val Loss: 2.7670
batch size: (904, 904)
Epoch 15, accuracy: 0.1680
batch size: (902, 902)
Epoch 16, accuracy: 0.1678
Epoch 16, Train Loss: 0.5777, Val Loss: 2.8456
batch size: (913, 913)
Epoch 17, accuracy: 0.1664
batch size: (897, 897)
Epoch 18, accuracy: 0.1682
Epoch 18, Train Loss: 0.5867, Val Loss: 2.7707
batch size: (903, 903)
Epoch 19, accuracy: 0.1682
batch size: (908, 908)
Epoch 20, accuracy: 0.1715
Epoch 20, Train Loss: 0.4071, Val Loss: 2.7807
batch size: (894, 894)
Epoch 21, accuracy: 0.1693
batch size: (886, 886)
Epoch 22, accuracy: 0.1658
Epoch 22, Train Loss: 0.4988, Val Loss: 2.7839
batch size: (893, 893)
Epoch 23, accuracy: 0.1655
/root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
/root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
batch size: (927, 927)
Epoch 24, accuracy: 0.1676
Epoch 24, Train Loss: 0.4777, Val Loss: 2.9404
batch size: (898, 898)
Epoch 25, accuracy: 0.1691
batch size: (907, 907)
Epoch 26, accuracy: 0.1684
Epoch 26, Train Loss: 0.5983, Val Loss: 2.8766
batch size: (905, 905)
Epoch 27, accuracy: 0.1675
batch size: (896, 896)
Epoch 28, accuracy: 0.1688
Epoch 28, Train Loss: 0.5486, Val Loss: 2.7810
batch size: (906, 906)
Epoch 29, accuracy: 0.1703
batch size: (901, 901)
Epoch 30, accuracy: 0.1661
Epoch 30, Train Loss: 0.4949, Val Loss: 2.7413
batch size: (880, 880)
Epoch 31, accuracy: 0.1674
batch size: (892, 892)
Epoch 32, accuracy: 0.1652
Epoch 32, Train Loss: 0.4082, Val Loss: 2.8374
batch size: (890, 890)
Epoch 33, accuracy: 0.1695
batch size: (886, 886)
Epoch 34, accuracy: 0.1696
Epoch 34, Train Loss: 0.6212, Val Loss: 2.8515
batch size: (896, 896)
Epoch 35, accuracy: 0.1688
batch size: (905, 905)
Epoch 36, accuracy: 0.1663
Epoch 36, Train Loss: 0.4675, Val Loss: 2.8537
batch size: (897, 897)
Epoch 37, accuracy: 0.1676
batch size: (899, 899)
Epoch 38, accuracy: 0.1671
Epoch 38, Train Loss: 0.5099, Val Loss: 2.8278
batch size: (902, 902)
Epoch 39, accuracy: 0.1669
batch size: (885, 885)
Epoch 40, accuracy: 0.1671
Epoch 40, Train Loss: 0.5281, Val Loss: 2.8510
batch size: (890, 890)
Epoch 41, accuracy: 0.1670
batch size: (899, 899)
Epoch 42, accuracy: 0.1658
Epoch 42, Train Loss: 0.5864, Val Loss: 2.8661
batch size: (910, 910)
Epoch 43, accuracy: 0.1666
batch size: (918, 918)
Epoch 44, accuracy: 0.1666
Epoch 44, Train Loss: 0.4876, Val Loss: 2.8536
batch size: (900, 900)
Epoch 45, accuracy: 0.1671
batch size: (884, 884)
Epoch 46, accuracy: 0.1669
Epoch 46, Train Loss: 0.4560, Val Loss: 2.7771
batch size: (902, 902)
Epoch 47, accuracy: 0.1680
batch size: (900, 900)
Epoch 48, accuracy: 0.1637
Epoch 48, Train Loss: 0.4584, Val Loss: 2.8327
batch size: (902, 902)
Epoch 49, accuracy: 0.1679
Loaded best model with val_loss = 1.131485104560852
test :accuracy 0.4320, f1_macro: 0.2011, f1_micro: 0.4320, auc: 0.5555
Training GCN with 32 layers...
可训练参数: 2130185_GCN
不可训练参数: 0
batch size: (898, 898)
✅ Epoch 0: New best model saved with val_loss = 1.0796
Epoch 0, accuracy: 0.4318
Epoch 0, Train Loss: 1.2041, Val Loss: 1.0796
batch size: (910, 910)
Epoch 1, accuracy: 0.4289
batch size: (877, 877)
Epoch 2, accuracy: 0.1674
Epoch 2, Train Loss: 1.1101, Val Loss: 1.2363
batch size: (899, 899)
Epoch 3, accuracy: 0.1689
batch size: (914, 914)
Epoch 4, accuracy: 0.4273
Epoch 4, Train Loss: 1.2776, Val Loss: 1.1492
batch size: (901, 901)
Epoch 5, accuracy: 0.3850
batch size: (924, 924)
Epoch 6, accuracy: 0.1696
Epoch 6, Train Loss: 1.0991, Val Loss: 1.2065
batch size: (915, 915)
Epoch 7, accuracy: 0.1656
batch size: (899, 899)
Epoch 8, accuracy: 0.1674
Epoch 8, Train Loss: 1.1946, Val Loss: 1.2178
batch size: (911, 911)
Epoch 9, accuracy: 0.3754
batch size: (906, 906)
Epoch 10, accuracy: 0.3945
Epoch 10, Train Loss: 1.2660, Val Loss: 1.1645
batch size: (894, 894)
Epoch 11, accuracy: 0.4054
batch size: (902, 902)
Epoch 12, accuracy: 0.4261
Epoch 12, Train Loss: 1.2392, Val Loss: 1.1778
batch size: (894, 894)
Epoch 13, accuracy: 0.1725
batch size: (893, 893)
Epoch 14, accuracy: 0.3963
Epoch 14, Train Loss: 1.2526, Val Loss: 1.1807
batch size: (890, 890)
Epoch 15, accuracy: 0.4196
batch size: (908, 908)
Epoch 16, accuracy: 0.4240
Epoch 16, Train Loss: 1.1952, Val Loss: 1.1627
batch size: (899, 899)
Epoch 17, accuracy: 0.4200
batch size: (905, 905)
Epoch 18, accuracy: 0.1754
Epoch 18, Train Loss: 1.0958, Val Loss: 1.1711
batch size: (891, 891)
Epoch 19, accuracy: 0.3901
batch size: (898, 898)
Epoch 20, accuracy: 0.4303
Epoch 20, Train Loss: 1.1080, Val Loss: 1.1538
batch size: (899, 899)
Epoch 21, accuracy: 0.4222
batch size: (887, 887)
Epoch 22, accuracy: 0.4092
Epoch 22, Train Loss: 1.1267, Val Loss: 1.1831
batch size: (912, 912)
Epoch 23, accuracy: 0.3860
batch size: (912, 912)
Epoch 24, accuracy: 0.1746
Epoch 24, Train Loss: 1.1284, Val Loss: 1.1832
batch size: (918, 918)
Epoch 25, accuracy: 0.4205
batch size: (899, 899)
Epoch 26, accuracy: 0.4297
Epoch 26, Train Loss: 1.1928, Val Loss: 1.1568
batch size: (893, 893)
Epoch 27, accuracy: 0.4314
batch size: (898, 898)
Epoch 28, accuracy: 0.4284
Epoch 28, Train Loss: 1.1896, Val Loss: 1.1557
batch size: (914, 914)
Epoch 29, accuracy: 0.4035
batch size: (894, 894)
Epoch 30, accuracy: 0.4255
Epoch 30, Train Loss: 1.1139, Val Loss: 1.1687
batch size: (896, 896)
Epoch 31, accuracy: 0.4247
batch size: (915, 915)
Epoch 32, accuracy: 0.4177
Epoch 32, Train Loss: 1.1667, Val Loss: 1.1871
batch size: (900, 900)
Epoch 33, accuracy: 0.4265
batch size: (909, 909)
Epoch 34, accuracy: 0.4260
Epoch 34, Train Loss: 1.1618, Val Loss: 1.1873
batch size: (898, 898)
Epoch 35, accuracy: 0.3874
batch size: (916, 916)
Epoch 36, accuracy: 0.3784
Epoch 36, Train Loss: 1.1558, Val Loss: 1.1801
batch size: (898, 898)
Epoch 37, accuracy: 0.3924
batch size: (880, 880)
Epoch 38, accuracy: 0.3881
Epoch 38, Train Loss: 1.1516, Val Loss: 1.1821
batch size: (908, 908)
Epoch 39, accuracy: 0.3902
batch size: (879, 879)
Epoch 40, accuracy: 0.4005
Epoch 40, Train Loss: 1.1012, Val Loss: 1.1937
batch size: (886, 886)
Epoch 41, accuracy: 0.3913
batch size: (895, 895)
Epoch 42, accuracy: 0.3830
Epoch 42, Train Loss: 1.1488, Val Loss: 1.1715
batch size: (893, 893)
Epoch 43, accuracy: 0.1720
batch size: (908, 908)
Epoch 44, accuracy: 0.4178
Epoch 44, Train Loss: 1.1333, Val Loss: 1.1715
batch size: (894, 894)
Epoch 45, accuracy: 0.4330
batch size: (903, 903)
Epoch 46, accuracy: 0.3974
Epoch 46, Train Loss: 1.1219, Val Loss: 1.1636
batch size: (892, 892)
Epoch 47, accuracy: 0.4288
batch size: (937, 937)
Epoch 48, accuracy: 0.4224
Epoch 48, Train Loss: 1.1070, Val Loss: 1.1594
batch size: (899, 899)
Epoch 49, accuracy: 0.3920
Loaded best model with val_loss = 1.0795607566833496
test :accuracy 0.4328, f1_macro: 0.2014, f1_micro: 0.4328, auc: 0.5029
Training GraphSAGE with 2 layers...
可训练参数: 262153_GraphSAGE
不可训练参数: 0
batch size: (872, 872)
✅ Epoch 0: New best model saved with val_loss = 1.0927
Epoch 0, accuracy: 0.4064
Epoch 0, Train Loss: 1.1619, Val Loss: 1.0927
batch size: (905, 905)
✅ Epoch 1: New best model saved with val_loss = 1.0862
Epoch 1, accuracy: 0.4058
batch size: (909, 909)
✅ Epoch 2: New best model saved with val_loss = 1.0784
Epoch 2, accuracy: 0.4140
Epoch 2, Train Loss: 0.1872, Val Loss: 1.0784
batch size: (894, 894)
✅ Epoch 3: New best model saved with val_loss = 1.0694
Epoch 3, accuracy: 0.4267
batch size: (917, 917)
✅ Epoch 4: New best model saved with val_loss = 1.0601
Epoch 4, accuracy: 0.4313
Epoch 4, Train Loss: 0.0380, Val Loss: 1.0601
batch size: (902, 902)
✅ Epoch 5: New best model saved with val_loss = 1.0501
Epoch 5, accuracy: 0.4360
batch size: (891, 891)
✅ Epoch 6: New best model saved with val_loss = 1.0390
Epoch 6, accuracy: 0.4460
Epoch 6, Train Loss: 0.0070, Val Loss: 1.0390
batch size: (905, 905)
✅ Epoch 7: New best model saved with val_loss = 1.0278
Epoch 7, accuracy: 0.4534
batch size: (905, 905)
✅ Epoch 8: New best model saved with val_loss = 1.0177
Epoch 8, accuracy: 0.4637
Epoch 8, Train Loss: 0.0030, Val Loss: 1.0177
batch size: (894, 894)
✅ Epoch 9: New best model saved with val_loss = 1.0063
Epoch 9, accuracy: 0.4815
batch size: (897, 897)
✅ Epoch 10: New best model saved with val_loss = 0.9934
Epoch 10, accuracy: 0.4981
Epoch 10, Train Loss: 0.0006, Val Loss: 0.9934
batch size: (904, 904)
✅ Epoch 11: New best model saved with val_loss = 0.9822
Epoch 11, accuracy: 0.5123
batch size: (898, 898)
✅ Epoch 12: New best model saved with val_loss = 0.9698
Epoch 12, accuracy: 0.5305
Epoch 12, Train Loss: 0.0021, Val Loss: 0.9698
batch size: (908, 908)
✅ Epoch 13: New best model saved with val_loss = 0.9586
Epoch 13, accuracy: 0.5474
batch size: (893, 893)
✅ Epoch 14: New best model saved with val_loss = 0.9451
Epoch 14, accuracy: 0.5678
Epoch 14, Train Loss: 0.0007, Val Loss: 0.9451
batch size: (917, 917)
✅ Epoch 15: New best model saved with val_loss = 0.9319
Epoch 15, accuracy: 0.5826
batch size: (924, 924)
/root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
✅ Epoch 16: New best model saved with val_loss = 0.9194
Epoch 16, accuracy: 0.6009
Epoch 16, Train Loss: 0.0003, Val Loss: 0.9194
batch size: (907, 907)
✅ Epoch 17: New best model saved with val_loss = 0.9073
Epoch 17, accuracy: 0.6138
batch size: (898, 898)
✅ Epoch 18: New best model saved with val_loss = 0.8935
Epoch 18, accuracy: 0.6256
Epoch 18, Train Loss: 0.0002, Val Loss: 0.8935
batch size: (899, 899)
✅ Epoch 19: New best model saved with val_loss = 0.8821
Epoch 19, accuracy: 0.6383
batch size: (893, 893)
✅ Epoch 20: New best model saved with val_loss = 0.8677
Epoch 20, accuracy: 0.6527
Epoch 20, Train Loss: 0.0006, Val Loss: 0.8677
batch size: (903, 903)
✅ Epoch 21: New best model saved with val_loss = 0.8561
Epoch 21, accuracy: 0.6598
batch size: (892, 892)
✅ Epoch 22: New best model saved with val_loss = 0.8426
Epoch 22, accuracy: 0.6706
Epoch 22, Train Loss: 0.0003, Val Loss: 0.8426
batch size: (890, 890)
✅ Epoch 23: New best model saved with val_loss = 0.8317
Epoch 23, accuracy: 0.6772
batch size: (888, 888)
✅ Epoch 24: New best model saved with val_loss = 0.8175
Epoch 24, accuracy: 0.6852
Epoch 24, Train Loss: 0.0001, Val Loss: 0.8175
batch size: (913, 913)
✅ Epoch 25: New best model saved with val_loss = 0.8055
Epoch 25, accuracy: 0.6901
batch size: (889, 889)
✅ Epoch 26: New best model saved with val_loss = 0.7902
Epoch 26, accuracy: 0.6950
Epoch 26, Train Loss: 0.0003, Val Loss: 0.7902
batch size: (907, 907)
✅ Epoch 27: New best model saved with val_loss = 0.7823
Epoch 27, accuracy: 0.7010
batch size: (900, 900)
✅ Epoch 28: New best model saved with val_loss = 0.7703
Epoch 28, accuracy: 0.7009
Epoch 28, Train Loss: 0.0001, Val Loss: 0.7703
batch size: (901, 901)
✅ Epoch 29: New best model saved with val_loss = 0.7567
Epoch 29, accuracy: 0.7035
batch size: (888, 888)
✅ Epoch 30: New best model saved with val_loss = 0.7456
Epoch 30, accuracy: 0.7061
Epoch 30, Train Loss: 0.0001, Val Loss: 0.7456
batch size: (897, 897)
✅ Epoch 31: New best model saved with val_loss = 0.7367
Epoch 31, accuracy: 0.7049
batch size: (897, 897)
✅ Epoch 32: New best model saved with val_loss = 0.7240
Epoch 32, accuracy: 0.7102
Epoch 32, Train Loss: 0.0002, Val Loss: 0.7240
batch size: (906, 906)
✅ Epoch 33: New best model saved with val_loss = 0.7152
Epoch 33, accuracy: 0.7082
batch size: (911, 911)
✅ Epoch 34: New best model saved with val_loss = 0.7066
Epoch 34, accuracy: 0.7117
Epoch 34, Train Loss: 0.0002, Val Loss: 0.7066
batch size: (885, 885)
✅ Epoch 35: New best model saved with val_loss = 0.6917
Epoch 35, accuracy: 0.7095
batch size: (902, 902)
✅ Epoch 36: New best model saved with val_loss = 0.6861
Epoch 36, accuracy: 0.7084
Epoch 36, Train Loss: 0.0001, Val Loss: 0.6861
batch size: (914, 914)
✅ Epoch 37: New best model saved with val_loss = 0.6770
Epoch 37, accuracy: 0.7098
batch size: (913, 913)
✅ Epoch 38: New best model saved with val_loss = 0.6676
Epoch 38, accuracy: 0.7098
Epoch 38, Train Loss: 0.0002, Val Loss: 0.6676
batch size: (887, 887)
✅ Epoch 39: New best model saved with val_loss = 0.6591
Epoch 39, accuracy: 0.7113
batch size: (904, 904)
✅ Epoch 40: New best model saved with val_loss = 0.6502
Epoch 40, accuracy: 0.7139
Epoch 40, Train Loss: 0.0002, Val Loss: 0.6502
batch size: (878, 878)
✅ Epoch 41: New best model saved with val_loss = 0.6447
Epoch 41, accuracy: 0.7144
batch size: (901, 901)
✅ Epoch 42: New best model saved with val_loss = 0.6322
Epoch 42, accuracy: 0.7129
Epoch 42, Train Loss: 0.0001, Val Loss: 0.6322
batch size: (899, 899)
✅ Epoch 43: New best model saved with val_loss = 0.6306
Epoch 43, accuracy: 0.7164
batch size: (896, 896)
✅ Epoch 44: New best model saved with val_loss = 0.6280
Epoch 44, accuracy: 0.7146
Epoch 44, Train Loss: 0.0001, Val Loss: 0.6280
batch size: (900, 900)
✅ Epoch 45: New best model saved with val_loss = 0.6231
Epoch 45, accuracy: 0.7131
batch size: (895, 895)
✅ Epoch 46: New best model saved with val_loss = 0.6163
Epoch 46, accuracy: 0.7126
Epoch 46, Train Loss: 0.0002, Val Loss: 0.6163
batch size: (896, 896)
✅ Epoch 47: New best model saved with val_loss = 0.6127
Epoch 47, accuracy: 0.7130
batch size: (919, 919)
✅ Epoch 48: New best model saved with val_loss = 0.6087
Epoch 48, accuracy: 0.7146
Epoch 48, Train Loss: 0.0001, Val Loss: 0.6087
batch size: (902, 902)
✅ Epoch 49: New best model saved with val_loss = 0.6054
Epoch 49, accuracy: 0.7123
Loaded best model with val_loss = 0.6053767204284668
test :accuracy 0.7154, f1_macro: 0.7141, f1_micro: 0.7154, auc: 0.8544
Training GraphSAGE with 8 layers...
可训练参数: 1054729_GraphSAGE
不可训练参数: 0
batch size: (881, 881)
✅ Epoch 0: New best model saved with val_loss = 1.0979
Epoch 0, accuracy: 0.4067
Epoch 0, Train Loss: 1.4318, Val Loss: 1.0979
batch size: (897, 897)
Epoch 1, accuracy: 0.3796
batch size: (897, 897)
Epoch 2, accuracy: 0.3573
Epoch 2, Train Loss: 1.1304, Val Loss: 1.0986
batch size: (925, 925)
Epoch 3, accuracy: 0.3604
batch size: (896, 896)
Epoch 4, accuracy: 0.3538
Epoch 4, Train Loss: 1.0967, Val Loss: 1.0986
batch size: (892, 892)
Epoch 5, accuracy: 0.3554
batch size: (896, 896)
Epoch 6, accuracy: 0.3547
Epoch 6, Train Loss: 1.1027, Val Loss: 1.0986
batch size: (914, 914)
Epoch 7, accuracy: 0.3544
batch size: (885, 885)
Epoch 8, accuracy: 0.3537
Epoch 8, Train Loss: 1.0990, Val Loss: 1.0986
batch size: (892, 892)
Epoch 9, accuracy: 0.3542
batch size: (916, 916)
Epoch 10, accuracy: 0.3533
Epoch 10, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (911, 911)
Epoch 11, accuracy: 0.3582
batch size: (893, 893)
Epoch 12, accuracy: 0.3563
Epoch 12, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (900, 900)
Epoch 13, accuracy: 0.3531
batch size: (881, 881)
Epoch 14, accuracy: 0.3551
Epoch 14, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (893, 893)
Epoch 15, accuracy: 0.3552
batch size: (913, 913)
Epoch 16, accuracy: 0.3563
Epoch 16, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (902, 902)
Epoch 17, accuracy: 0.3544
batch size: (880, 880)
Epoch 18, accuracy: 0.3545
Epoch 18, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (885, 885)
Epoch 19, accuracy: 0.3543
batch size: (901, 901)
Epoch 20, accuracy: 0.3563
Epoch 20, Train Loss: 1.0991, Val Loss: 1.0986
batch size: (919, 919)
Epoch 21, accuracy: 0.3578
batch size: (886, 886)
Epoch 22, accuracy: 0.3553
Epoch 22, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (900, 900)
Epoch 23, accuracy: 0.3545
batch size: (911, 911)
Epoch 24, accuracy: 0.3561
Epoch 24, Train Loss: 1.0950, Val Loss: 1.0986
batch size: (907, 907)
Epoch 25, accuracy: 0.3563
batch size: (907, 907)
Epoch 26, accuracy: 0.3573
Epoch 26, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (896, 896)
Epoch 27, accuracy: 0.3541
batch size: (891, 891)
Epoch 28, accuracy: 0.3548
Epoch 28, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (908, 908)
Epoch 29, accuracy: 0.3592
batch size: (888, 888)
Epoch 30, accuracy: 0.3567
Epoch 30, Train Loss: 1.1014, Val Loss: 1.0986
batch size: (889, 889)
Epoch 31, accuracy: 0.3582
batch size: (906, 906)
Epoch 32, accuracy: 0.3546
Epoch 32, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (909, 909)
Epoch 33, accuracy: 0.3588
batch size: (894, 894)
Epoch 34, accuracy: 0.3559
Epoch 34, Train Loss: 1.0985, Val Loss: 1.0986
batch size: (906, 906)
Epoch 35, accuracy: 0.3528
batch size: (908, 908)
Epoch 36, accuracy: 0.3564
Epoch 36, Train Loss: 1.0989, Val Loss: 1.0986
batch size: (895, 895)
Epoch 37, accuracy: 0.3571
batch size: (894, 894)
Epoch 38, accuracy: 0.3546
Epoch 38, Train Loss: 1.0987, Val Loss: 1.0986
batch size: (891, 891)
Epoch 39, accuracy: 0.3538
batch size: (875, 875)
Epoch 40, accuracy: 0.3577
Epoch 40, Train Loss: 1.0961, Val Loss: 1.0986
batch size: (902, 902)
Epoch 41, accuracy: 0.3591
batch size: (879, 879)
Epoch 42, accuracy: 0.3575
Epoch 42, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (897, 897)
Epoch 43, accuracy: 0.3581
batch size: (896, 896)
Epoch 44, accuracy: 0.3514
Epoch 44, Train Loss: 1.0979, Val Loss: 1.0986
batch size: (919, 919)
Epoch 45, accuracy: 0.3543
batch size: (895, 895)
Epoch 46, accuracy: 0.3542
Epoch 46, Train Loss: 1.0986, Val Loss: 1.0986
/root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
/root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
batch size: (907, 907)
Epoch 47, accuracy: 0.3565
batch size: (873, 873)
Epoch 48, accuracy: 0.3593
Epoch 48, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (901, 901)
Epoch 49, accuracy: 0.3537
Loaded best model with val_loss = 1.097944736480713
test :accuracy 0.3985, f1_macro: 0.2129, f1_micro: 0.3985, auc: 0.4852
Training GraphSAGE with 32 layers...
可训练参数: 4225033_GraphSAGE
不可训练参数: 0
batch size: (896, 896)
✅ Epoch 0: New best model saved with val_loss = 1.0985
Epoch 0, accuracy: 0.1874
Epoch 0, Train Loss: 1.1742, Val Loss: 1.0985
batch size: (883, 883)
Epoch 1, accuracy: 0.1680
batch size: (893, 893)
Epoch 2, accuracy: 0.1675
Epoch 2, Train Loss: 1.1189, Val Loss: 1.0986
batch size: (894, 894)
Epoch 3, accuracy: 0.1704
batch size: (904, 904)
Epoch 4, accuracy: 0.1661
Epoch 4, Train Loss: 1.0955, Val Loss: 1.0986
batch size: (905, 905)
Epoch 5, accuracy: 0.1651
batch size: (904, 904)
Epoch 6, accuracy: 0.1660
Epoch 6, Train Loss: 1.0961, Val Loss: 1.0986
batch size: (904, 904)
Epoch 7, accuracy: 0.1683
batch size: (912, 912)
Epoch 8, accuracy: 0.1670
Epoch 8, Train Loss: 1.0969, Val Loss: 1.0986
batch size: (905, 905)
Epoch 9, accuracy: 0.1668
batch size: (908, 908)
Epoch 10, accuracy: 0.1649
Epoch 10, Train Loss: 1.0954, Val Loss: 1.0986
batch size: (896, 896)
Epoch 11, accuracy: 0.1691
batch size: (892, 892)
Epoch 12, accuracy: 0.1658
Epoch 12, Train Loss: 1.1005, Val Loss: 1.0986
batch size: (900, 900)
Epoch 13, accuracy: 0.1669
batch size: (879, 879)
Epoch 14, accuracy: 0.1692
Epoch 14, Train Loss: 1.1033, Val Loss: 1.0986
batch size: (901, 901)
Epoch 15, accuracy: 0.1675
batch size: (893, 893)
Epoch 16, accuracy: 0.1662
Epoch 16, Train Loss: 1.0974, Val Loss: 1.0986
batch size: (910, 910)
Epoch 17, accuracy: 0.1696
batch size: (907, 907)
Epoch 18, accuracy: 0.1695
Epoch 18, Train Loss: 1.1014, Val Loss: 1.0986
batch size: (903, 903)
Epoch 19, accuracy: 0.1648
batch size: (907, 907)
Epoch 20, accuracy: 0.1673
Epoch 20, Train Loss: 1.0971, Val Loss: 1.0986
batch size: (895, 895)
Epoch 21, accuracy: 0.1652
batch size: (903, 903)
Epoch 22, accuracy: 0.1668
Epoch 22, Train Loss: 1.0936, Val Loss: 1.0986
batch size: (918, 918)
Epoch 23, accuracy: 0.1675
batch size: (898, 898)
Epoch 24, accuracy: 0.1664
Epoch 24, Train Loss: 1.1012, Val Loss: 1.0986
batch size: (901, 901)
Epoch 25, accuracy: 0.1694
batch size: (898, 898)
Epoch 26, accuracy: 0.1680
Epoch 26, Train Loss: 1.0914, Val Loss: 1.0986
batch size: (908, 908)
Epoch 27, accuracy: 0.1690
batch size: (912, 912)
Epoch 28, accuracy: 0.1675
Epoch 28, Train Loss: 1.1011, Val Loss: 1.0986
batch size: (895, 895)
Epoch 29, accuracy: 0.1674
batch size: (890, 890)
Epoch 30, accuracy: 0.1682
Epoch 30, Train Loss: 1.0977, Val Loss: 1.0986
batch size: (904, 904)
Epoch 31, accuracy: 0.1679
batch size: (864, 864)
Epoch 32, accuracy: 0.1676
Epoch 32, Train Loss: 1.1011, Val Loss: 1.0986
batch size: (901, 901)
Epoch 33, accuracy: 0.1656
batch size: (899, 899)
Epoch 34, accuracy: 0.1652
Epoch 34, Train Loss: 1.1011, Val Loss: 1.0986
batch size: (898, 898)
Epoch 35, accuracy: 0.1672
batch size: (884, 884)
Epoch 36, accuracy: 0.1683
Epoch 36, Train Loss: 1.0939, Val Loss: 1.0986
batch size: (887, 887)
Epoch 37, accuracy: 0.1664
batch size: (916, 916)
Epoch 38, accuracy: 0.1681
Epoch 38, Train Loss: 1.0966, Val Loss: 1.0986
batch size: (902, 902)
Epoch 39, accuracy: 0.1623
batch size: (917, 917)
Epoch 40, accuracy: 0.1662
Epoch 40, Train Loss: 1.1031, Val Loss: 1.0986
batch size: (890, 890)
Epoch 41, accuracy: 0.1671
batch size: (880, 880)
Epoch 42, accuracy: 0.1677
Epoch 42, Train Loss: 1.1028, Val Loss: 1.0986
batch size: (901, 901)
Epoch 43, accuracy: 0.1695
batch size: (908, 908)
Epoch 44, accuracy: 0.1637
Epoch 44, Train Loss: 1.0946, Val Loss: 1.0986
batch size: (909, 909)
Epoch 45, accuracy: 0.1689
batch size: (895, 895)
Epoch 46, accuracy: 0.1654
Epoch 46, Train Loss: 1.1002, Val Loss: 1.0986
batch size: (916, 916)
Epoch 47, accuracy: 0.1665
batch size: (903, 903)
Epoch 48, accuracy: 0.1662
Epoch 48, Train Loss: 1.0973, Val Loss: 1.0986
batch size: (889, 889)
Epoch 49, accuracy: 0.1692
Loaded best model with val_loss = 1.0984535217285156
test :accuracy 0.1902, f1_macro: 0.1507, f1_micro: 0.1902, auc: 0.4964
Training GAT with 2 layers...
可训练参数: 196495_GAT
不可训练参数: 0
batch size: (884, 884)
✅ Epoch 0: New best model saved with val_loss = 1.0822
Epoch 0, accuracy: 0.6420
Epoch 0, Train Loss: 1.1013, Val Loss: 1.0822
batch size: (902, 902)
✅ Epoch 1: New best model saved with val_loss = 1.0619
Epoch 1, accuracy: 0.6868
batch size: (888, 888)
✅ Epoch 2: New best model saved with val_loss = 1.0373
Epoch 2, accuracy: 0.7009
Epoch 2, Train Loss: 1.0317, Val Loss: 1.0373
batch size: (881, 881)
✅ Epoch 3: New best model saved with val_loss = 1.0087
Epoch 3, accuracy: 0.7076
batch size: (907, 907)
✅ Epoch 4: New best model saved with val_loss = 0.9761
Epoch 4, accuracy: 0.7126
Epoch 4, Train Loss: 0.9466, Val Loss: 0.9761
batch size: (898, 898)
✅ Epoch 5: New best model saved with val_loss = 0.9439
Epoch 5, accuracy: 0.7153
batch size: (919, 919)
✅ Epoch 6: New best model saved with val_loss = 0.9073
Epoch 6, accuracy: 0.7189
Epoch 6, Train Loss: 0.8392, Val Loss: 0.9073
batch size: (905, 905)
✅ Epoch 7: New best model saved with val_loss = 0.8689
Epoch 7, accuracy: 0.7211
batch size: (907, 907)
✅ Epoch 8: New best model saved with val_loss = 0.8336
Epoch 8, accuracy: 0.7245
Epoch 8, Train Loss: 0.7221, Val Loss: 0.8336
batch size: (889, 889)
✅ Epoch 9: New best model saved with val_loss = 0.7942
Epoch 9, accuracy: 0.7255
batch size: (899, 899)
✅ Epoch 10: New best model saved with val_loss = 0.7624
Epoch 10, accuracy: 0.7291
Epoch 10, Train Loss: 0.6070, Val Loss: 0.7624
batch size: (883, 883)
✅ Epoch 11: New best model saved with val_loss = 0.7297
Epoch 11, accuracy: 0.7317
batch size: (883, 883)
✅ Epoch 12: New best model saved with val_loss = 0.6991
Epoch 12, accuracy: 0.7335
Epoch 12, Train Loss: 0.5052, Val Loss: 0.6991
batch size: (904, 904)
✅ Epoch 13: New best model saved with val_loss = 0.6739
Epoch 13, accuracy: 0.7371
batch size: (889, 889)
✅ Epoch 14: New best model saved with val_loss = 0.6494
Epoch 14, accuracy: 0.7384
Epoch 14, Train Loss: 0.4103, Val Loss: 0.6494
batch size: (920, 920)
✅ Epoch 15: New best model saved with val_loss = 0.6241
Epoch 15, accuracy: 0.7389
batch size: (895, 895)
✅ Epoch 16: New best model saved with val_loss = 0.6113
Epoch 16, accuracy: 0.7427
Epoch 16, Train Loss: 0.3138, Val Loss: 0.6113
batch size: (892, 892)
✅ Epoch 17: New best model saved with val_loss = 0.5967
Epoch 17, accuracy: 0.7424
batch size: (905, 905)
✅ Epoch 18: New best model saved with val_loss = 0.5885
Epoch 18, accuracy: 0.7445
Epoch 18, Train Loss: 0.2662, Val Loss: 0.5885
batch size: (896, 896)
✅ Epoch 19: New best model saved with val_loss = 0.5832
Epoch 19, accuracy: 0.7479
batch size: (902, 902)
✅ Epoch 20: New best model saved with val_loss = 0.5725
Epoch 20, accuracy: 0.7479
Epoch 20, Train Loss: 0.2019, Val Loss: 0.5725
batch size: (900, 900)
✅ Epoch 21: New best model saved with val_loss = 0.5672
Epoch 21, accuracy: 0.7470
batch size: (892, 892)
Epoch 22, accuracy: 0.7491
Epoch 22, Train Loss: 0.1683, Val Loss: 0.5730
batch size: (909, 909)
✅ Epoch 23: New best model saved with val_loss = 0.5644
Epoch 23, accuracy: 0.7478
batch size: (895, 895)
Epoch 24, accuracy: 0.7485
Epoch 24, Train Loss: 0.1300, Val Loss: 0.5694
batch size: (895, 895)
Epoch 25, accuracy: 0.7455
batch size: (908, 908)
Epoch 26, accuracy: 0.7385
Epoch 26, Train Loss: 0.1013, Val Loss: 0.5706
batch size: (897, 897)
Epoch 27, accuracy: 0.7402
batch size: (904, 904)
Epoch 28, accuracy: 0.7404
Epoch 28, Train Loss: 0.0820, Val Loss: 0.5833
batch size: (889, 889)
Epoch 29, accuracy: 0.7368
batch size: (910, 910)
Epoch 30, accuracy: 0.7384
Epoch 30, Train Loss: 0.0806, Val Loss: 0.5807
batch size: (918, 918)
Epoch 31, accuracy: 0.7362
batch size: (900, 900)
Epoch 32, accuracy: 0.7384
Epoch 32, Train Loss: 0.0801, Val Loss: 0.5695
batch size: (899, 899)
Epoch 33, accuracy: 0.7369
batch size: (900, 900)
Epoch 34, accuracy: 0.7374/root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
/root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))

Epoch 34, Train Loss: 0.0654, Val Loss: 0.5739
batch size: (877, 877)
Epoch 35, accuracy: 0.7388
batch size: (893, 893)
Epoch 36, accuracy: 0.7393
Epoch 36, Train Loss: 0.0701, Val Loss: 0.5735
batch size: (923, 923)
Epoch 37, accuracy: 0.7382
batch size: (901, 901)
Epoch 38, accuracy: 0.7395
Epoch 38, Train Loss: 0.0765, Val Loss: 0.5717
batch size: (905, 905)
Epoch 39, accuracy: 0.7372
batch size: (905, 905)
Epoch 40, accuracy: 0.7392
Epoch 40, Train Loss: 0.0643, Val Loss: 0.5791
batch size: (911, 911)
Epoch 41, accuracy: 0.7386
batch size: (921, 921)
Epoch 42, accuracy: 0.7384
Epoch 42, Train Loss: 0.0722, Val Loss: 0.5795
batch size: (913, 913)
✅ Epoch 43: New best model saved with val_loss = 0.5633
Epoch 43, accuracy: 0.7398
batch size: (898, 898)
Epoch 44, accuracy: 0.7380
Epoch 44, Train Loss: 0.0640, Val Loss: 0.5714
batch size: (895, 895)
Epoch 45, accuracy: 0.7369
batch size: (890, 890)
Epoch 46, accuracy: 0.7397
Epoch 46, Train Loss: 0.0643, Val Loss: 0.5726
batch size: (899, 899)
Epoch 47, accuracy: 0.7406
batch size: (893, 893)
Epoch 48, accuracy: 0.7404
Epoch 48, Train Loss: 0.0678, Val Loss: 0.5698
batch size: (903, 903)
Epoch 49, accuracy: 0.7394
Loaded best model with val_loss = 0.5632632970809937
test :accuracy 0.7395, f1_macro: 0.7358, f1_micro: 0.7395, auc: 0.8907
Training GAT with 8 layers...
可训练参数: 1090447_GAT
不可训练参数: 0
batch size: (896, 896)
✅ Epoch 0: New best model saved with val_loss = 1.1007
Epoch 0, accuracy: 0.1669
Epoch 0, Train Loss: 1.0976, Val Loss: 1.1007
batch size: (898, 898)
✅ Epoch 1: New best model saved with val_loss = 1.0875
Epoch 1, accuracy: 0.4320
batch size: (890, 890)
Epoch 2, accuracy: 0.1713
Epoch 2, Train Loss: 1.1016, Val Loss: 1.1106
batch size: (893, 893)
Epoch 3, accuracy: 0.1701
batch size: (905, 905)
Epoch 4, accuracy: 0.1636
Epoch 4, Train Loss: 1.0873, Val Loss: 1.0944
batch size: (890, 890)
✅ Epoch 5: New best model saved with val_loss = 1.0781
Epoch 5, accuracy: 0.1717
batch size: (903, 903)
✅ Epoch 6: New best model saved with val_loss = 1.0578
Epoch 6, accuracy: 0.5032
Epoch 6, Train Loss: 1.0651, Val Loss: 1.0578
batch size: (898, 898)
Epoch 7, accuracy: 0.4199
batch size: (902, 902)
✅ Epoch 8: New best model saved with val_loss = 0.9871
Epoch 8, accuracy: 0.5106
Epoch 8, Train Loss: 1.0616, Val Loss: 0.9871
batch size: (908, 908)
Epoch 9, accuracy: 0.4622
batch size: (905, 905)
Epoch 10, accuracy: 0.4991
Epoch 10, Train Loss: 1.0536, Val Loss: 1.0095
batch size: (903, 903)
✅ Epoch 11: New best model saved with val_loss = 0.9557
Epoch 11, accuracy: 0.6000
batch size: (927, 927)
✅ Epoch 12: New best model saved with val_loss = 0.8822
Epoch 12, accuracy: 0.6783
Epoch 12, Train Loss: 0.9712, Val Loss: 0.8822
batch size: (909, 909)
✅ Epoch 13: New best model saved with val_loss = 0.7881
Epoch 13, accuracy: 0.7118
batch size: (884, 884)
Epoch 14, accuracy: 0.6892
Epoch 14, Train Loss: 0.6402, Val Loss: 0.8267
batch size: (914, 914)
Epoch 15, accuracy: 0.7025
batch size: (912, 912)
Epoch 16, accuracy: 0.7238
Epoch 16, Train Loss: 0.3737, Val Loss: 0.8155
batch size: (895, 895)
Epoch 17, accuracy: 0.6842
batch size: (883, 883)
Epoch 18, accuracy: 0.6830
Epoch 18, Train Loss: 0.3629, Val Loss: 1.3428
batch size: (908, 908)
Epoch 19, accuracy: 0.7167
batch size: (917, 917)
Epoch 20, accuracy: 0.7234
Epoch 20, Train Loss: 0.3889, Val Loss: 1.0553
batch size: (888, 888)
Epoch 21, accuracy: 0.7284
batch size: (898, 898)
Epoch 22, accuracy: 0.7318
Epoch 22, Train Loss: 0.2125, Val Loss: 0.9085
batch size: (901, 901)
Epoch 23, accuracy: 0.7320
batch size: (894, 894)
Epoch 24, accuracy: 0.7245
Epoch 24, Train Loss: 0.1421, Val Loss: 0.8631
batch size: (906, 906)
Epoch 25, accuracy: 0.7106
batch size: (896, 896)
Epoch 26, accuracy: 0.7110
Epoch 26, Train Loss: 0.2687, Val Loss: 0.9798
batch size: (885, 885)
Epoch 27, accuracy: 0.7074
batch size: (905, 905)
Epoch 28, accuracy: 0.7070
Epoch 28, Train Loss: 0.1909, Val Loss: 0.9445
batch size: (901, 901)
Epoch 29, accuracy: 0.7065
batch size: (899, 899)
Epoch 30, accuracy: 0.7044
Epoch 30, Train Loss: 0.2035, Val Loss: 0.9480
batch size: (882, 882)
Epoch 31, accuracy: 0.7059
batch size: (903, 903)
Epoch 32, accuracy: 0.7044
Epoch 32, Train Loss: 0.1740, Val Loss: 1.0027
batch size: (899, 899)
Epoch 33, accuracy: 0.7065
batch size: (905, 905)
Epoch 34, accuracy: 0.7061
Epoch 34, Train Loss: 0.1848, Val Loss: 0.9262
batch size: (880, 880)
Epoch 35, accuracy: 0.7082
batch size: (894, 894)
Epoch 36, accuracy: 0.7066
Epoch 36, Train Loss: 0.2116, Val Loss: 0.9823
batch size: (903, 903)
Epoch 37, accuracy: 0.7093
batch size: (917, 917)
Epoch 38, accuracy: 0.7067
Epoch 38, Train Loss: 0.2358, Val Loss: 0.9351
batch size: (902, 902)
Epoch 39, accuracy: 0.7068
batch size: (896, 896)
Epoch 40, accuracy: 0.7105
Epoch 40, Train Loss: 0.1719, Val Loss: 0.8459
batch size: (874, 874)
Epoch 41, accuracy: 0.7071
batch size: (889, 889)
Epoch 42, accuracy: 0.7063
Epoch 42, Train Loss: 0.2845, Val Loss: 0.9559
batch size: (900, 900)
Epoch 43, accuracy: 0.7072
batch size: (896, 896)
Epoch 44, accuracy: 0.7069
Epoch 44, Train Loss: 0.3273, Val Loss: 0.8839
batch size: (890, 890)
Epoch 45, accuracy: 0.7067
batch size: (898, 898)
Epoch 46, accuracy: 0.7087
Epoch 46, Train Loss: 0.3112, Val Loss: 0.9399
batch size: (905, 905)
Epoch 47, accuracy: 0.7061
batch size: (896, 896)
Epoch 48, accuracy: 0.7078
Epoch 48, Train Loss: 0.1929, Val Loss: 0.9525
batch size: (904, 904)
Epoch 49, accuracy: 0.7101
Loaded best model with val_loss = 0.7880523204803467
test :accuracy 0.7092, f1_macro: 0.7110, f1_micro: 0.7092, auc: 0.8662
Training GAT with 32 layers...
可训练参数: 4666255_GAT
不可训练参数: 0
batch size: (915, 915)
✅ Epoch 0: New best model saved with val_loss = 1.1010
Epoch 0, accuracy: 0.1680
Epoch 0, Train Loss: 1.1003, Val Loss: 1.1010
batch size: (915, 915)
Epoch 1, accuracy: 0.1655
batch size: (909, 909)
✅ Epoch 2: New best model saved with val_loss = 1.0882
Epoch 2, accuracy: 0.4048
Epoch 2, Train Loss: 1.1100, Val Loss: 1.0882
batch size: (904, 904)
Epoch 3, accuracy: 0.4001
batch size: (901, 901)
Epoch 4, accuracy: 0.3997
Epoch 4, Train Loss: 1.1043, Val Loss: 1.0981
batch size: (892, 892)
Epoch 5, accuracy: 0.1666
batch size: (887, 887)
Epoch 6, accuracy: 0.1718
Epoch 6, Train Loss: 1.0858, Val Loss: 1.1124
batch size: (906, 906)
Epoch 7, accuracy: 0.1677
batch size: (894, 894)
Epoch 8, accuracy: 0.4061
Epoch 8, Train Loss: 1.1067, Val Loss: 1.1033
batch size: (895, 895)
Epoch 9, accuracy: 0.4021
batch size: (881, 881)
Epoch 10, accuracy: 0.3991
Epoch 10, Train Loss: 1.0996, Val Loss: 1.1033
batch size: (902, 902)
Epoch 11, accuracy: 0.4034
batch size: (898, 898)
Epoch 12, accuracy: 0.4054
Epoch 12, Train Loss: 1.1091, Val Loss: 1.1025
batch size: (907, 907)
Epoch 13, accuracy: 0.4043
batch size: (917, 917)
Epoch 14, accuracy: 0.4023
Epoch 14, Train Loss: 1.1044, Val Loss: 1.1015
batch size: (896, 896)
Epoch 15, accuracy: 0.4010
batch size: (899, 899)
Epoch 16, accuracy: 0.4042
Epoch 16, Train Loss: 1.1046, Val Loss: 1.1015
batch size: (911, 911)
Epoch 17, accuracy: 0.4048
batch size: (913, 913)
Epoch 18, accuracy: 0.4045
Epoch 18, Train Loss: 1.1054, Val Loss: 1.1013
batch size: (903, 903)
Epoch 19, accuracy: 0.4029
batch size: (905, 905)
Epoch 20, accuracy: 0.4042
Epoch 20, Train Loss: 1.0943, Val Loss: 1.1012
batch size: (889, 889)
Epoch 21, accuracy: 0.4070
batch size: (899, 899)
Epoch 22, accuracy: 0.3997
Epoch 22, Train Loss: 1.1008, Val Loss: 1.1012
batch size: (880, 880)
Epoch 23, accuracy: 0.4022
batch size: (909, 909)
Epoch 24, accuracy: 0.4018
Epoch 24, Train Loss: 1.1038, Val Loss: 1.1011
batch size: (913, 913)
Epoch 25, accuracy: 0.4029
batch size: (890, 890)
Epoch 26, accuracy: 0.3994
Epoch 26, Train Loss: 1.1031, Val Loss: 1.1011
batch size: (894, 894)
Epoch 27, accuracy: 0.4020
batch size: (916, 916)
Epoch 28, accuracy: 0.4067
Epoch 28, Train Loss: 1.0996, Val Loss: 1.1011
batch size: (899, 899)
Epoch 29, accuracy: 0.4003
batch size: (919, 919)
Epoch 30, accuracy: 0.4006
Epoch 30, Train Loss: 1.0950, Val Loss: 1.1011
batch size: (905, 905)
Epoch 31, accuracy: 0.4041
batch size: (897, 897)
/root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
/root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
Epoch 32, accuracy: 0.4009
Epoch 32, Train Loss: 1.1067, Val Loss: 1.1011
batch size: (891, 891)
Epoch 33, accuracy: 0.3961
batch size: (883, 883)
Epoch 34, accuracy: 0.4018
Epoch 34, Train Loss: 1.0984, Val Loss: 1.1011
batch size: (901, 901)
Epoch 35, accuracy: 0.4078
batch size: (894, 894)
Epoch 36, accuracy: 0.4007
Epoch 36, Train Loss: 1.0965, Val Loss: 1.1011
batch size: (901, 901)
Epoch 37, accuracy: 0.4042
batch size: (902, 902)
Epoch 38, accuracy: 0.4052
Epoch 38, Train Loss: 1.0988, Val Loss: 1.1011
batch size: (892, 892)
Epoch 39, accuracy: 0.4039
batch size: (919, 919)
Epoch 40, accuracy: 0.4073
Epoch 40, Train Loss: 1.1031, Val Loss: 1.1011
batch size: (897, 897)
Epoch 41, accuracy: 0.4013
batch size: (904, 904)
Epoch 42, accuracy: 0.4019
Epoch 42, Train Loss: 1.0991, Val Loss: 1.1011
batch size: (899, 899)
Epoch 43, accuracy: 0.4031
batch size: (901, 901)
Epoch 44, accuracy: 0.4054
Epoch 44, Train Loss: 1.0990, Val Loss: 1.1011
batch size: (899, 899)
Epoch 45, accuracy: 0.4027
batch size: (908, 908)
Epoch 46, accuracy: 0.3967
Epoch 46, Train Loss: 1.1018, Val Loss: 1.1011
batch size: (899, 899)
Epoch 47, accuracy: 0.4010
batch size: (893, 893)
Epoch 48, accuracy: 0.4026
Epoch 48, Train Loss: 1.1016, Val Loss: 1.1011
batch size: (901, 901)
Epoch 49, accuracy: 0.3994
Loaded best model with val_loss = 1.0882353782653809
test :accuracy 0.4044, f1_macro: 0.1920, f1_micro: 0.4044, auc: 0.3904
Training JKNet with 2 layers...
可训练参数: 391942_JKNet
不可训练参数: 0
batch size: (886, 886)
✅ Epoch 0: New best model saved with val_loss = 1.0872
Epoch 0, accuracy: 0.4537
Epoch 0, Train Loss: 1.2117, Val Loss: 1.0872
batch size: (895, 895)
✅ Epoch 1: New best model saved with val_loss = 1.0829
Epoch 1, accuracy: 0.4439
batch size: (892, 892)
✅ Epoch 2: New best model saved with val_loss = 1.0777
Epoch 2, accuracy: 0.4525
Epoch 2, Train Loss: 0.0966, Val Loss: 1.0777
batch size: (905, 905)
✅ Epoch 3: New best model saved with val_loss = 1.0705
Epoch 3, accuracy: 0.4614
batch size: (895, 895)
✅ Epoch 4: New best model saved with val_loss = 1.0610
Epoch 4, accuracy: 0.4689
Epoch 4, Train Loss: 0.0119, Val Loss: 1.0610
batch size: (895, 895)
✅ Epoch 5: New best model saved with val_loss = 1.0476
Epoch 5, accuracy: 0.4929
batch size: (885, 885)
✅ Epoch 6: New best model saved with val_loss = 1.0339
Epoch 6, accuracy: 0.4967
Epoch 6, Train Loss: 0.0021, Val Loss: 1.0339
batch size: (887, 887)
✅ Epoch 7: New best model saved with val_loss = 1.0225
Epoch 7, accuracy: 0.4952
batch size: (911, 911)
✅ Epoch 8: New best model saved with val_loss = 1.0127
Epoch 8, accuracy: 0.4862
Epoch 8, Train Loss: 0.0007, Val Loss: 1.0127
batch size: (913, 913)
✅ Epoch 9: New best model saved with val_loss = 1.0042
Epoch 9, accuracy: 0.4793
batch size: (891, 891)
✅ Epoch 10: New best model saved with val_loss = 0.9973
Epoch 10, accuracy: 0.4775
Epoch 10, Train Loss: 0.0007, Val Loss: 0.9973
batch size: (908, 908)
✅ Epoch 11: New best model saved with val_loss = 0.9927
Epoch 11, accuracy: 0.4761
batch size: (885, 885)
✅ Epoch 12: New best model saved with val_loss = 0.9879
Epoch 12, accuracy: 0.4765
Epoch 12, Train Loss: 0.0002, Val Loss: 0.9879
batch size: (912, 912)
✅ Epoch 13: New best model saved with val_loss = 0.9845
Epoch 13, accuracy: 0.4824
batch size: (914, 914)
✅ Epoch 14: New best model saved with val_loss = 0.9817
Epoch 14, accuracy: 0.4850
Epoch 14, Train Loss: 0.0002, Val Loss: 0.9817
batch size: (904, 904)
✅ Epoch 15: New best model saved with val_loss = 0.9813
Epoch 15, accuracy: 0.4828
batch size: (879, 879)
✅ Epoch 16: New best model saved with val_loss = 0.9803
Epoch 16, accuracy: 0.4840
Epoch 16, Train Loss: 0.0000, Val Loss: 0.9803
batch size: (867, 867)
✅ Epoch 17: New best model saved with val_loss = 0.9795
Epoch 17, accuracy: 0.4847
batch size: (897, 897)
Epoch 18, accuracy: 0.4859
Epoch 18, Train Loss: 0.0001, Val Loss: 0.9795
batch size: (886, 886)
✅ Epoch 19: New best model saved with val_loss = 0.9789
Epoch 19, accuracy: 0.4875
batch size: (898, 898)
✅ Epoch 20: New best model saved with val_loss = 0.9779
Epoch 20, accuracy: 0.4869
Epoch 20, Train Loss: 0.0001, Val Loss: 0.9779
batch size: (893, 893)
✅ Epoch 21: New best model saved with val_loss = 0.9774
Epoch 21, accuracy: 0.4833
batch size: (902, 902)
✅ Epoch 22: New best model saved with val_loss = 0.9767
Epoch 22, accuracy: 0.4909
Epoch 22, Train Loss: 0.0003, Val Loss: 0.9767
batch size: (916, 916)
Epoch 23, accuracy: 0.4903
batch size: (893, 893)
Epoch 24, accuracy: 0.4896
Epoch 24, Train Loss: 0.0002, Val Loss: 0.9776
batch size: (906, 906)
✅ Epoch 25: New best model saved with val_loss = 0.9764
Epoch 25, accuracy: 0.4882
batch size: (896, 896)
Epoch 26, accuracy: 0.4849
Epoch 26, Train Loss: 0.0002, Val Loss: 0.9772
batch size: (895, 895)
Epoch 27, accuracy: 0.4832
batch size: (897, 897)
Epoch 28, accuracy: 0.4835
Epoch 28, Train Loss: 0.0001, Val Loss: 0.9781
batch size: (889, 889)
Epoch 29, accuracy: 0.4770
batch size: (907, 907)
Epoch 30, accuracy: 0.4739
Epoch 30, Train Loss: 0.0001, Val Loss: 0.9795
batch size: (898, 898)
Epoch 31, accuracy: 0.4728
batch size: (902, 902)
Epoch 32, accuracy: 0.4666
Epoch 32, Train Loss: 0.0001, Val Loss: 0.9802
batch size: (920, 920)
Epoch 33, accuracy: 0.4751
batch size: (914, 914)
Epoch 34, accuracy: 0.4692
Epoch 34, Train Loss: 0.0000, Val Loss: 0.9812
batch size: (884, 884)
Epoch 35, accuracy: 0.4686
batch size: (896, 896)
Epoch 36, accuracy: 0.4636
Epoch 36, Train Loss: 0.0002, Val Loss: 0.9821
batch size: (895, 895)
Epoch 37, accuracy: 0.4658
batch size: (893, 893)
Epoch 38, accuracy: 0.4634
Epoch 38, Train Loss: 0.0001, Val Loss: 0.9820
batch size: (900, 900)
Epoch 39, accuracy: 0.4630
batch size: (895, 895)
Epoch 40, accuracy: 0.4656
Epoch 40, Train Loss: 0.0000, Val Loss: 0.9811
batch size: (897, 897)
Epoch 41, accuracy: 0.4636
batch size: (916, 916)
Epoch 42, accuracy: 0.4616
Epoch 42, Train Loss: 0.0001, Val Loss: 0.9817
batch size: (892, 892)
Epoch 43, accuracy: 0.4659
batch size: (906, 906)
Epoch 44, accuracy: 0.4645
Epoch 44, Train Loss: 0.0001, Val Loss: 0.9818
batch size: (905, 905)
Epoch 45, accuracy: 0.4659
batch size: (895, 895)
Epoch 46, accuracy: 0.4653
Epoch 46, Train Loss: 0.0001, Val Loss: 0.9821
batch size: (896, 896)
Epoch 47, accuracy: 0.4671
batch size: (908, 908)
Epoch 48, accuracy: 0.4707
Epoch 48, Train Loss: 0.0000, Val Loss: 0.9816
batch size: (918, 918)
Epoch 49, accuracy: 0.4673
Loaded best model with val_loss = 0.9763902425765991
test :accuracy 0.4893, f1_macro: 0.3353, f1_micro: 0.4893, auc: 0.8055
Training JKNet with 8 layers...
可训练参数: 1184518_JKNet
不可训练参数: 0
batch size: (868, 868)
✅ Epoch 0: New best model saved with val_loss = 1.1240
Epoch 0, accuracy: 0.4036
Epoch 0, Train Loss: 1.2612, Val Loss: 1.1240
batch size: (893, 893)
✅ Epoch 1: New best model saved with val_loss = 1.0729
Epoch 1, accuracy: 0.4278
batch size: (913, 913)
✅ Epoch 2: New best model saved with val_loss = 1.0505
Epoch 2, accuracy: 0.4075
Epoch 2, Train Loss: 0.8542, Val Loss: 1.0505
batch size: (902, 902)
Epoch 3, accuracy: 0.4009
batch size: (882, 882)
Epoch 4, accuracy: 0.4110
Epoch 4, Train Loss: 0.2258, Val Loss: 1.0973
batch size: (908, 908)
Epoch 5, accuracy: 0.4419
batch size: (892, 892)
Epoch 6, accuracy: 0.4266
Epoch 6, Train Loss: 0.1993, Val Loss: 1.0572
batch size: (900, 900)
Epoch 7, accuracy: 0.4279
batch size: (888, 888)
Epoch 8, accuracy: 0.4240
Epoch 8, Train Loss: 0.0552, Val Loss: 1.0638
batch size: (906, 906)
Epoch 9, accuracy: 0.4207
batch size: (907, 907)
Epoch 10, accuracy: 0.4196
Epoch 10, Train Loss: 0.0179, Val Loss: 1.0557
batch size: (895, 895)
Epoch 11, accuracy: 0.4191
batch size: (887, 887)
Epoch 12, accuracy: 0.4224
Epoch 12, Train Loss: 0.0130, Val Loss: 1.0596
batch size: (897, 897)
Epoch 13, accuracy: 0.4221
batch size: (918, 918)
Epoch 14, accuracy: 0.4217
Epoch 14, Train Loss: 0.0219, Val Loss: 1.0615
batch size: (905, 905)
Epoch 15, accuracy: 0.4221
batch size: (911, 911)
Epoch 16, accuracy: 0.4209
Epoch 16, Train Loss: 0.0088, Val Loss: 1.0587
batch size: (892, 892)
Epoch 17, accuracy: 0.4179
batch size: /root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
/root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
(894, 894)
Epoch 18, accuracy: 0.4218
Epoch 18, Train Loss: 0.0136, Val Loss: 1.0569
batch size: (906, 906)
Epoch 19, accuracy: 0.4220
batch size: (869, 869)
Epoch 20, accuracy: 0.4234
Epoch 20, Train Loss: 0.0332, Val Loss: 1.0567
batch size: (895, 895)
Epoch 21, accuracy: 0.4219
batch size: (896, 896)
Epoch 22, accuracy: 0.4205
Epoch 22, Train Loss: 0.0292, Val Loss: 1.0579
batch size: (900, 900)
Epoch 23, accuracy: 0.4232
batch size: (899, 899)
Epoch 24, accuracy: 0.4193
Epoch 24, Train Loss: 0.0123, Val Loss: 1.0589
batch size: (896, 896)
Epoch 25, accuracy: 0.4232
batch size: (895, 895)
Epoch 26, accuracy: 0.4199
Epoch 26, Train Loss: 0.0890, Val Loss: 1.0569
batch size: (884, 884)
Epoch 27, accuracy: 0.4230
batch size: (905, 905)
Epoch 28, accuracy: 0.4218
Epoch 28, Train Loss: 0.0197, Val Loss: 1.0563
batch size: (909, 909)
Epoch 29, accuracy: 0.4175
batch size: (867, 867)
Epoch 30, accuracy: 0.4187
Epoch 30, Train Loss: 0.0095, Val Loss: 1.0555
batch size: (910, 910)
Epoch 31, accuracy: 0.4214
batch size: (897, 897)
Epoch 32, accuracy: 0.4205
Epoch 32, Train Loss: 0.0139, Val Loss: 1.0540
batch size: (896, 896)
Epoch 33, accuracy: 0.4222
batch size: (903, 903)
Epoch 34, accuracy: 0.4216
Epoch 34, Train Loss: 0.0176, Val Loss: 1.0550
batch size: (893, 893)
Epoch 35, accuracy: 0.4205
batch size: (897, 897)
Epoch 36, accuracy: 0.4184
Epoch 36, Train Loss: 0.0202, Val Loss: 1.0588
batch size: (922, 922)
Epoch 37, accuracy: 0.4189
batch size: (908, 908)
Epoch 38, accuracy: 0.4208
Epoch 38, Train Loss: 0.0240, Val Loss: 1.0577
batch size: (872, 872)
Epoch 39, accuracy: 0.4237
batch size: (907, 907)
Epoch 40, accuracy: 0.4196
Epoch 40, Train Loss: 0.0406, Val Loss: 1.0565
batch size: (909, 909)
Epoch 41, accuracy: 0.4205
batch size: (911, 911)
Epoch 42, accuracy: 0.4197
Epoch 42, Train Loss: 0.0627, Val Loss: 1.0568
batch size: (901, 901)
Epoch 43, accuracy: 0.4184
batch size: (914, 914)
Epoch 44, accuracy: 0.4198
Epoch 44, Train Loss: 0.0137, Val Loss: 1.0613
batch size: (904, 904)
Epoch 45, accuracy: 0.4202
batch size: (912, 912)
Epoch 46, accuracy: 0.4221
Epoch 46, Train Loss: 0.0160, Val Loss: 1.0547
batch size: (896, 896)
Epoch 47, accuracy: 0.4217
batch size: (900, 900)
Epoch 48, accuracy: 0.4229
Epoch 48, Train Loss: 0.0148, Val Loss: 1.0544
batch size: (897, 897)
Epoch 49, accuracy: 0.4205
Loaded best model with val_loss = 1.050546646118164
test :accuracy 0.4055, f1_macro: 0.2312, f1_micro: 0.4055, auc: 0.6781
Training JKNet with 32 layers...
可训练参数: 4354822_JKNet
不可训练参数: 0
batch size: (897, 897)
✅ Epoch 0: New best model saved with val_loss = 1.4360
Epoch 0, accuracy: 0.1672
Epoch 0, Train Loss: 1.3686, Val Loss: 1.4360
batch size: (914, 914)
✅ Epoch 1: New best model saved with val_loss = 1.0991
Epoch 1, accuracy: 0.4306
batch size: (883, 883)
Epoch 2, accuracy: 0.4003
Epoch 2, Train Loss: 5.3752, Val Loss: 1.1681
batch size: (894, 894)
Epoch 3, accuracy: 0.4007
batch size: (900, 900)
Epoch 4, accuracy: 0.1708
Epoch 4, Train Loss: 2.0114, Val Loss: 1.1238
batch size: (910, 910)
Epoch 5, accuracy: 0.1668
batch size: (884, 884)
✅ Epoch 6: New best model saved with val_loss = 1.0921
Epoch 6, accuracy: 0.4313
Epoch 6, Train Loss: 1.6589, Val Loss: 1.0921
batch size: (887, 887)
✅ Epoch 7: New best model saved with val_loss = 1.0756
Epoch 7, accuracy: 0.4280
batch size: (904, 904)
✅ Epoch 8: New best model saved with val_loss = 1.0669
Epoch 8, accuracy: 0.4012
Epoch 8, Train Loss: 0.7299, Val Loss: 1.0669
batch size: (896, 896)
Epoch 9, accuracy: 0.4017
batch size: (895, 895)
✅ Epoch 10: New best model saved with val_loss = 1.0655
Epoch 10, accuracy: 0.4029
Epoch 10, Train Loss: 0.5443, Val Loss: 1.0655
batch size: (908, 908)
✅ Epoch 11: New best model saved with val_loss = 1.0644
Epoch 11, accuracy: 0.4062
batch size: (898, 898)
✅ Epoch 12: New best model saved with val_loss = 1.0639
Epoch 12, accuracy: 0.3992
Epoch 12, Train Loss: 0.4617, Val Loss: 1.0639
batch size: (910, 910)
✅ Epoch 13: New best model saved with val_loss = 1.0598
Epoch 13, accuracy: 0.4032
batch size: (927, 927)
Epoch 14, accuracy: 0.3992
Epoch 14, Train Loss: 0.0271, Val Loss: 1.0603
batch size: (898, 898)
Epoch 15, accuracy: 0.4013
batch size: (903, 903)
✅ Epoch 16: New best model saved with val_loss = 1.0587
Epoch 16, accuracy: 0.4040
Epoch 16, Train Loss: 0.0151, Val Loss: 1.0587
batch size: (906, 906)
Epoch 17, accuracy: 0.4326
batch size: (906, 906)
Epoch 18, accuracy: 0.4455
Epoch 18, Train Loss: 0.0097, Val Loss: 1.0625
batch size: (908, 908)
Epoch 19, accuracy: 0.4377
batch size: (916, 916)
Epoch 20, accuracy: 0.4054
Epoch 20, Train Loss: 0.3185, Val Loss: 1.0772
batch size: (885, 885)
Epoch 21, accuracy: 0.4030
batch size: (924, 924)
Epoch 22, accuracy: 0.4020
Epoch 22, Train Loss: 0.0058, Val Loss: 1.0765
batch size: (917, 917)
Epoch 23, accuracy: 0.4020
batch size: (893, 893)
Epoch 24, accuracy: 0.4008
Epoch 24, Train Loss: 0.0035, Val Loss: 1.0831
batch size: (917, 917)
Epoch 25, accuracy: 0.4020
batch size: (903, 903)
Epoch 26, accuracy: 0.4013
Epoch 26, Train Loss: 0.0046, Val Loss: 1.0811
batch size: (916, 916)
Epoch 27, accuracy: 0.4050
batch size: (880, 880)
Epoch 28, accuracy: 0.4057
Epoch 28, Train Loss: 0.0015, Val Loss: 1.0823
batch size: (911, 911)
Epoch 29, accuracy: 0.4014
batch size: (888, 888)
Epoch 30, accuracy: 0.4039
Epoch 30, Train Loss: 0.0059, Val Loss: 1.0803
batch size: (913, 913)
Epoch 31, accuracy: 0.4017
batch size: (904, 904)
Epoch 32, accuracy: 0.4063
Epoch 32, Train Loss: 0.0051, Val Loss: 1.0834
batch size: (908, 908)
Epoch 33, accuracy: 0.3994
batch size: (897, 897)
Epoch 34, accuracy: 0.4038
Epoch 34, Train Loss: 0.0051, Val Loss: 1.0815
batch size: (905, 905)
Epoch 35, accuracy: 0.4021
batch size: (914, 914)
Epoch 36, accuracy: 0.4037
Epoch 36, Train Loss: 0.0021, Val Loss: 1.0822
batch size: (891, 891)
Epoch 37, accuracy: 0.4051
batch size: (910, 910)
Epoch 38, accuracy: 0.4025
Epoch 38, Train Loss: 0.0049, Val Loss: 1.0826
batch size: (886, 886)
Epoch 39, accuracy: 0.4036
batch size: (910, 910)
Epoch 40, accuracy: 0.4026
Epoch 40, Train Loss: 0.0044, Val Loss: 1.0809
batch size: (901, 901)
Epoch 41, accuracy: 0.4022
batch size: (904, 904)
Epoch 42, accuracy: 0.3954
Epoch 42, Train Loss: 0.0062, Val Loss: 1.0815
batch size: (900, 900)
Epoch 43, accuracy: 0.4024
batch size: (902, 902)
Epoch 44, accuracy: 0.4013
Epoch 44, Train Loss: 0.0052, Val Loss: 1.0819
batch size: (895, 895)
Epoch 45, accuracy: 0.4040
batch size: (909, 909)
Epoch 46, accuracy: 0.4041
Epoch 46, Train Loss: 0.0038, Val Loss: 1.0812
batch size: (896, 896)
Epoch 47, accuracy: 0.3999
batch size: (900, 900)
Epoch 48, accuracy: 0.4055
Epoch 48, Train Loss: 0.0045, Val Loss: 1.0839
batch size: (890, 890)
Epoch 49, accuracy: 0.4026
Loaded best model with val_loss = 1.0586919784545898
test :accuracy 0.4013, f1_macro: 0.1956, f1_micro: 0.4013, auc: 0.7483
Training resGCN with 2 layers...
可训练参数: 132626_resGCN
不可训练参数: 0
batch size: (916, 916)
✅ Epoch 0: New best model saved with val_loss = 1.0934
Epoch 0, accuracy: 0.4342
Epoch 0, Train Loss: 1.0987, Val Loss: 1.0934
batch size: (911, 911)
✅ Epoch 1: New best model saved with val_loss = 1.0845
Epoch 1, accuracy: 0.5635
batch size: (893, 893)
✅ Epoch 2: New best model saved with val_loss = 1.0727
Epoch 2, accuracy: 0.6075
Epoch 2, Train Loss: 1.0751, Val Loss: 1.0727
batch size: (892, 892)
✅ Epoch 3: New best model saved with val_loss = 1.0674
Epoch 3, accuracy: 0.5666
batch size: (879, 879)
✅ Epoch 4: New best model saved with val_loss = 1.0625
Epoch 4, accuracy: 0.5547
Epoch 4, Train Loss: 1.0316, Val Loss: 1.0625
batch size: (904, 904)
✅ Epoch 5: New best model saved with val_loss = 1.0453
Epoch 5, accuracy: 0.5675
batch size: (894, 894)
✅ Epoch 6: New best model saved with val_loss = 1.0294
Epoch 6, accuracy: 0.5567
Epoch 6, Train Loss: 0.9834, Val Loss: 1.0294
batch size: (894, 894)
✅ Epoch 7: New best model saved with val_loss = 1.0107
Epoch 7, accuracy: 0.5207
batch size: (896, 896)
✅ Epoch 8: New best model saved with val_loss = 0.9967
Epoch 8, accuracy: 0.5065
Epoch 8, Train Loss: 0.9425, Val Loss: 0.9967
batch size: /root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
/root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
(914, 914)
✅ Epoch 9: New best model saved with val_loss = 0.9839
Epoch 9, accuracy: 0.4918
batch size: (908, 908)
✅ Epoch 10: New best model saved with val_loss = 0.9668
Epoch 10, accuracy: 0.4898
Epoch 10, Train Loss: 0.9390, Val Loss: 0.9668
batch size: (911, 911)
✅ Epoch 11: New best model saved with val_loss = 0.9535
Epoch 11, accuracy: 0.4858
batch size: (903, 903)
✅ Epoch 12: New best model saved with val_loss = 0.9436
Epoch 12, accuracy: 0.4904
Epoch 12, Train Loss: 0.8738, Val Loss: 0.9436
batch size: (898, 898)
✅ Epoch 13: New best model saved with val_loss = 0.9354
Epoch 13, accuracy: 0.4904
batch size: (883, 883)
✅ Epoch 14: New best model saved with val_loss = 0.9290
Epoch 14, accuracy: 0.4881
Epoch 14, Train Loss: 0.8034, Val Loss: 0.9290
batch size: (904, 904)
Epoch 15, accuracy: 0.4865
batch size: (903, 903)
✅ Epoch 16: New best model saved with val_loss = 0.9208
Epoch 16, accuracy: 0.4842
Epoch 16, Train Loss: 0.7822, Val Loss: 0.9208
batch size: (890, 890)
✅ Epoch 17: New best model saved with val_loss = 0.9035
Epoch 17, accuracy: 0.4823
batch size: (882, 882)
✅ Epoch 18: New best model saved with val_loss = 0.8953
Epoch 18, accuracy: 0.4877
Epoch 18, Train Loss: 0.7223, Val Loss: 0.8953
batch size: (899, 899)
✅ Epoch 19: New best model saved with val_loss = 0.8934
Epoch 19, accuracy: 0.4912
batch size: (906, 906)
✅ Epoch 20: New best model saved with val_loss = 0.8795
Epoch 20, accuracy: 0.4920
Epoch 20, Train Loss: 0.7499, Val Loss: 0.8795
batch size: (889, 889)
Epoch 21, accuracy: 0.4885
batch size: (903, 903)
Epoch 22, accuracy: 0.4770
Epoch 22, Train Loss: 0.7481, Val Loss: 0.9080
batch size: (887, 887)
Epoch 23, accuracy: 0.4803
batch size: (884, 884)
Epoch 24, accuracy: 0.4386
Epoch 24, Train Loss: 0.6717, Val Loss: 0.9271
batch size: (903, 903)
Epoch 25, accuracy: 0.4459
batch size: (916, 916)
Epoch 26, accuracy: 0.4549
Epoch 26, Train Loss: 0.6500, Val Loss: 0.9003
batch size: (907, 907)
Epoch 27, accuracy: 0.4594
batch size: (901, 901)
Epoch 28, accuracy: 0.4586
Epoch 28, Train Loss: 0.6378, Val Loss: 0.8937
batch size: (897, 897)
Epoch 29, accuracy: 0.4570
batch size: (914, 914)
Epoch 30, accuracy: 0.4613
Epoch 30, Train Loss: 0.6402, Val Loss: 0.8981
batch size: (904, 904)
Epoch 31, accuracy: 0.4629
batch size: (921, 921)
Epoch 32, accuracy: 0.4640
Epoch 32, Train Loss: 0.6049, Val Loss: 0.8868
batch size: (905, 905)
✅ Epoch 33: New best model saved with val_loss = 0.8792
Epoch 33, accuracy: 0.4588
batch size: (887, 887)
Epoch 34, accuracy: 0.4666
Epoch 34, Train Loss: 0.6020, Val Loss: 0.8994
batch size: (901, 901)
Epoch 35, accuracy: 0.4620
batch size: (900, 900)
Epoch 36, accuracy: 0.4603
Epoch 36, Train Loss: 0.6169, Val Loss: 0.8983
batch size: (898, 898)
Epoch 37, accuracy: 0.4614
batch size: (894, 894)
Epoch 38, accuracy: 0.4613
Epoch 38, Train Loss: 0.6035, Val Loss: 0.8921
batch size: (889, 889)
Epoch 39, accuracy: 0.4623
batch size: (892, 892)
Epoch 40, accuracy: 0.4638
Epoch 40, Train Loss: 0.6336, Val Loss: 0.8898
batch size: (890, 890)
Epoch 41, accuracy: 0.4620
batch size: (909, 909)
Epoch 42, accuracy: 0.4643
Epoch 42, Train Loss: 0.6987, Val Loss: 0.8836
batch size: (892, 892)
Epoch 43, accuracy: 0.4585
batch size: (908, 908)
Epoch 44, accuracy: 0.4590
Epoch 44, Train Loss: 0.6116, Val Loss: 0.8875
batch size: (883, 883)
Epoch 45, accuracy: 0.4636
batch size: (908, 908)
Epoch 46, accuracy: 0.4643
Epoch 46, Train Loss: 0.6214, Val Loss: 0.8951
batch size: (883, 883)
✅ Epoch 47: New best model saved with val_loss = 0.8787
Epoch 47, accuracy: 0.4592
batch size: (894, 894)
Epoch 48, accuracy: 0.4599
Epoch 48, Train Loss: 0.6430, Val Loss: 0.9001
batch size: (920, 920)
Epoch 49, accuracy: 0.4637
Loaded best model with val_loss = 0.8786703944206238
test :accuracy 0.4615, f1_macro: 0.3756, f1_micro: 0.4615, auc: 0.7721
Training resGCN with 8 layers...
可训练参数: 531986_resGCN
不可训练参数: 0
batch size: (917, 917)
✅ Epoch 0: New best model saved with val_loss = 1.6202
Epoch 0, accuracy: 0.1690
Epoch 0, Train Loss: 1.0838, Val Loss: 1.6202
batch size: (916, 916)
✅ Epoch 1: New best model saved with val_loss = 1.0754
Epoch 1, accuracy: 0.4514
batch size: (891, 891)
Epoch 2, accuracy: 0.4295
Epoch 2, Train Loss: 1.1477, Val Loss: 1.0874
batch size: (907, 907)
Epoch 3, accuracy: 0.4257
batch size: (897, 897)
Epoch 4, accuracy: 0.4203
Epoch 4, Train Loss: 1.0939, Val Loss: 1.0947
batch size: (902, 902)
Epoch 5, accuracy: 0.4038
batch size: (922, 922)
Epoch 6, accuracy: 0.4033
Epoch 6, Train Loss: 1.0979, Val Loss: 1.0942
batch size: (886, 886)
Epoch 7, accuracy: 0.4010
batch size: (889, 889)
Epoch 8, accuracy: 0.4031
Epoch 8, Train Loss: 1.0992, Val Loss: 1.0940
batch size: (910, 910)
Epoch 9, accuracy: 0.4027
batch size: (903, 903)
Epoch 10, accuracy: 0.4001
Epoch 10, Train Loss: 1.0999, Val Loss: 1.0940
batch size: (904, 904)
Epoch 11, accuracy: 0.4044
batch size: (898, 898)
Epoch 12, accuracy: 0.4027
Epoch 12, Train Loss: 1.0976, Val Loss: 1.0940
batch size: (908, 908)
Epoch 13, accuracy: 0.4031
batch size: (882, 882)
Epoch 14, accuracy: 0.4024
Epoch 14, Train Loss: 1.0983, Val Loss: 1.0940
batch size: (908, 908)
Epoch 15, accuracy: 0.3969
batch size: (895, 895)
Epoch 16, accuracy: 0.4026
Epoch 16, Train Loss: 1.0992, Val Loss: 1.0940
batch size: (893, 893)
Epoch 17, accuracy: 0.4000
batch size: (882, 882)
Epoch 18, accuracy: 0.4014
Epoch 18, Train Loss: 1.0979, Val Loss: 1.0940
batch size: (899, 899)
Epoch 19, accuracy: 0.4023
batch size: (901, 901)
Epoch 20, accuracy: 0.4019
Epoch 20, Train Loss: 1.0986, Val Loss: 1.0940
batch size: (904, 904)
Epoch 21, accuracy: 0.4026
batch size: (918, 918)
Epoch 22, accuracy: 0.3984
Epoch 22, Train Loss: 1.0989, Val Loss: 1.0940
batch size: (906, 906)
Epoch 23, accuracy: 0.4009
batch size: (909, 909)
Epoch 24, accuracy: 0.4009
Epoch 24, Train Loss: 1.0987, Val Loss: 1.0940
batch size: (912, 912)
Epoch 25, accuracy: 0.4034
batch size: (906, 906)
Epoch 26, accuracy: 0.4020
Epoch 26, Train Loss: 1.0981, Val Loss: 1.0940
batch size: (900, 900)
Epoch 27, accuracy: 0.4005
batch size: (896, 896)
Epoch 28, accuracy: 0.4026
Epoch 28, Train Loss: 1.0988, Val Loss: 1.0940
batch size: (888, 888)
Epoch 29, accuracy: 0.4034
batch size: (869, 869)
Epoch 30, accuracy: 0.4039
Epoch 30, Train Loss: 1.0989, Val Loss: 1.0940
batch size: (908, 908)
Epoch 31, accuracy: 0.4022
batch size: (906, 906)
Epoch 32, accuracy: 0.3992
Epoch 32, Train Loss: 1.0990, Val Loss: 1.0940
batch size: (882, 882)
Epoch 33, accuracy: 0.4039
batch size: (902, 902)
Epoch 34, accuracy: 0.4015
Epoch 34, Train Loss: 1.0988, Val Loss: 1.0940
batch size: (884, 884)
Epoch 35, accuracy: 0.4034
batch size: (904, 904)
Epoch 36, accuracy: 0.4025
Epoch 36, Train Loss: 1.0983, Val Loss: 1.0940
batch size: (893, 893)
Epoch 37, accuracy: 0.4017
batch size: (910, 910)
Epoch 38, accuracy: 0.4004
Epoch 38, Train Loss: 1.0985, Val Loss: 1.0940
batch size: (896, 896)
Epoch 39, accuracy: 0.4034
batch size: (912, 912)
Epoch 40, accuracy: 0.3982
Epoch 40, Train Loss: 1.0988, Val Loss: 1.0940
batch size: (887, 887)
Epoch 41, accuracy: 0.4010
batch size: (901, 901)
Epoch 42, accuracy: 0.4053
Epoch 42, Train Loss: 1.0984, Val Loss: 1.0940
batch size: (891, 891)
Epoch 43, accuracy: 0.4055
batch size: (890, 890)
Epoch 44, accuracy: 0.4027
Epoch 44, Train Loss: 1.0993, Val Loss: 1.0940
batch size: (903, 903)
Epoch 45, accuracy: 0.4042
batch size: (905, 905)
Epoch 46, accuracy: 0.4074
Epoch 46, Train Loss: 1.0991, Val Loss: 1.0940
batch size: (889, 889)
Epoch 47, accuracy: 0.3979
batch size: (893, 893)
Epoch 48, accuracy: 0.4044
Epoch 48, Train Loss: 1.0975, Val Loss: 1.0940
batch size: (907, 907)
Epoch 49, accuracy: 0.4054
Loaded best model with val_loss = 1.0754203796386719
test :accuracy 0.4513, f1_macro: 0.3100, f1_micro: 0.4513, auc: 0.4880
Training resGCN with 32 layers...
可训练参数: 2129426_resGCN
不可训练参数: 0
batch size: (886, 886)
✅ Epoch 0: New best model saved with val_loss = 1.0972
Epoch 0, accuracy: 0.4030
Epoch 0, Train Loss: 175843.7969, Val Loss: 1.0972
batch size: (898, 898)
✅ Epoch 1: New best model saved with val_loss = 1.0964
Epoch 1, accuracy: 0.4053
/root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
batch size: (908, 908)
✅ Epoch 2: New best model saved with val_loss = 1.0957
Epoch 2, accuracy: 0.4037
Epoch 2, Train Loss: 1.0986, Val Loss: 1.0957
batch size: (885, 885)
✅ Epoch 3: New best model saved with val_loss = 1.0951
Epoch 3, accuracy: 0.4006
batch size: (915, 915)
✅ Epoch 4: New best model saved with val_loss = 1.0947
Epoch 4, accuracy: 0.4048
Epoch 4, Train Loss: 1.0987, Val Loss: 1.0947
batch size: (894, 894)
✅ Epoch 5: New best model saved with val_loss = 1.0943
Epoch 5, accuracy: 0.4016
batch size: (897, 897)
✅ Epoch 6: New best model saved with val_loss = 1.0940
Epoch 6, accuracy: 0.4039
Epoch 6, Train Loss: 1.0987, Val Loss: 1.0940
batch size: (901, 901)
✅ Epoch 7: New best model saved with val_loss = 1.0937
Epoch 7, accuracy: 0.4027
batch size: (898, 898)
✅ Epoch 8: New best model saved with val_loss = 1.0935
Epoch 8, accuracy: 0.4015
Epoch 8, Train Loss: 1.0988, Val Loss: 1.0935
batch size: (902, 902)
✅ Epoch 9: New best model saved with val_loss = 1.0933
Epoch 9, accuracy: 0.4013
batch size: (890, 890)
✅ Epoch 10: New best model saved with val_loss = 1.0931
Epoch 10, accuracy: 0.4027
Epoch 10, Train Loss: 1.0988, Val Loss: 1.0931
batch size: (912, 912)
✅ Epoch 11: New best model saved with val_loss = 1.0929
Epoch 11, accuracy: 0.4057
batch size: (911, 911)
✅ Epoch 12: New best model saved with val_loss = 1.0928
Epoch 12, accuracy: 0.4038
Epoch 12, Train Loss: 1.0988, Val Loss: 1.0928
batch size: (893, 893)
✅ Epoch 13: New best model saved with val_loss = 1.0927
Epoch 13, accuracy: 0.3981
batch size: (891, 891)
✅ Epoch 14: New best model saved with val_loss = 1.0927
Epoch 14, accuracy: 0.4017
Epoch 14, Train Loss: 1.0988, Val Loss: 1.0927
batch size: (879, 879)
✅ Epoch 15: New best model saved with val_loss = 1.0926
Epoch 15, accuracy: 0.4013
batch size: (878, 878)
✅ Epoch 16: New best model saved with val_loss = 1.0925
Epoch 16, accuracy: 0.4032
Epoch 16, Train Loss: 1.0988, Val Loss: 1.0925
batch size: (900, 900)
✅ Epoch 17: New best model saved with val_loss = 1.0925
Epoch 17, accuracy: 0.3999
batch size: (911, 911)
✅ Epoch 18: New best model saved with val_loss = 1.0925
Epoch 18, accuracy: 0.4006
Epoch 18, Train Loss: 1.0988, Val Loss: 1.0925
batch size: (896, 896)
✅ Epoch 19: New best model saved with val_loss = 1.0925
Epoch 19, accuracy: 0.4010
batch size: (889, 889)
Epoch 20, accuracy: 0.4006
Epoch 20, Train Loss: 1.0988, Val Loss: 1.0925
batch size: (888, 888)
Epoch 21, accuracy: 0.4005
batch size: (908, 908)
Epoch 22, accuracy: 0.3971
Epoch 22, Train Loss: 1.0988, Val Loss: 1.0926
batch size: (892, 892)
Epoch 23, accuracy: 0.4067
batch size: (906, 906)
Epoch 24, accuracy: 0.4035
Epoch 24, Train Loss: 1.0988, Val Loss: 1.0926
batch size: (879, 879)
Epoch 25, accuracy: 0.4025
batch size: (907, 907)
Epoch 26, accuracy: 0.4023
Epoch 26, Train Loss: 1.0988, Val Loss: 1.0926
batch size: (875, 875)
Epoch 27, accuracy: 0.3995
batch size: (938, 938)
Epoch 28, accuracy: 0.4003
Epoch 28, Train Loss: 1.0988, Val Loss: 1.0926
batch size: (910, 910)
Epoch 29, accuracy: 0.4050
batch size: (878, 878)
Epoch 30, accuracy: 0.4050
Epoch 30, Train Loss: 1.0988, Val Loss: 1.0926
batch size: (903, 903)
Epoch 31, accuracy: 0.3992
batch size: (882, 882)
Epoch 32, accuracy: 0.3989
Epoch 32, Train Loss: 1.0988, Val Loss: 1.0926
batch size: (891, 891)
Epoch 33, accuracy: 0.4017
batch size: (896, 896)
Epoch 34, accuracy: 0.4050
Epoch 34, Train Loss: 1.0988, Val Loss: 1.0926
batch size: (894, 894)
Epoch 35, accuracy: 0.4062
batch size: (895, 895)
Epoch 36, accuracy: 0.4052
Epoch 36, Train Loss: 1.0988, Val Loss: 1.0926
batch size: (897, 897)
Epoch 37, accuracy: 0.4015
batch size: (882, 882)
Epoch 38, accuracy: 0.4020
Epoch 38, Train Loss: 1.0988, Val Loss: 1.0926
batch size: (897, 897)
Epoch 39, accuracy: 0.3995
batch size: (907, 907)
Epoch 40, accuracy: 0.3983
Epoch 40, Train Loss: 1.0988, Val Loss: 1.0926
batch size: (913, 913)
Epoch 41, accuracy: 0.4023
batch size: (903, 903)
Epoch 42, accuracy: 0.4013
Epoch 42, Train Loss: 1.0988, Val Loss: 1.0926
batch size: (890, 890)
Epoch 43, accuracy: 0.4013
batch size: (906, 906)
Epoch 44, accuracy: 0.3979
Epoch 44, Train Loss: 1.0988, Val Loss: 1.0926
batch size: (868, 868)
Epoch 45, accuracy: 0.4031
batch size: (871, 871)
Epoch 46, accuracy: 0.4029
Epoch 46, Train Loss: 1.0988, Val Loss: 1.0926
batch size: (890, 890)
Epoch 47, accuracy: 0.4007
batch size: (913, 913)
Epoch 48, accuracy: 0.4053
Epoch 48, Train Loss: 1.0988, Val Loss: 1.0926
batch size: (910, 910)
Epoch 49, accuracy: 0.3991
Loaded best model with val_loss = 1.0924997329711914
test :accuracy 0.3957, f1_macro: 0.1890, f1_micro: 0.3957, auc: 0.5000
Training GINConv with 2 layers...
可训练参数: 99979_GINConv
不可训练参数: 0
batch size: (872, 872)
✅ Epoch 0: New best model saved with val_loss = 1.0794
Epoch 0, accuracy: 0.4049
Epoch 0, Train Loss: 1.2889, Val Loss: 1.0794
batch size: (903, 903)
✅ Epoch 1: New best model saved with val_loss = 1.0789
Epoch 1, accuracy: 0.4297
batch size: (900, 900)
Epoch 2, accuracy: 0.4197
Epoch 2, Train Loss: 0.5271, Val Loss: 1.0796
batch size: (893, 893)
✅ Epoch 3: New best model saved with val_loss = 1.0595
Epoch 3, accuracy: 0.4361
batch size: (909, 909)
✅ Epoch 4: New best model saved with val_loss = 1.0235
Epoch 4, accuracy: 0.4728
Epoch 4, Train Loss: 0.2938, Val Loss: 1.0235
batch size: (908, 908)
✅ Epoch 5: New best model saved with val_loss = 0.9842
Epoch 5, accuracy: 0.4819
batch size: (903, 903)
✅ Epoch 6: New best model saved with val_loss = 0.9533
Epoch 6, accuracy: 0.4878
Epoch 6, Train Loss: 0.1349, Val Loss: 0.9533
batch size: (910, 910)
✅ Epoch 7: New best model saved with val_loss = 0.9202
Epoch 7, accuracy: 0.4861
batch size: (906, 906)
✅ Epoch 8: New best model saved with val_loss = 0.8876
Epoch 8, accuracy: 0.4804
Epoch 8, Train Loss: 0.0266, Val Loss: 0.8876
batch size: (908, 908)
✅ Epoch 9: New best model saved with val_loss = 0.8577
Epoch 9, accuracy: 0.4830
batch size: (914, 914)
✅ Epoch 10: New best model saved with val_loss = 0.8293
Epoch 10, accuracy: 0.4803
Epoch 10, Train Loss: 0.0146, Val Loss: 0.8293
batch size: (909, 909)
✅ Epoch 11: New best model saved with val_loss = 0.8022
Epoch 11, accuracy: 0.4797
batch size: (897, 897)
✅ Epoch 12: New best model saved with val_loss = 0.7822
Epoch 12, accuracy: 0.5038
Epoch 12, Train Loss: 0.0185, Val Loss: 0.7822
batch size: (896, 896)
✅ Epoch 13: New best model saved with val_loss = 0.7715
Epoch 13, accuracy: 0.5312
batch size: (899, 899)
Epoch 14, accuracy: 0.5631
Epoch 14, Train Loss: 0.0111, Val Loss: 0.7784
batch size: (890, 890)
Epoch 15, accuracy: 0.5833
batch size: (901, 901)
Epoch 16, accuracy: 0.5948
Epoch 16, Train Loss: 0.0218, Val Loss: 0.7880
batch size: (893, 893)
✅ Epoch 17: New best model saved with val_loss = 0.7601
Epoch 17, accuracy: 0.6069
batch size: (901, 901)
✅ Epoch 18: New best model saved with val_loss = 0.7360
Epoch 18, accuracy: 0.6155
Epoch 18, Train Loss: 0.0025, Val Loss: 0.7360
batch size: (913, 913)
✅ Epoch 19: New best model saved with val_loss = 0.7092
Epoch 19, accuracy: 0.6237
batch size: (894, 894)
✅ Epoch 20: New best model saved with val_loss = 0.6801
Epoch 20, accuracy: 0.6273
Epoch 20, Train Loss: 0.0026, Val Loss: 0.6801
batch size: (916, 916)
✅ Epoch 21: New best model saved with val_loss = 0.6754
Epoch 21, accuracy: 0.6364
batch size: (900, 900)
✅ Epoch 22: New best model saved with val_loss = 0.6512
Epoch 22, accuracy: 0.6411
Epoch 22, Train Loss: 0.0027, Val Loss: 0.6512
batch size: (923, 923)
✅ Epoch 23: New best model saved with val_loss = 0.6448
Epoch 23, accuracy: 0.6473
batch size: (898, 898)
Epoch 24, accuracy: 0.6487
Epoch 24, Train Loss: 0.0003, Val Loss: 0.6714
batch size: (896, 896)
Epoch 25, accuracy: 0.6542
batch size: (899, 899)
Epoch 26, accuracy: 0.6591
Epoch 26, Train Loss: 0.0018, Val Loss: 0.6742
batch size: (895, 895)
Epoch 27, accuracy: 0.6629
batch size: (908, 908)
Epoch 28, accuracy: 0.6714
Epoch 28, Train Loss: 0.0000, Val Loss: 0.7191
batch size: (887, 887)
Epoch 29, accuracy: 0.6750
batch size: (906, 906)
Epoch 30, accuracy: 0.6749
/root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
/root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
Epoch 30, Train Loss: 0.0000, Val Loss: 0.7165
batch size: (898, 898)
Epoch 31, accuracy: 0.6796
batch size: (905, 905)
Epoch 32, accuracy: 0.6830
Epoch 32, Train Loss: 0.0000, Val Loss: 0.7801
batch size: (907, 907)
Epoch 33, accuracy: 0.6850
batch size: (912, 912)
Epoch 34, accuracy: 0.6860
Epoch 34, Train Loss: 0.0002, Val Loss: 0.7800
batch size: (907, 907)
Epoch 35, accuracy: 0.6899
batch size: (884, 884)
Epoch 36, accuracy: 0.6908
Epoch 36, Train Loss: 0.0001, Val Loss: 0.8472
batch size: (886, 886)
Epoch 37, accuracy: 0.6930
batch size: (900, 900)
Epoch 38, accuracy: 0.6986
Epoch 38, Train Loss: 0.0000, Val Loss: 0.8538
batch size: (898, 898)
Epoch 39, accuracy: 0.7004
batch size: (903, 903)
Epoch 40, accuracy: 0.7007
Epoch 40, Train Loss: 0.0000, Val Loss: 0.9524
batch size: (898, 898)
Epoch 41, accuracy: 0.6999
batch size: (887, 887)
Epoch 42, accuracy: 0.7038
Epoch 42, Train Loss: 0.0001, Val Loss: 0.9823
batch size: (893, 893)
Epoch 43, accuracy: 0.7036
batch size: (898, 898)
Epoch 44, accuracy: 0.7036
Epoch 44, Train Loss: 0.0001, Val Loss: 1.1063
batch size: (898, 898)
Epoch 45, accuracy: 0.7065
batch size: (901, 901)
Epoch 46, accuracy: 0.7069
Epoch 46, Train Loss: 0.0000, Val Loss: 1.0936
batch size: (906, 906)
Epoch 47, accuracy: 0.7081
batch size: (877, 877)
Epoch 48, accuracy: 0.7059
Epoch 48, Train Loss: 0.0000, Val Loss: 1.1981
batch size: (892, 892)
Epoch 49, accuracy: 0.7075
Loaded best model with val_loss = 0.6447845101356506
test :accuracy 0.6459, f1_macro: 0.6222, f1_micro: 0.6459, auc: 0.8446
Training GINConv with 8 layers...
可训练参数: 300427_GINConv
不可训练参数: 0
batch size: (906, 906)
✅ Epoch 0: New best model saved with val_loss = 1.1101
Epoch 0, accuracy: 0.3744
Epoch 0, Train Loss: 1.3794, Val Loss: 1.1101
batch size: (903, 903)
Epoch 1, accuracy: 0.3739
batch size: (883, 883)
Epoch 2, accuracy: 0.3756
Epoch 2, Train Loss: 1.5216, Val Loss: 1.5664
batch size: (901, 901)
Epoch 3, accuracy: 0.3751
batch size: (911, 911)
Epoch 4, accuracy: 0.3750
Epoch 4, Train Loss: 0.9656, Val Loss: 1.2118
batch size: (915, 915)
Epoch 5, accuracy: 0.3724
batch size: (900, 900)
Epoch 6, accuracy: 0.4175
Epoch 6, Train Loss: 0.9488, Val Loss: 1.1473
batch size: (904, 904)
Epoch 7, accuracy: 0.4190
batch size: (900, 900)
✅ Epoch 8: New best model saved with val_loss = 1.1095
Epoch 8, accuracy: 0.4201
Epoch 8, Train Loss: 1.0020, Val Loss: 1.1095
batch size: (914, 914)
✅ Epoch 9: New best model saved with val_loss = 1.1054
Epoch 9, accuracy: 0.4208
batch size: (888, 888)
Epoch 10, accuracy: 0.4228
Epoch 10, Train Loss: 0.9594, Val Loss: 1.1091
batch size: (886, 886)
Epoch 11, accuracy: 0.3705
batch size: (899, 899)
Epoch 12, accuracy: 0.3744
Epoch 12, Train Loss: 0.9188, Val Loss: 1.1082
batch size: (893, 893)
Epoch 13, accuracy: 0.3736
batch size: (904, 904)
Epoch 14, accuracy: 0.3719
Epoch 14, Train Loss: 0.9278, Val Loss: 1.1180
batch size: (894, 894)
Epoch 15, accuracy: 0.3727
batch size: (892, 892)
Epoch 16, accuracy: 0.3760
Epoch 16, Train Loss: 0.9207, Val Loss: 1.1184
batch size: (898, 898)
Epoch 17, accuracy: 0.3715
batch size: (904, 904)
Epoch 18, accuracy: 0.3708
Epoch 18, Train Loss: 0.9299, Val Loss: 1.1174
batch size: (912, 912)
Epoch 19, accuracy: 0.3724
batch size: (886, 886)
Epoch 20, accuracy: 0.3704
Epoch 20, Train Loss: 0.9278, Val Loss: 1.1151
batch size: (895, 895)
Epoch 21, accuracy: 0.3720
batch size: (881, 881)
Epoch 22, accuracy: 0.3723
Epoch 22, Train Loss: 0.9086, Val Loss: 1.1141
batch size: (890, 890)
Epoch 23, accuracy: 0.3711
batch size: (897, 897)
Epoch 24, accuracy: 0.3706
Epoch 24, Train Loss: 0.9059, Val Loss: 1.1119
batch size: (894, 894)
Epoch 25, accuracy: 0.3727
batch size: (912, 912)
Epoch 26, accuracy: 0.3703
Epoch 26, Train Loss: 0.9006, Val Loss: 1.1136
batch size: (909, 909)
Epoch 27, accuracy: 0.3748
batch size: (913, 913)
Epoch 28, accuracy: 0.3754
Epoch 28, Train Loss: 0.9102, Val Loss: 1.1240
batch size: (909, 909)
Epoch 29, accuracy: 0.3752
batch size: (907, 907)
Epoch 30, accuracy: 0.3724
Epoch 30, Train Loss: 0.9120, Val Loss: 1.1132
batch size: (899, 899)
Epoch 31, accuracy: 0.3727
batch size: (902, 902)
Epoch 32, accuracy: 0.3677
Epoch 32, Train Loss: 0.9427, Val Loss: 1.1134
batch size: (912, 912)
Epoch 33, accuracy: 0.3711
batch size: (880, 880)
Epoch 34, accuracy: 0.3728
Epoch 34, Train Loss: 0.9135, Val Loss: 1.1149
batch size: (891, 891)
Epoch 35, accuracy: 0.3738
batch size: (893, 893)
Epoch 36, accuracy: 0.3708
Epoch 36, Train Loss: 0.9055, Val Loss: 1.1166
batch size: (905, 905)
Epoch 37, accuracy: 0.3698
batch size: (886, 886)
Epoch 38, accuracy: 0.3684
Epoch 38, Train Loss: 0.9016, Val Loss: 1.1198
batch size: (906, 906)
Epoch 39, accuracy: 0.3726
batch size: (905, 905)
Epoch 40, accuracy: 0.3765
Epoch 40, Train Loss: 0.9098, Val Loss: 1.1164
batch size: (891, 891)
Epoch 41, accuracy: 0.3741
batch size: (896, 896)
Epoch 42, accuracy: 0.3754
Epoch 42, Train Loss: 0.9297, Val Loss: 1.1167
batch size: (913, 913)
Epoch 43, accuracy: 0.3708
batch size: (884, 884)
Epoch 44, accuracy: 0.3724
Epoch 44, Train Loss: 0.8976, Val Loss: 1.1211
batch size: (890, 890)
Epoch 45, accuracy: 0.3721
batch size: (904, 904)
Epoch 46, accuracy: 0.3712
Epoch 46, Train Loss: 0.9332, Val Loss: 1.1138
batch size: (903, 903)
Epoch 47, accuracy: 0.3683
batch size: (895, 895)
Epoch 48, accuracy: 0.3707
Epoch 48, Train Loss: 0.9579, Val Loss: 1.1127
batch size: (908, 908)
Epoch 49, accuracy: 0.3721
Loaded best model with val_loss = 1.1054224967956543
test :accuracy 0.4167, f1_macro: 0.2789, f1_micro: 0.4167, auc: 0.5121
Training GINConv with 32 layers...
可训练参数: 1102219_GINConv
不可训练参数: 0
batch size: (893, 893)
✅ Epoch 0: New best model saved with val_loss = 1770.9020
Epoch 0, accuracy: 0.2139
Epoch 0, Train Loss: 1.1714, Val Loss: 1770.9020
batch size: (896, 896)
✅ Epoch 1: New best model saved with val_loss = 63.9191
Epoch 1, accuracy: 0.1675
batch size: (899, 899)
✅ Epoch 2: New best model saved with val_loss = 62.7378
Epoch 2, accuracy: 0.2167
Epoch 2, Train Loss: 1.9871, Val Loss: 62.7378
batch size: (909, 909)
✅ Epoch 3: New best model saved with val_loss = 6.6944
Epoch 3, accuracy: 0.2130
batch size: (901, 901)
✅ Epoch 4: New best model saved with val_loss = 4.7424
Epoch 4, accuracy: 0.2131
Epoch 4, Train Loss: 1.2775, Val Loss: 4.7424
batch size: (913, 913)
✅ Epoch 5: New best model saved with val_loss = 1.4138
Epoch 5, accuracy: 0.3977
batch size: (885, 885)
✅ Epoch 6: New best model saved with val_loss = 1.1791
Epoch 6, accuracy: 0.4042
Epoch 6, Train Loss: 1.0720, Val Loss: 1.1791
batch size: (900, 900)
Epoch 7, accuracy: 0.4030
batch size: (916, 916)
Epoch 8, accuracy: 0.3573
Epoch 8, Train Loss: 1.3406, Val Loss: 1.1986
batch size: (903, 903)
✅ Epoch 9: New best model saved with val_loss = 1.1700
Epoch 9, accuracy: 0.3550
batch size: (899, 899)
Epoch 10, accuracy: 0.3568
Epoch 10, Train Loss: 1.2852, Val Loss: 1.2040
batch size: (893, 893)
✅ Epoch 11: New best model saved with val_loss = 1.1512
Epoch 11, accuracy: 0.4044
batch size: (904, 904)
✅ Epoch 12: New best model saved with val_loss = 1.1181
Epoch 12, accuracy: 0.4049
Epoch 12, Train Loss: 1.0729, Val Loss: 1.1181
batch size: (918, 918)
Epoch 13, accuracy: 0.4039
batch size: (900, 900)
✅ Epoch 14: New best model saved with val_loss = 1.1057
Epoch 14, accuracy: 0.4051
Epoch 14, Train Loss: 1.0755, Val Loss: 1.1057
batch size: (908, 908)
Epoch 15, accuracy: 0.4065
batch size: (902, 902)
Epoch 16, accuracy: 0.3547
Epoch 16, Train Loss: 1.0673, Val Loss: 1.1205
batch size: (917, 917)
Epoch 17, accuracy: 0.3746
batch size: (890, 890)
Epoch 18, accuracy: 0.4196
Epoch 18, Train Loss: 1.1665, Val Loss: 1.1114
batch size: (903, 903)
Epoch 19, accuracy: 0.4167
batch size: (908, 908)
Epoch 20, accuracy: 0.4207
Epoch 20, Train Loss: 1.4092, Val Loss: 1.1253
batch size: (898, 898)
Epoch 21, accuracy: 0.4234
batch size: (894, 894)
✅ Epoch 22: New best model saved with val_loss = 1.1046
Epoch 22, accuracy: 0.4215
Epoch 22, Train Loss: 1.0751, Val Loss: 1.1046
batch size: (915, 915)
✅ Epoch 23: New best model saved with val_loss = 1.0986
Epoch 23, accuracy: 0.4193
batch size:/root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
/root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
 (914, 914)
Epoch 24, accuracy: 0.4189
Epoch 24, Train Loss: 1.4971, Val Loss: 1.1211
batch size: (923, 923)
Epoch 25, accuracy: 0.4171
batch size: (913, 913)
Epoch 26, accuracy: 0.4190
Epoch 26, Train Loss: 1.4641, Val Loss: 1.1071
batch size: (904, 904)
Epoch 27, accuracy: 0.4196
batch size: (917, 917)
Epoch 28, accuracy: 0.4186
Epoch 28, Train Loss: 1.2072, Val Loss: 1.1119
batch size: (886, 886)
Epoch 29, accuracy: 0.4212
batch size: (888, 888)
Epoch 30, accuracy: 0.4167
Epoch 30, Train Loss: 1.0858, Val Loss: 1.1158
batch size: (898, 898)
Epoch 31, accuracy: 0.4227
batch size: (903, 903)
Epoch 32, accuracy: 0.4209
Epoch 32, Train Loss: 1.2274, Val Loss: 1.1238
batch size: (893, 893)
Epoch 33, accuracy: 0.4210
batch size: (881, 881)
Epoch 34, accuracy: 0.4210
Epoch 34, Train Loss: 1.0688, Val Loss: 1.1121
batch size: (902, 902)
Epoch 35, accuracy: 0.4213
batch size: (897, 897)
Epoch 36, accuracy: 0.4236
Epoch 36, Train Loss: 1.0736, Val Loss: 1.1067
batch size: (893, 893)
Epoch 37, accuracy: 0.4211
batch size: (895, 895)
Epoch 38, accuracy: 0.4228
Epoch 38, Train Loss: 1.2400, Val Loss: 1.1146
batch size: (904, 904)
Epoch 39, accuracy: 0.4186
batch size: (910, 910)
Epoch 40, accuracy: 0.4189
Epoch 40, Train Loss: 1.1419, Val Loss: 1.1164
batch size: (901, 901)
Epoch 41, accuracy: 0.4223
batch size: (903, 903)
Epoch 42, accuracy: 0.4203
Epoch 42, Train Loss: 1.1007, Val Loss: 1.1215
batch size: (890, 890)
Epoch 43, accuracy: 0.4172
batch size: (889, 889)
Epoch 44, accuracy: 0.4201
Epoch 44, Train Loss: 1.1280, Val Loss: 1.1141
batch size: (904, 904)
Epoch 45, accuracy: 0.4210
batch size: (889, 889)
Epoch 46, accuracy: 0.4206
Epoch 46, Train Loss: 1.0722, Val Loss: 1.1029
batch size: (895, 895)
Epoch 47, accuracy: 0.4196
batch size: (903, 903)
Epoch 48, accuracy: 0.4173
Epoch 48, Train Loss: 1.0747, Val Loss: 1.1081
batch size: (888, 888)
Epoch 49, accuracy: 0.4195
Loaded best model with val_loss = 1.098576545715332
test :accuracy 0.4213, f1_macro: 0.2753, f1_micro: 0.4213, auc: 0.5011
Training mlp with 2 layers...
可训练参数: 83209_mlp
不可训练参数: 0
batch size: (903, 903)
✅ Epoch 0: New best model saved with val_loss = 1.0965
Epoch 0, accuracy: 0.4323
Epoch 0, Train Loss: 1.0994, Val Loss: 1.0965
batch size: (903, 903)
✅ Epoch 1: New best model saved with val_loss = 1.0953
Epoch 1, accuracy: 0.5073
batch size: (904, 904)
✅ Epoch 2: New best model saved with val_loss = 1.0914
Epoch 2, accuracy: 0.5184
Epoch 2, Train Loss: 1.0845, Val Loss: 1.0914
batch size: (895, 895)
✅ Epoch 3: New best model saved with val_loss = 1.0834
Epoch 3, accuracy: 0.5790
batch size: (918, 918)
✅ Epoch 4: New best model saved with val_loss = 1.0705
Epoch 4, accuracy: 0.6589
Epoch 4, Train Loss: 1.0453, Val Loss: 1.0705
batch size: (905, 905)
✅ Epoch 5: New best model saved with val_loss = 1.0528
Epoch 5, accuracy: 0.6919
batch size: (901, 901)
✅ Epoch 6: New best model saved with val_loss = 1.0310
Epoch 6, accuracy: 0.6964
Epoch 6, Train Loss: 0.9704, Val Loss: 1.0310
batch size: (878, 878)
✅ Epoch 7: New best model saved with val_loss = 1.0061
Epoch 7, accuracy: 0.6994
batch size: (903, 903)
✅ Epoch 8: New best model saved with val_loss = 0.9789
Epoch 8, accuracy: 0.6992
Epoch 8, Train Loss: 0.8582, Val Loss: 0.9789
batch size: (880, 880)
✅ Epoch 9: New best model saved with val_loss = 0.9497
Epoch 9, accuracy: 0.7002
batch size: (915, 915)
✅ Epoch 10: New best model saved with val_loss = 0.9184
Epoch 10, accuracy: 0.6977
Epoch 10, Train Loss: 0.7029, Val Loss: 0.9184
batch size: (890, 890)
✅ Epoch 11: New best model saved with val_loss = 0.8856
Epoch 11, accuracy: 0.6985
batch size: (888, 888)
✅ Epoch 12: New best model saved with val_loss = 0.8516
Epoch 12, accuracy: 0.6957
Epoch 12, Train Loss: 0.5087, Val Loss: 0.8516
batch size: (902, 902)
✅ Epoch 13: New best model saved with val_loss = 0.8175
Epoch 13, accuracy: 0.7007
batch size: (891, 891)
✅ Epoch 14: New best model saved with val_loss = 0.7853
Epoch 14, accuracy: 0.7037
Epoch 14, Train Loss: 0.3089, Val Loss: 0.7853
batch size: (885, 885)
✅ Epoch 15: New best model saved with val_loss = 0.7585
Epoch 15, accuracy: 0.7057
batch size: (898, 898)
✅ Epoch 16: New best model saved with val_loss = 0.7408
Epoch 16, accuracy: 0.7091
Epoch 16, Train Loss: 0.1505, Val Loss: 0.7408
batch size: (902, 902)
✅ Epoch 17: New best model saved with val_loss = 0.7351
Epoch 17, accuracy: 0.7076
batch size: (892, 892)
Epoch 18, accuracy: 0.7028
Epoch 18, Train Loss: 0.0589, Val Loss: 0.7417
batch size: (912, 912)
Epoch 19, accuracy: 0.7067
batch size: (912, 912)
Epoch 20, accuracy: 0.7042
Epoch 20, Train Loss: 0.0197, Val Loss: 0.7843
batch size: (896, 896)
Epoch 21, accuracy: 0.7078
batch size: (885, 885)
Epoch 22, accuracy: 0.7066
Epoch 22, Train Loss: 0.0063, Val Loss: 0.8477
batch size: (908, 908)
Epoch 23, accuracy: 0.7058
batch size: (912, 912)
Epoch 24, accuracy: 0.7042
Epoch 24, Train Loss: 0.0022, Val Loss: 0.8836
batch size: (894, 894)
Epoch 25, accuracy: 0.7055
batch size: (888, 888)
Epoch 26, accuracy: 0.7064
Epoch 26, Train Loss: 0.0020, Val Loss: 0.8883
batch size: (873, 873)
Epoch 27, accuracy: 0.7065
batch size: (888, 888)
Epoch 28, accuracy: 0.7042
Epoch 28, Train Loss: 0.0019, Val Loss: 0.8914
batch size: (889, 889)
Epoch 29, accuracy: 0.7042
batch size: (894, 894)
Epoch 30, accuracy: 0.7091
Epoch 30, Train Loss: 0.0018, Val Loss: 0.8925
batch size: (894, 894)
Epoch 31, accuracy: 0.7073
batch size: (917, 917)
Epoch 32, accuracy: 0.7056
Epoch 32, Train Loss: 0.0018, Val Loss: 0.8926
batch size: (910, 910)
Epoch 33, accuracy: 0.7048
batch size: (895, 895)
Epoch 34, accuracy: 0.7067
Epoch 34, Train Loss: 0.0018, Val Loss: 0.8926
batch size: (894, 894)
Epoch 35, accuracy: 0.7058
batch size: (904, 904)
Epoch 36, accuracy: 0.7066
Epoch 36, Train Loss: 0.0018, Val Loss: 0.8925
batch size: (897, 897)
Epoch 37, accuracy: 0.7044
batch size: (904, 904)
Epoch 38, accuracy: 0.7055
Epoch 38, Train Loss: 0.0018, Val Loss: 0.8925
batch size: (890, 890)
Epoch 39, accuracy: 0.7064
batch size: (898, 898)
Epoch 40, accuracy: 0.7072
Epoch 40, Train Loss: 0.0018, Val Loss: 0.8925
batch size: (912, 912)
Epoch 41, accuracy: 0.7074
batch size: (903, 903)
Epoch 42, accuracy: 0.7067
Epoch 42, Train Loss: 0.0018, Val Loss: 0.8925
batch size: (891, 891)
Epoch 43, accuracy: 0.7062
batch size: (891, 891)
Epoch 44, accuracy: 0.7083
Epoch 44, Train Loss: 0.0018, Val Loss: 0.8925
batch size: (893, 893)
Epoch 45, accuracy: 0.7065
batch size: (903, 903)
Epoch 46, accuracy: 0.7067
Epoch 46, Train Loss: 0.0018, Val Loss: 0.8925
batch size: (906, 906)
Epoch 47, accuracy: 0.7069
batch size: (895, 895)
Epoch 48, accuracy: 0.7059
Epoch 48, Train Loss: 0.0018, Val Loss: 0.8925
batch size: (913, 913)
Epoch 49, accuracy: 0.7081
Loaded best model with val_loss = 0.7351285219192505
test :accuracy 0.7067, f1_macro: 0.7024, f1_micro: 0.7067, auc: 0.8540
Training mlp with 8 layers...
可训练参数: 184585_mlp
不可训练参数: 0
batch size: (901, 901)
✅ Epoch 0: New best model saved with val_loss = 1.0962
Epoch 0, accuracy: 0.4045
Epoch 0, Train Loss: 1.0996, Val Loss: 1.0962
batch size: (896, 896)
Epoch 1, accuracy: 0.4020
batch size: (901, 901)
Epoch 2, accuracy: 0.3986
Epoch 2, Train Loss: 1.0990, Val Loss: 1.1003
batch size: (886, 886)
Epoch 3, accuracy: 0.1698
batch size: (916, 916)
Epoch 4, accuracy: 0.4265
Epoch 4, Train Loss: 1.0986, Val Loss: 1.0995
batch size: (886, 886)
Epoch 5, accuracy: 0.4296
batch size: (912, 912)
Epoch 6, accuracy: 0.4321
Epoch 6, Train Loss: 1.0987, Val Loss: 1.0976
batch size: (914, 914)
Epoch 7, accuracy: 0.4294
batch size: (896, 896)
Epoch 8, accuracy: 0.4311
Epoch 8, Train Loss: 1.0987, Val Loss: 1.0976
batch size: (877, 877)
Epoch 9, accuracy: 0.4267
batch size: (897, 897)
Epoch 10, accuracy: 0.4280
Epoch 10, Train Loss: 1.0987, Val Loss: 1.0977
batch size: (894, 894)
Epoch 11, accuracy: 0.4312
batch size: (893, 893)
Epoch 12, accuracy: 0.4251
Epoch 12, Train Loss: 1.0987, Val Loss: 1.0979
batch size: (891, 891)
Epoch 13, accuracy: 0.4303
batch size: (897, 897)
Epoch 14, accuracy: 0.4303
Epoch 14, Train Loss: 1.0986, Val Loss: 1.0980
batch size: (883, 883)
/root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
/root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
/root/miniconda3/lib/python3.12/site-packages/torch_geometric/sampler/neighbor_sampler.py:61: UserWarning: Using 'NeighborSampler' without a 'pyg-lib' installation is deprecated and will be removed soon. Please install 'pyg-lib' for accelerated neighborhood sampling
  warnings.warn(f"Using '{self.__class__.__name__}' without a "
Epoch 15, accuracy: 0.4316
batch size: (894, 894)
Epoch 16, accuracy: 0.4301
Epoch 16, Train Loss: 1.0986, Val Loss: 1.0980
batch size: (896, 896)
Epoch 17, accuracy: 0.4300
batch size: (898, 898)
Epoch 18, accuracy: 0.4305
Epoch 18, Train Loss: 1.0986, Val Loss: 1.0980
batch size: (908, 908)
Epoch 19, accuracy: 0.4280
batch size: (893, 893)
Epoch 20, accuracy: 0.4275
Epoch 20, Train Loss: 1.0986, Val Loss: 1.0980
batch size: (883, 883)
Epoch 21, accuracy: 0.4297
batch size: (903, 903)
Epoch 22, accuracy: 0.4288
Epoch 22, Train Loss: 1.0986, Val Loss: 1.0980
batch size: (879, 879)
Epoch 23, accuracy: 0.4291
batch size: (901, 901)
Epoch 24, accuracy: 0.4326
Epoch 24, Train Loss: 1.0986, Val Loss: 1.0980
batch size: (897, 897)
Epoch 25, accuracy: 0.4293
batch size: (914, 914)
Epoch 26, accuracy: 0.4279
Epoch 26, Train Loss: 1.0986, Val Loss: 1.0980
batch size: (887, 887)
Epoch 27, accuracy: 0.4281
batch size: (896, 896)
Epoch 28, accuracy: 0.4301
Epoch 28, Train Loss: 1.0986, Val Loss: 1.0980
batch size: (906, 906)
Epoch 29, accuracy: 0.4294
batch size: (899, 899)
Epoch 30, accuracy: 0.4306
Epoch 30, Train Loss: 1.0986, Val Loss: 1.0980
batch size: (915, 915)
Epoch 31, accuracy: 0.4269
batch size: (916, 916)
Epoch 32, accuracy: 0.4294
Epoch 32, Train Loss: 1.0986, Val Loss: 1.0980
batch size: (922, 922)
Epoch 33, accuracy: 0.4292
batch size: (875, 875)
Epoch 34, accuracy: 0.4282
Epoch 34, Train Loss: 1.0986, Val Loss: 1.0980
batch size: (892, 892)
Epoch 35, accuracy: 0.4322
batch size: (907, 907)
Epoch 36, accuracy: 0.4309
Epoch 36, Train Loss: 1.0986, Val Loss: 1.0980
batch size: (902, 902)
Epoch 37, accuracy: 0.4292
batch size: (895, 895)
Epoch 38, accuracy: 0.4300
Epoch 38, Train Loss: 1.0986, Val Loss: 1.0980
batch size: (906, 906)
Epoch 39, accuracy: 0.4308
batch size: (895, 895)
Epoch 40, accuracy: 0.4291
Epoch 40, Train Loss: 1.0986, Val Loss: 1.0980
batch size: (899, 899)
Epoch 41, accuracy: 0.4304
batch size: (896, 896)
Epoch 42, accuracy: 0.4313
Epoch 42, Train Loss: 1.0986, Val Loss: 1.0980
batch size: (899, 899)
Epoch 43, accuracy: 0.4294
batch size: (906, 906)
Epoch 44, accuracy: 0.4320
Epoch 44, Train Loss: 1.0986, Val Loss: 1.0980
batch size: (893, 893)
Epoch 45, accuracy: 0.4267
batch size: (909, 909)
Epoch 46, accuracy: 0.4250
Epoch 46, Train Loss: 1.0986, Val Loss: 1.0980
batch size: (897, 897)
Epoch 47, accuracy: 0.4294
batch size: (887, 887)
Epoch 48, accuracy: 0.4332
Epoch 48, Train Loss: 1.0986, Val Loss: 1.0980
batch size: (880, 880)
Epoch 49, accuracy: 0.4274
Loaded best model with val_loss = 1.0961750745773315
test :accuracy 0.4031, f1_macro: 0.1915, f1_micro: 0.4031, auc: 0.5528
Training mlp with 32 layers...
可训练参数: 590089_mlp
不可训练参数: 0
batch size: (886, 886)
✅ Epoch 0: New best model saved with val_loss = 1.0907
Epoch 0, accuracy: 0.4308
Epoch 0, Train Loss: 1.0987, Val Loss: 1.0907
batch size: (908, 908)
Epoch 1, accuracy: 0.4316
batch size: (881, 881)
Epoch 2, accuracy: 0.1644
Epoch 2, Train Loss: 1.0987, Val Loss: 1.1004
batch size: (919, 919)
Epoch 3, accuracy: 0.1670
batch size: (891, 891)
Epoch 4, accuracy: 0.1664
Epoch 4, Train Loss: 1.0987, Val Loss: 1.1029
batch size: (910, 910)
Epoch 5, accuracy: 0.1668
batch size: (908, 908)
Epoch 6, accuracy: 0.1674
Epoch 6, Train Loss: 1.0987, Val Loss: 1.0990
batch size: (899, 899)
Epoch 7, accuracy: 0.1684
batch size: (895, 895)
Epoch 8, accuracy: 0.4293
Epoch 8, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (903, 903)
Epoch 9, accuracy: 0.4307
batch size: (903, 903)
Epoch 10, accuracy: 0.4336
Epoch 10, Train Loss: 1.0986, Val Loss: 1.0983
batch size: (905, 905)
Epoch 11, accuracy: 0.4294
batch size: (911, 911)
Epoch 12, accuracy: 0.4315
Epoch 12, Train Loss: 1.0986, Val Loss: 1.0981
batch size: (908, 908)
Epoch 13, accuracy: 0.4276
batch size: (911, 911)
Epoch 14, accuracy: 0.4256
Epoch 14, Train Loss: 1.0986, Val Loss: 1.0981
batch size: (885, 885)
Epoch 15, accuracy: 0.4316
batch size: (905, 905)
Epoch 16, accuracy: 0.4290
Epoch 16, Train Loss: 1.0986, Val Loss: 1.0981
batch size: (911, 911)
Epoch 17, accuracy: 0.4297
batch size: (905, 905)
Epoch 18, accuracy: 0.4277
Epoch 18, Train Loss: 1.0986, Val Loss: 1.0981
batch size: (911, 911)
Epoch 19, accuracy: 0.4307
batch size: (911, 911)
Epoch 20, accuracy: 0.4336
Epoch 20, Train Loss: 1.0986, Val Loss: 1.0981
batch size: (898, 898)
Epoch 21, accuracy: 0.4325
batch size: (901, 901)
Epoch 22, accuracy: 0.4286
Epoch 22, Train Loss: 1.0986, Val Loss: 1.0981
batch size: (892, 892)
Epoch 23, accuracy: 0.4291
batch size: (913, 913)
Epoch 24, accuracy: 0.4308
Epoch 24, Train Loss: 1.0986, Val Loss: 1.0981
batch size: (889, 889)
Epoch 25, accuracy: 0.4266
batch size: (889, 889)
Epoch 26, accuracy: 0.4331
Epoch 26, Train Loss: 1.0986, Val Loss: 1.0981
batch size: (893, 893)
Epoch 27, accuracy: 0.4287
batch size: (917, 917)
Epoch 28, accuracy: 0.4314
Epoch 28, Train Loss: 1.0986, Val Loss: 1.0981
batch size: (896, 896)
Epoch 29, accuracy: 0.4339
batch size: (897, 897)
Epoch 30, accuracy: 0.4325
Epoch 30, Train Loss: 1.0986, Val Loss: 1.0981
batch size: (897, 897)
Epoch 31, accuracy: 0.4298
batch size: (886, 886)
Epoch 32, accuracy: 0.4286
Epoch 32, Train Loss: 1.0986, Val Loss: 1.0981
batch size: (905, 905)
Epoch 33, accuracy: 0.4307
batch size: (895, 895)
Epoch 34, accuracy: 0.4285
Epoch 34, Train Loss: 1.0986, Val Loss: 1.0981
batch size: (882, 882)
Epoch 35, accuracy: 0.4330
batch size: (901, 901)
Epoch 36, accuracy: 0.4308
Epoch 36, Train Loss: 1.0986, Val Loss: 1.0981
batch size: (892, 892)
Epoch 37, accuracy: 0.4302
batch size: (900, 900)
Epoch 38, accuracy: 0.4352
Epoch 38, Train Loss: 1.0986, Val Loss: 1.0981
batch size: (874, 874)
Epoch 39, accuracy: 0.4311
batch size: (890, 890)
Epoch 40, accuracy: 0.4303
Epoch 40, Train Loss: 1.0986, Val Loss: 1.0981
batch size: (886, 886)
Epoch 41, accuracy: 0.4286
batch size: (927, 927)
Epoch 42, accuracy: 0.4341
Epoch 42, Train Loss: 1.0986, Val Loss: 1.0981
batch size: (902, 902)
Epoch 43, accuracy: 0.4314
batch size: (910, 910)
Epoch 44, accuracy: 0.4290
Epoch 44, Train Loss: 1.0986, Val Loss: 1.0981
batch size: (909, 909)
Epoch 45, accuracy: 0.4300
batch size: (902, 902)
Epoch 46, accuracy: 0.4308
Epoch 46, Train Loss: 1.0986, Val Loss: 1.0981
batch size: (900, 900)
Epoch 47, accuracy: 0.4309
batch size: (902, 902)
Epoch 48, accuracy: 0.4316
Epoch 48, Train Loss: 1.0986, Val Loss: 1.0981
batch size: (888, 888)
Epoch 49, accuracy: 0.4296
Loaded best model with val_loss = 1.0907467603683472
test :accuracy 0.4306, f1_macro: 0.2006, f1_micro: 0.4306, auc: 0.5000
Final Results: {'GCN_2_Pubmed': np.float64(0.7112354064012074), 'GCN_8_Pubmed': np.float64(0.4320282155453368), 'GCN_32_Pubmed': np.float64(0.43277385947683245), 'GraphSAGE_2_Pubmed': np.float64(0.7153994354585779), 'GraphSAGE_8_Pubmed': np.float64(0.39851090232228326), 'GraphSAGE_32_Pubmed': np.float64(0.1902280420452521), 'GAT_2_Pubmed': np.float64(0.7394773409834596), 'GAT_8_Pubmed': np.float64(0.7091573133796544), 'GAT_32_Pubmed': np.float64(0.4044426744546219), 'JKNet_2_Pubmed': np.float64(0.48927945340944845), 'JKNet_8_Pubmed': np.float64(0.4055095184770437), 'JKNet_32_Pubmed': np.float64(0.4013275923932544), 'resGCN_2_Pubmed': np.float64(0.46148995585983243), 'resGCN_8_Pubmed': np.float64(0.45125870380289235), 'resGCN_32_Pubmed': np.float64(0.3957060646303674), 'GINConv_2_Pubmed': np.float64(0.6458972648432288), 'GINConv_8_Pubmed': np.float64(0.4167109929078014), 'GINConv_32_Pubmed': np.float64(0.42133726647000985), 'mlp_2_Pubmed': np.float64(0.7066976661003309), 'mlp_8_Pubmed': np.float64(0.40305528178478633), 'mlp_32_Pubmed': np.float64(0.4305530934231519)} ['133385_GCN_0', '532745_GCN_0', '2130185_GCN_0', '262153_GraphSAGE_0', '1054729_GraphSAGE_0', '4225033_GraphSAGE_0', '196495_GAT_0', '1090447_GAT_0', '4666255_GAT_0', '391942_JKNet_0', '1184518_JKNet_0', '4354822_JKNet_0', '132626_resGCN_0', '531986_resGCN_0', '2129426_resGCN_0', '99979_GINConv_0', '300427_GINConv_0', '1102219_GINConv_0', '83209_mlp_0', '184585_mlp_0', '590089_mlp_0']
========== Running baseline 3/3 ==========
Training GCN with 2 layers...
可训练参数: 133385_GCN
不可训练参数: 0
batch size: (893, 893)
✅ Epoch 0: New best model saved with val_loss = 1.0724
/root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
Epoch 0, accuracy: 0.6301
Epoch 0, Train Loss: 1.2242, Val Loss: 1.0724
batch size: (896, 896)
✅ Epoch 1: New best model saved with val_loss = 1.0505
Epoch 1, accuracy: 0.6122
batch size: (892, 892)
✅ Epoch 2: New best model saved with val_loss = 1.0307
Epoch 2, accuracy: 0.5863
Epoch 2, Train Loss: 0.1607, Val Loss: 1.0307
batch size: (905, 905)
✅ Epoch 3: New best model saved with val_loss = 1.0150
Epoch 3, accuracy: 0.5808
batch size: (896, 896)
✅ Epoch 4: New best model saved with val_loss = 0.9991
Epoch 4, accuracy: 0.5932
Epoch 4, Train Loss: 0.0524, Val Loss: 0.9991
batch size: (907, 907)
✅ Epoch 5: New best model saved with val_loss = 0.9852
Epoch 5, accuracy: 0.6169
batch size: (889, 889)
✅ Epoch 6: New best model saved with val_loss = 0.9702
Epoch 6, accuracy: 0.6340
Epoch 6, Train Loss: 0.0243, Val Loss: 0.9702
batch size: (919, 919)
✅ Epoch 7: New best model saved with val_loss = 0.9571
Epoch 7, accuracy: 0.6501
batch size: (911, 911)
✅ Epoch 8: New best model saved with val_loss = 0.9453
Epoch 8, accuracy: 0.6585
Epoch 8, Train Loss: 0.0218, Val Loss: 0.9453
batch size: (878, 878)
✅ Epoch 9: New best model saved with val_loss = 0.9315
Epoch 9, accuracy: 0.6634
batch size: (880, 880)
✅ Epoch 10: New best model saved with val_loss = 0.9153
Epoch 10, accuracy: 0.6683
Epoch 10, Train Loss: 0.0051, Val Loss: 0.9153
batch size: (896, 896)
✅ Epoch 11: New best model saved with val_loss = 0.9050
Epoch 11, accuracy: 0.6752
batch size: (887, 887)
✅ Epoch 12: New best model saved with val_loss = 0.8945
Epoch 12, accuracy: 0.6781
Epoch 12, Train Loss: 0.0200, Val Loss: 0.8945
batch size: (922, 922)
✅ Epoch 13: New best model saved with val_loss = 0.8847
Epoch 13, accuracy: 0.6860
batch size: (885, 885)
✅ Epoch 14: New best model saved with val_loss = 0.8747
Epoch 14, accuracy: 0.6897
Epoch 14, Train Loss: 0.0084, Val Loss: 0.8747
batch size: (883, 883)
✅ Epoch 15: New best model saved with val_loss = 0.8576
Epoch 15, accuracy: 0.6948
batch size: (885, 885)
✅ Epoch 16: New best model saved with val_loss = 0.8498
Epoch 16, accuracy: 0.6959
Epoch 16, Train Loss: 0.0027, Val Loss: 0.8498
batch size: (907, 907)
✅ Epoch 17: New best model saved with val_loss = 0.8376
Epoch 17, accuracy: 0.7017
batch size: (900, 900)
✅ Epoch 18: New best model saved with val_loss = 0.8217
Epoch 18, accuracy: 0.7027
Epoch 18, Train Loss: 0.0018, Val Loss: 0.8217
batch size: (893, 893)
✅ Epoch 19: New best model saved with val_loss = 0.8063
Epoch 19, accuracy: 0.7057
batch size: (907, 907)
✅ Epoch 20: New best model saved with val_loss = 0.7949
Epoch 20, accuracy: 0.7043
Epoch 20, Train Loss: 0.0021, Val Loss: 0.7949
batch size: (895, 895)
✅ Epoch 21: New best model saved with val_loss = 0.7814
Epoch 21, accuracy: 0.7081
batch size: (907, 907)
✅ Epoch 22: New best model saved with val_loss = 0.7683
Epoch 22, accuracy: 0.7077
Epoch 22, Train Loss: 0.0011, Val Loss: 0.7683
batch size: (900, 900)
✅ Epoch 23: New best model saved with val_loss = 0.7569
Epoch 23, accuracy: 0.7080
batch size: (893, 893)
✅ Epoch 24: New best model saved with val_loss = 0.7442
Epoch 24, accuracy: 0.7131
Epoch 24, Train Loss: 0.0010, Val Loss: 0.7442
batch size: (903, 903)
✅ Epoch 25: New best model saved with val_loss = 0.7264
Epoch 25, accuracy: 0.7162
batch size: (882, 882)
✅ Epoch 26: New best model saved with val_loss = 0.7109
Epoch 26, accuracy: 0.7157
Epoch 26, Train Loss: 0.0021, Val Loss: 0.7109
batch size: (908, 908)
✅ Epoch 27: New best model saved with val_loss = 0.7038
Epoch 27, accuracy: 0.7168
batch size: (920, 920)
✅ Epoch 28: New best model saved with val_loss = 0.6921
Epoch 28, accuracy: 0.7162
Epoch 28, Train Loss: 0.0007, Val Loss: 0.6921
batch size: (890, 890)
✅ Epoch 29: New best model saved with val_loss = 0.6781
Epoch 29, accuracy: 0.7186
batch size: (889, 889)
✅ Epoch 30: New best model saved with val_loss = 0.6705
Epoch 30, accuracy: 0.7167
Epoch 30, Train Loss: 0.0056, Val Loss: 0.6705
batch size: (910, 910)
✅ Epoch 31: New best model saved with val_loss = 0.6568
Epoch 31, accuracy: 0.7194
batch size: (892, 892)
✅ Epoch 32: New best model saved with val_loss = 0.6499
Epoch 32, accuracy: 0.7210
Epoch 32, Train Loss: 0.0007, Val Loss: 0.6499
batch size: (878, 878)
✅ Epoch 33: New best model saved with val_loss = 0.6408
Epoch 33, accuracy: 0.7233
batch size: (896, 896)
✅ Epoch 34: New best model saved with val_loss = 0.6323
Epoch 34, accuracy: 0.7219
Epoch 34, Train Loss: 0.0005, Val Loss: 0.6323
batch size: (892, 892)
✅ Epoch 35: New best model saved with val_loss = 0.6215
Epoch 35, accuracy: 0.7212
batch size: (897, 897)
✅ Epoch 36: New best model saved with val_loss = 0.6133
Epoch 36, accuracy: 0.7226
Epoch 36, Train Loss: 0.0003, Val Loss: 0.6133
batch size: (899, 899)
✅ Epoch 37: New best model saved with val_loss = 0.6056
Epoch 37, accuracy: 0.7215
batch size: (893, 893)
✅ Epoch 38: New best model saved with val_loss = 0.6018
Epoch 38, accuracy: 0.7217
Epoch 38, Train Loss: 0.0008, Val Loss: 0.6018
batch size: (899, 899)
✅ Epoch 39: New best model saved with val_loss = 0.5953
Epoch 39, accuracy: 0.7207
batch size: (884, 884)
✅ Epoch 40: New best model saved with val_loss = 0.5854
Epoch 40, accuracy: 0.7200
Epoch 40, Train Loss: 0.0010, Val Loss: 0.5854
batch size: (908, 908)
Epoch 41, accuracy: 0.7226
batch size: (903, 903)
✅ Epoch 42: New best model saved with val_loss = 0.5763
Epoch 42, accuracy: 0.7213
Epoch 42, Train Loss: 0.0004, Val Loss: 0.5763
batch size: (905, 905)
✅ Epoch 43: New best model saved with val_loss = 0.5675
Epoch 43, accuracy: 0.7224
batch size: (901, 901)
Epoch 44, accuracy: 0.7212
Epoch 44, Train Loss: 0.0008, Val Loss: 0.5777
batch size: (885, 885)
✅ Epoch 45: New best model saved with val_loss = 0.5566
Epoch 45, accuracy: 0.7206
batch size: (904, 904)
Epoch 46, accuracy: 0.7217
Epoch 46, Train Loss: 0.0026, Val Loss: 0.5767
batch size: (910, 910)
Epoch 47, accuracy: 0.7185
batch size: (892, 892)
Epoch 48, accuracy: 0.7174
Epoch 48, Train Loss: 0.0010, Val Loss: 0.5813
batch size: (903, 903)
Epoch 49, accuracy: 0.7157
Loaded best model with val_loss = 0.5566133856773376
test :accuracy 0.7205, f1_macro: 0.7154, f1_micro: 0.7205, auc: 0.8752
Training GCN with 8 layers...
可训练参数: 532745_GCN
不可训练参数: 0
batch size: (892, 892)
✅ Epoch 0: New best model saved with val_loss = 1.1485
Epoch 0, accuracy: 0.1693
Epoch 0, Train Loss: 1.2425, Val Loss: 1.1485
batch size: (908, 908)
Epoch 1, accuracy: 0.1783
batch size: (887, 887)
Epoch 2, accuracy: 0.4313
Epoch 2, Train Loss: 1.1115, Val Loss: 1.2657
batch size: (906, 906)
Epoch 3, accuracy: 0.4267
batch size: (908, 908)
Epoch 4, accuracy: 0.1659
Epoch 4, Train Loss: 1.0214, Val Loss: 1.5777
batch size: (890, 890)
Epoch 5, accuracy: 0.1687
batch size: (869, 869)
Epoch 6, accuracy: 0.1678
Epoch 6, Train Loss: 0.9532, Val Loss: 2.6349
batch size: (909, 909)
Epoch 7, accuracy: 0.1653
batch size: (908, 908)
Epoch 8, accuracy: 0.1668
Epoch 8, Train Loss: 0.6837, Val Loss: 2.2304
batch size: (884, 884)
Epoch 9, accuracy: 0.1668
batch size: (909, 909)
Epoch 10, accuracy: 0.1663
Epoch 10, Train Loss: 0.7753, Val Loss: 2.1366
batch size: (898, 898)
Epoch 11, accuracy: 0.1659
batch size: (905, 905)
Epoch 12, accuracy: 0.1665
Epoch 12, Train Loss: 0.6500, Val Loss: 2.1141
batch size: (894, 894)
Epoch 13, accuracy: 0.1651
batch size: (911, 911)
Epoch 14, accuracy: 0.1678
Epoch 14, Train Loss: 0.7358, Val Loss: 2.1072
batch size: (886, 886)
Epoch 15, accuracy: 0.1686
batch size: (902, 902)
Epoch 16, accuracy: 0.1671
Epoch 16, Train Loss: 0.7218, Val Loss: 2.2321
batch size: (917, 917)
Epoch 17, accuracy: 0.1672
batch size: (908, 908)
Epoch 18, accuracy: 0.1675
Epoch 18, Train Loss: 0.7027, Val Loss: 2.1860
batch size: (909, 909)
Epoch 19, accuracy: 0.1663
batch size: (908, 908)
Epoch 20, accuracy: 0.1668
Epoch 20, Train Loss: 0.7281, Val Loss: 2.1824
batch size: (881, 881)
Epoch 21, accuracy: 0.1658
batch size: (895, 895)
Epoch 22, accuracy: 0.1670
Epoch 22, Train Loss: 0.7271, Val Loss: 2.1553
batch size: (888, 888)
Epoch 23, accuracy: 0.1684
batch size: (906, 906)
Epoch 24, accuracy: 0.1694
/root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
/root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
Epoch 24, Train Loss: 0.6662, Val Loss: 2.1468
batch size: (910, 910)
Epoch 25, accuracy: 0.1675
batch size: (888, 888)
Epoch 26, accuracy: 0.1691
Epoch 26, Train Loss: 0.7388, Val Loss: 2.1798
batch size: (904, 904)
Epoch 27, accuracy: 0.1719
batch size: (887, 887)
Epoch 28, accuracy: 0.1664
Epoch 28, Train Loss: 0.7204, Val Loss: 1.9990
batch size: (909, 909)
Epoch 29, accuracy: 0.1639
batch size: (896, 896)
Epoch 30, accuracy: 0.1673
Epoch 30, Train Loss: 0.6608, Val Loss: 2.0728
batch size: (901, 901)
Epoch 31, accuracy: 0.1657
batch size: (901, 901)
Epoch 32, accuracy: 0.1675
Epoch 32, Train Loss: 0.7333, Val Loss: 2.0486
batch size: (906, 906)
Epoch 33, accuracy: 0.1668
batch size: (893, 893)
Epoch 34, accuracy: 0.1702
Epoch 34, Train Loss: 0.6844, Val Loss: 2.1400
batch size: (902, 902)
Epoch 35, accuracy: 0.1683
batch size: (906, 906)
Epoch 36, accuracy: 0.1697
Epoch 36, Train Loss: 0.5581, Val Loss: 2.1040
batch size: (926, 926)
Epoch 37, accuracy: 0.1687
batch size: (889, 889)
Epoch 38, accuracy: 0.1677
Epoch 38, Train Loss: 0.5824, Val Loss: 2.1345
batch size: (916, 916)
Epoch 39, accuracy: 0.1700
batch size: (891, 891)
Epoch 40, accuracy: 0.1666
Epoch 40, Train Loss: 0.6463, Val Loss: 2.1020
batch size: (891, 891)
Epoch 41, accuracy: 0.1672
batch size: (881, 881)
Epoch 42, accuracy: 0.1666
Epoch 42, Train Loss: 0.6561, Val Loss: 2.2437
batch size: (899, 899)
Epoch 43, accuracy: 0.1677
batch size: (902, 902)
Epoch 44, accuracy: 0.1658
Epoch 44, Train Loss: 0.7142, Val Loss: 2.2214
batch size: (904, 904)
Epoch 45, accuracy: 0.1671
batch size: (895, 895)
Epoch 46, accuracy: 0.1667
Epoch 46, Train Loss: 0.6716, Val Loss: 2.0605
batch size: (874, 874)
Epoch 47, accuracy: 0.1652
batch size: (901, 901)
Epoch 48, accuracy: 0.1681
Epoch 48, Train Loss: 0.6725, Val Loss: 2.0669
batch size: (921, 921)
Epoch 49, accuracy: 0.1665
Loaded best model with val_loss = 1.1484770774841309
test :accuracy 0.1683, f1_macro: 0.0985, f1_micro: 0.1683, auc: 0.5305
Training GCN with 32 layers...
可训练参数: 2130185_GCN
不可训练参数: 0
batch size: (903, 903)
✅ Epoch 0: New best model saved with val_loss = 1.1882
Epoch 0, accuracy: 0.1665
Epoch 0, Train Loss: 1.2545, Val Loss: 1.1882
batch size: (904, 904)
Epoch 1, accuracy: 0.1673
batch size: (910, 910)
✅ Epoch 2: New best model saved with val_loss = 1.1261
Epoch 2, accuracy: 0.1659
Epoch 2, Train Loss: 1.2262, Val Loss: 1.1261
batch size: (900, 900)
✅ Epoch 3: New best model saved with val_loss = 1.1036
Epoch 3, accuracy: 0.4304
batch size: (873, 873)
Epoch 4, accuracy: 0.1865
Epoch 4, Train Loss: 1.2539, Val Loss: 1.1157
batch size: (909, 909)
Epoch 5, accuracy: 0.1637
batch size: (903, 903)
Epoch 6, accuracy: 0.1675
Epoch 6, Train Loss: 1.1641, Val Loss: 1.1375
batch size: (899, 899)
Epoch 7, accuracy: 0.1668
batch size: (893, 893)
Epoch 8, accuracy: 0.3590
Epoch 8, Train Loss: 1.1711, Val Loss: 1.1055
batch size: (882, 882)
Epoch 9, accuracy: 0.1679
batch size: (903, 903)
Epoch 10, accuracy: 0.1667
Epoch 10, Train Loss: 1.0835, Val Loss: 1.1145
batch size: (889, 889)
Epoch 11, accuracy: 0.1690
batch size: (886, 886)
Epoch 12, accuracy: 0.1655
Epoch 12, Train Loss: 1.1665, Val Loss: 1.1107
batch size: (893, 893)
✅ Epoch 13: New best model saved with val_loss = 1.1031
Epoch 13, accuracy: 0.1648
batch size: (903, 903)
Epoch 14, accuracy: 0.1658
Epoch 14, Train Loss: 1.1560, Val Loss: 1.1058
batch size: (917, 917)
Epoch 15, accuracy: 0.1672
batch size: (906, 906)
Epoch 16, accuracy: 0.1648
Epoch 16, Train Loss: 1.1865, Val Loss: 1.1056
batch size: (883, 883)
✅ Epoch 17: New best model saved with val_loss = 1.1009
Epoch 17, accuracy: 0.1675
batch size: (881, 881)
Epoch 18, accuracy: 0.1681
Epoch 18, Train Loss: 1.0742, Val Loss: 1.1057
batch size: (915, 915)
Epoch 19, accuracy: 0.1673
batch size: (909, 909)
Epoch 20, accuracy: 0.1691
Epoch 20, Train Loss: 1.2166, Val Loss: 1.1018
batch size: (887, 887)
Epoch 21, accuracy: 0.1654
batch size: (896, 896)
Epoch 22, accuracy: 0.1665
Epoch 22, Train Loss: 1.2060, Val Loss: 1.1071
batch size: (902, 902)
Epoch 23, accuracy: 0.1692
batch size: (898, 898)
Epoch 24, accuracy: 0.1690
Epoch 24, Train Loss: 1.1940, Val Loss: 1.1065
batch size: (902, 902)
Epoch 25, accuracy: 0.1645
batch size: (903, 903)
Epoch 26, accuracy: 0.1685
Epoch 26, Train Loss: 1.2340, Val Loss: 1.1094
batch size: (901, 901)
Epoch 27, accuracy: 0.1669
batch size: (898, 898)
Epoch 28, accuracy: 0.1672
Epoch 28, Train Loss: 1.1417, Val Loss: 1.1103
batch size: (893, 893)
Epoch 29, accuracy: 0.1685
batch size: (906, 906)
Epoch 30, accuracy: 0.1658
Epoch 30, Train Loss: 1.2329, Val Loss: 1.1125
batch size: (903, 903)
Epoch 31, accuracy: 0.1659
batch size: (896, 896)
Epoch 32, accuracy: 0.1658
Epoch 32, Train Loss: 1.1117, Val Loss: 1.1084
batch size: (916, 916)
Epoch 33, accuracy: 0.1688
batch size: (908, 908)
Epoch 34, accuracy: 0.1663
Epoch 34, Train Loss: 1.1726, Val Loss: 1.1078
batch size: (890, 890)
Epoch 35, accuracy: 0.1663
batch size: (899, 899)
Epoch 36, accuracy: 0.1677
Epoch 36, Train Loss: 1.0987, Val Loss: 1.1131
batch size: (896, 896)
Epoch 37, accuracy: 0.1692
batch size: (903, 903)
Epoch 38, accuracy: 0.1668
Epoch 38, Train Loss: 1.0780, Val Loss: 1.1083
batch size: (888, 888)
Epoch 39, accuracy: 0.1660
batch size: (891, 891)
Epoch 40, accuracy: 0.1688
Epoch 40, Train Loss: 1.1108, Val Loss: 1.1092
batch size: (895, 895)
Epoch 41, accuracy: 0.1691
batch size: (900, 900)
Epoch 42, accuracy: 0.1656
Epoch 42, Train Loss: 1.1169, Val Loss: 1.1130
batch size: (902, 902)
Epoch 43, accuracy: 0.1658
batch size: (891, 891)
Epoch 44, accuracy: 0.1680
Epoch 44, Train Loss: 1.0566, Val Loss: 1.1116
batch size: (900, 900)
Epoch 45, accuracy: 0.1710
batch size: (889, 889)
Epoch 46, accuracy: 0.1699
Epoch 46, Train Loss: 1.0811, Val Loss: 1.1109
batch size: (900, 900)
Epoch 47, accuracy: 0.1686
batch size: (896, 896)
Epoch 48, accuracy: 0.1649
Epoch 48, Train Loss: 1.0821, Val Loss: 1.1104
batch size: (902, 902)
Epoch 49, accuracy: 0.1678
Loaded best model with val_loss = 1.1009100675582886
test :accuracy 0.1665, f1_macro: 0.0952, f1_micro: 0.1665, auc: 0.5128
Training GraphSAGE with 2 layers...
可训练参数: 262153_GraphSAGE
不可训练参数: 0
batch size: (906, 906)
✅ Epoch 0: New best model saved with val_loss = 1.0986
Epoch 0, accuracy: 0.3735
Epoch 0, Train Loss: 1.1715, Val Loss: 1.0986
batch size: (883, 883)
✅ Epoch 1: New best model saved with val_loss = 1.0949
Epoch 1, accuracy: 0.4175
batch size: (895, 895)
✅ Epoch 2: New best model saved with val_loss = 1.0851
Epoch 2, accuracy: 0.5176
Epoch 2, Train Loss: 0.3050, Val Loss: 1.0851
batch size: (896, 896)
✅ Epoch 3: New best model saved with val_loss = 1.0716
Epoch 3, accuracy: 0.5720
batch size: (896, 896)
✅ Epoch 4: New best model saved with val_loss = 1.0577
Epoch 4, accuracy: 0.6277
Epoch 4, Train Loss: 0.0828, Val Loss: 1.0577
batch size: (910, 910)
✅ Epoch 5: New best model saved with val_loss = 1.0443
Epoch 5, accuracy: 0.6465
batch size: (889, 889)
✅ Epoch 6: New best model saved with val_loss = 1.0306
Epoch 6, accuracy: 0.6586
Epoch 6, Train Loss: 0.0116, Val Loss: 1.0306
batch size: (903, 903)
✅ Epoch 7: New best model saved with val_loss = 1.0187
Epoch 7, accuracy: 0.6699
batch size: (878, 878)
✅ Epoch 8: New best model saved with val_loss = 1.0060
Epoch 8, accuracy: 0.6824
Epoch 8, Train Loss: 0.0024, Val Loss: 1.0060
batch size: (928, 928)
✅ Epoch 9: New best model saved with val_loss = 0.9931
Epoch 9, accuracy: 0.6877
batch size: (881, 881)
✅ Epoch 10: New best model saved with val_loss = 0.9797
Epoch 10, accuracy: 0.6960
Epoch 10, Train Loss: 0.0003, Val Loss: 0.9797
batch size: (895, 895)
✅ Epoch 11: New best model saved with val_loss = 0.9673
Epoch 11, accuracy: 0.7028
batch size: (915, 915)
✅ Epoch 12: New best model saved with val_loss = 0.9543
Epoch 12, accuracy: 0.7073
Epoch 12, Train Loss: 0.0013, Val Loss: 0.9543
batch size: (904, 904)
✅ Epoch 13: New best model saved with val_loss = 0.9417
Epoch 13, accuracy: 0.7087
batch size: (887, 887)
✅ Epoch 14: New best model saved with val_loss = 0.9304
Epoch 14, accuracy: 0.7085
/root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
Epoch 14, Train Loss: 0.0008, Val Loss: 0.9304
batch size: (891, 891)
✅ Epoch 15: New best model saved with val_loss = 0.9157
Epoch 15, accuracy: 0.7087
batch size: (919, 919)
✅ Epoch 16: New best model saved with val_loss = 0.9029
Epoch 16, accuracy: 0.7123
Epoch 16, Train Loss: 0.0012, Val Loss: 0.9029
batch size: (904, 904)
✅ Epoch 17: New best model saved with val_loss = 0.8907
Epoch 17, accuracy: 0.7136
batch size: (908, 908)
✅ Epoch 18: New best model saved with val_loss = 0.8753
Epoch 18, accuracy: 0.7126
Epoch 18, Train Loss: 0.0003, Val Loss: 0.8753
batch size: (902, 902)
✅ Epoch 19: New best model saved with val_loss = 0.8648
Epoch 19, accuracy: 0.7174
batch size: (893, 893)
✅ Epoch 20: New best model saved with val_loss = 0.8494
Epoch 20, accuracy: 0.7196
Epoch 20, Train Loss: 0.0003, Val Loss: 0.8494
batch size: (906, 906)
✅ Epoch 21: New best model saved with val_loss = 0.8356
Epoch 21, accuracy: 0.7219
batch size: (902, 902)
✅ Epoch 22: New best model saved with val_loss = 0.8235
Epoch 22, accuracy: 0.7223
Epoch 22, Train Loss: 0.0002, Val Loss: 0.8235
batch size: (903, 903)
✅ Epoch 23: New best model saved with val_loss = 0.8075
Epoch 23, accuracy: 0.7227
batch size: (907, 907)
✅ Epoch 24: New best model saved with val_loss = 0.7956
Epoch 24, accuracy: 0.7254
Epoch 24, Train Loss: 0.0006, Val Loss: 0.7956
batch size: (877, 877)
✅ Epoch 25: New best model saved with val_loss = 0.7843
Epoch 25, accuracy: 0.7245
batch size: (902, 902)
✅ Epoch 26: New best model saved with val_loss = 0.7728
Epoch 26, accuracy: 0.7272
Epoch 26, Train Loss: 0.0002, Val Loss: 0.7728
batch size: (895, 895)
✅ Epoch 27: New best model saved with val_loss = 0.7596
Epoch 27, accuracy: 0.7278
batch size: (918, 918)
✅ Epoch 28: New best model saved with val_loss = 0.7475
Epoch 28, accuracy: 0.7300
Epoch 28, Train Loss: 0.0003, Val Loss: 0.7475
batch size: (887, 887)
✅ Epoch 29: New best model saved with val_loss = 0.7359
Epoch 29, accuracy: 0.7260
batch size: (910, 910)
✅ Epoch 30: New best model saved with val_loss = 0.7237
Epoch 30, accuracy: 0.7287
Epoch 30, Train Loss: 0.0002, Val Loss: 0.7237
batch size: (902, 902)
✅ Epoch 31: New best model saved with val_loss = 0.7120
Epoch 31, accuracy: 0.7317
batch size: (904, 904)
✅ Epoch 32: New best model saved with val_loss = 0.7000
Epoch 32, accuracy: 0.7282
Epoch 32, Train Loss: 0.0001, Val Loss: 0.7000
batch size: (899, 899)
✅ Epoch 33: New best model saved with val_loss = 0.6901
Epoch 33, accuracy: 0.7269
batch size: (909, 909)
✅ Epoch 34: New best model saved with val_loss = 0.6805
Epoch 34, accuracy: 0.7274
Epoch 34, Train Loss: 0.0001, Val Loss: 0.6805
batch size: (908, 908)
✅ Epoch 35: New best model saved with val_loss = 0.6711
Epoch 35, accuracy: 0.7237
batch size: (915, 915)
✅ Epoch 36: New best model saved with val_loss = 0.6609
Epoch 36, accuracy: 0.7236
Epoch 36, Train Loss: 0.0000, Val Loss: 0.6609
batch size: (902, 902)
✅ Epoch 37: New best model saved with val_loss = 0.6544
Epoch 37, accuracy: 0.7229
batch size: (897, 897)
✅ Epoch 38: New best model saved with val_loss = 0.6410
Epoch 38, accuracy: 0.7200
Epoch 38, Train Loss: 0.0001, Val Loss: 0.6410
batch size: (902, 902)
✅ Epoch 39: New best model saved with val_loss = 0.6378
Epoch 39, accuracy: 0.7185
batch size: (891, 891)
✅ Epoch 40: New best model saved with val_loss = 0.6275
Epoch 40, accuracy: 0.7189
Epoch 40, Train Loss: 0.0001, Val Loss: 0.6275
batch size: (892, 892)
✅ Epoch 41: New best model saved with val_loss = 0.6194
Epoch 41, accuracy: 0.7178
batch size: (894, 894)
Epoch 42, accuracy: 0.7166
Epoch 42, Train Loss: 0.0002, Val Loss: 0.6196
batch size: (920, 920)
✅ Epoch 43: New best model saved with val_loss = 0.6165
Epoch 43, accuracy: 0.7161
batch size: (920, 920)
✅ Epoch 44: New best model saved with val_loss = 0.6023
Epoch 44, accuracy: 0.7133
Epoch 44, Train Loss: 0.0001, Val Loss: 0.6023
batch size: (909, 909)
Epoch 45, accuracy: 0.7153
batch size: (892, 892)
Epoch 46, accuracy: 0.7146
Epoch 46, Train Loss: 0.0001, Val Loss: 0.6046
batch size: (899, 899)
Epoch 47, accuracy: 0.7148
batch size: (895, 895)
✅ Epoch 48: New best model saved with val_loss = 0.5990
Epoch 48, accuracy: 0.7141
Epoch 48, Train Loss: 0.0002, Val Loss: 0.5990
batch size: (909, 909)
✅ Epoch 49: New best model saved with val_loss = 0.5986
Epoch 49, accuracy: 0.7162
Loaded best model with val_loss = 0.5986008644104004
test :accuracy 0.7151, f1_macro: 0.7175, f1_micro: 0.7151, auc: 0.8655
Training GraphSAGE with 8 layers...
可训练参数: 1054729_GraphSAGE
不可训练参数: 0
batch size: (903, 903)
✅ Epoch 0: New best model saved with val_loss = 1.0934
Epoch 0, accuracy: 0.4321
Epoch 0, Train Loss: 1.2154, Val Loss: 1.0934
batch size: (901, 901)
Epoch 1, accuracy: 0.3950
batch size: (900, 900)
Epoch 2, accuracy: 0.1672
Epoch 2, Train Loss: 1.1077, Val Loss: 1.0986
batch size: (895, 895)
Epoch 3, accuracy: 0.1680
batch size: (894, 894)
Epoch 4, accuracy: 0.1713
Epoch 4, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (884, 884)
Epoch 5, accuracy: 0.1714
batch size: (917, 917)
Epoch 6, accuracy: 0.1670
Epoch 6, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (889, 889)
Epoch 7, accuracy: 0.1690
batch size: (907, 907)
Epoch 8, accuracy: 0.1693
Epoch 8, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (900, 900)
Epoch 9, accuracy: 0.1694
batch size: (893, 893)
Epoch 10, accuracy: 0.1677
Epoch 10, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (891, 891)
Epoch 11, accuracy: 0.1670
batch size: (904, 904)
Epoch 12, accuracy: 0.1660
Epoch 12, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (882, 882)
Epoch 13, accuracy: 0.1663
batch size: (914, 914)
Epoch 14, accuracy: 0.1683
Epoch 14, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (887, 887)
Epoch 15, accuracy: 0.1669
batch size: (897, 897)
Epoch 16, accuracy: 0.1689
Epoch 16, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (912, 912)
Epoch 17, accuracy: 0.1691
batch size: (911, 911)
Epoch 18, accuracy: 0.1666
Epoch 18, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (902, 902)
Epoch 19, accuracy: 0.1669
batch size: (878, 878)
Epoch 20, accuracy: 0.1666
Epoch 20, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (894, 894)
Epoch 21, accuracy: 0.1683
batch size: (905, 905)
Epoch 22, accuracy: 0.1709
Epoch 22, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (885, 885)
Epoch 23, accuracy: 0.1670
batch size: (902, 902)
Epoch 24, accuracy: 0.1709
Epoch 24, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (897, 897)
Epoch 25, accuracy: 0.1676
batch size: (883, 883)
Epoch 26, accuracy: 0.1667
Epoch 26, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (916, 916)
Epoch 27, accuracy: 0.1679
batch size: (906, 906)
Epoch 28, accuracy: 0.1671
Epoch 28, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (894, 894)
Epoch 29, accuracy: 0.1659
batch size: (903, 903)
Epoch 30, accuracy: 0.1689
Epoch 30, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (894, 894)
Epoch 31, accuracy: 0.1664
batch size: (903, 903)
Epoch 32, accuracy: 0.1677
Epoch 32, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (901, 901)
Epoch 33, accuracy: 0.1676
batch size: (915, 915)
Epoch 34, accuracy: 0.1702
Epoch 34, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (910, 910)
Epoch 35, accuracy: 0.1650
batch size: (900, 900)
Epoch 36, accuracy: 0.1665
Epoch 36, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (902, 902)
Epoch 37, accuracy: 0.1662
batch size: (905, 905)
Epoch 38, accuracy: 0.1699
Epoch 38, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (912, 912)
Epoch 39, accuracy: 0.1665
batch size: (890, 890)
Epoch 40, accuracy: 0.1670
Epoch 40, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (912, 912)
Epoch 41, accuracy: 0.1682
batch size: (894, 894)
Epoch 42, accuracy: 0.1653
Epoch 42, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (894, 894)
Epoch 43, accuracy: 0.1677
batch size: (910, 910)
Epoch 44, accuracy: 0.1684
Epoch 44, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (913, 913)
Epoch 45, accuracy: 0.1703
batch size: (882, 882)
Epoch 46, accuracy: 0.1685
Epoch 46, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (904, 904)
Epoch 47, accuracy: 0.1699
batch size:/root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
/root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
 (900, 900)
Epoch 48, accuracy: 0.1680
Epoch 48, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (905, 905)
Epoch 49, accuracy: 0.1668
Loaded best model with val_loss = 1.0933620929718018
test :accuracy 0.4287, f1_macro: 0.2000, f1_micro: 0.4287, auc: 0.4794
Training GraphSAGE with 32 layers...
可训练参数: 4225033_GraphSAGE
不可训练参数: 0
batch size: (912, 912)
✅ Epoch 0: New best model saved with val_loss = 1.1206
Epoch 0, accuracy: 0.1677
Epoch 0, Train Loss: 1.0779, Val Loss: 1.1206
batch size: (898, 898)
✅ Epoch 1: New best model saved with val_loss = 1.1099
Epoch 1, accuracy: 0.1676
batch size: (883, 883)
✅ Epoch 2: New best model saved with val_loss = 1.0986
Epoch 2, accuracy: 0.1662
Epoch 2, Train Loss: 1.1976, Val Loss: 1.0986
batch size: (898, 898)
Epoch 3, accuracy: 0.1713
batch size: (879, 879)
Epoch 4, accuracy: 0.1675
Epoch 4, Train Loss: 1.1026, Val Loss: 1.0986
batch size: (885, 885)
Epoch 5, accuracy: 0.1648
batch size: (896, 896)
Epoch 6, accuracy: 0.1679
Epoch 6, Train Loss: 1.0988, Val Loss: 1.0986
batch size: (903, 903)
Epoch 7, accuracy: 0.1670
batch size: (902, 902)
Epoch 8, accuracy: 0.1654
Epoch 8, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (903, 903)
Epoch 9, accuracy: 0.1667
batch size: (902, 902)
Epoch 10, accuracy: 0.1703
Epoch 10, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (902, 902)
Epoch 11, accuracy: 0.1689
batch size: (885, 885)
Epoch 12, accuracy: 0.1674
Epoch 12, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (905, 905)
Epoch 13, accuracy: 0.1668
batch size: (901, 901)
Epoch 14, accuracy: 0.1649
Epoch 14, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (896, 896)
Epoch 15, accuracy: 0.1684
batch size: (896, 896)
Epoch 16, accuracy: 0.1688
Epoch 16, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (900, 900)
Epoch 17, accuracy: 0.1690
batch size: (907, 907)
Epoch 18, accuracy: 0.1679
Epoch 18, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (890, 890)
Epoch 19, accuracy: 0.1689
batch size: (919, 919)
Epoch 20, accuracy: 0.1660
Epoch 20, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (892, 892)
Epoch 21, accuracy: 0.1669
batch size: (916, 916)
Epoch 22, accuracy: 0.1664
Epoch 22, Train Loss: 1.0994, Val Loss: 1.0986
batch size: (901, 901)
Epoch 23, accuracy: 0.1686
batch size: (884, 884)
Epoch 24, accuracy: 0.1690
Epoch 24, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (880, 880)
Epoch 25, accuracy: 0.1666
batch size: (918, 918)
Epoch 26, accuracy: 0.1658
Epoch 26, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (890, 890)
Epoch 27, accuracy: 0.1663
batch size: (909, 909)
Epoch 28, accuracy: 0.1673
Epoch 28, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (903, 903)
Epoch 29, accuracy: 0.1669
batch size: (896, 896)
Epoch 30, accuracy: 0.1650
Epoch 30, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (907, 907)
Epoch 31, accuracy: 0.1676
batch size: (881, 881)
Epoch 32, accuracy: 0.1657
Epoch 32, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (888, 888)
Epoch 33, accuracy: 0.1685
batch size: (904, 904)
Epoch 34, accuracy: 0.1674
Epoch 34, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (913, 913)
Epoch 35, accuracy: 0.1664
batch size: (893, 893)
Epoch 36, accuracy: 0.1677
Epoch 36, Train Loss: 1.0987, Val Loss: 1.0986
batch size: (899, 899)
Epoch 37, accuracy: 0.1689
batch size: (891, 891)
Epoch 38, accuracy: 0.1695
Epoch 38, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (908, 908)
Epoch 39, accuracy: 0.1666
batch size: (891, 891)
Epoch 40, accuracy: 0.1658
Epoch 40, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (885, 885)
Epoch 41, accuracy: 0.1681
batch size: (924, 924)
Epoch 42, accuracy: 0.1647
Epoch 42, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (880, 880)
Epoch 43, accuracy: 0.1690
batch size: (894, 894)
Epoch 44, accuracy: 0.1652
Epoch 44, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (905, 905)
Epoch 45, accuracy: 0.1682
batch size: (901, 901)
Epoch 46, accuracy: 0.1690
Epoch 46, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (914, 914)
Epoch 47, accuracy: 0.1667
batch size: (900, 900)
Epoch 48, accuracy: 0.1679
Epoch 48, Train Loss: 1.0986, Val Loss: 1.0986
batch size: (897, 897)
Epoch 49, accuracy: 0.1708
Loaded best model with val_loss = 1.0986120700836182
test :accuracy 0.1652, f1_macro: 0.0945, f1_micro: 0.1652, auc: 0.4964
Training GAT with 2 layers...
可训练参数: 196495_GAT
不可训练参数: 0
batch size: (906, 906)
✅ Epoch 0: New best model saved with val_loss = 1.0735
Epoch 0, accuracy: 0.7137
Epoch 0, Train Loss: 1.0966, Val Loss: 1.0735
batch size: (915, 915)
✅ Epoch 1: New best model saved with val_loss = 1.0505
Epoch 1, accuracy: 0.7283
batch size: (901, 901)
✅ Epoch 2: New best model saved with val_loss = 1.0222
Epoch 2, accuracy: 0.7334
Epoch 2, Train Loss: 1.0212, Val Loss: 1.0222
batch size: (915, 915)
✅ Epoch 3: New best model saved with val_loss = 0.9895
Epoch 3, accuracy: 0.7328
batch size: (888, 888)
✅ Epoch 4: New best model saved with val_loss = 0.9538
Epoch 4, accuracy: 0.7300
Epoch 4, Train Loss: 0.9249, Val Loss: 0.9538
batch size: (913, 913)
✅ Epoch 5: New best model saved with val_loss = 0.9177
Epoch 5, accuracy: 0.7288
batch size: (904, 904)
✅ Epoch 6: New best model saved with val_loss = 0.8797
Epoch 6, accuracy: 0.7296
Epoch 6, Train Loss: 0.8097, Val Loss: 0.8797
batch size: (889, 889)
✅ Epoch 7: New best model saved with val_loss = 0.8457
Epoch 7, accuracy: 0.7299
batch size: (891, 891)
✅ Epoch 8: New best model saved with val_loss = 0.8072
Epoch 8, accuracy: 0.7312
Epoch 8, Train Loss: 0.6860, Val Loss: 0.8072
batch size: (906, 906)
✅ Epoch 9: New best model saved with val_loss = 0.7749
Epoch 9, accuracy: 0.7341
batch size: (899, 899)
✅ Epoch 10: New best model saved with val_loss = 0.7426
Epoch 10, accuracy: 0.7341
Epoch 10, Train Loss: 0.5839, Val Loss: 0.7426
batch size: (883, 883)
✅ Epoch 11: New best model saved with val_loss = 0.7189
Epoch 11, accuracy: 0.7343
batch size: (915, 915)
✅ Epoch 12: New best model saved with val_loss = 0.6876
Epoch 12, accuracy: 0.7384
Epoch 12, Train Loss: 0.4714, Val Loss: 0.6876
batch size: (889, 889)
✅ Epoch 13: New best model saved with val_loss = 0.6615
Epoch 13, accuracy: 0.7370
batch size: (883, 883)
✅ Epoch 14: New best model saved with val_loss = 0.6410
Epoch 14, accuracy: 0.7392
Epoch 14, Train Loss: 0.3801, Val Loss: 0.6410
batch size: (906, 906)
✅ Epoch 15: New best model saved with val_loss = 0.6325
Epoch 15, accuracy: 0.7393
batch size: (906, 906)
✅ Epoch 16: New best model saved with val_loss = 0.6115
Epoch 16, accuracy: 0.7397
Epoch 16, Train Loss: 0.3102, Val Loss: 0.6115
batch size: (901, 901)
✅ Epoch 17: New best model saved with val_loss = 0.5998
Epoch 17, accuracy: 0.7387
batch size: (901, 901)
✅ Epoch 18: New best model saved with val_loss = 0.5933
Epoch 18, accuracy: 0.7394
Epoch 18, Train Loss: 0.2509, Val Loss: 0.5933
batch size: (912, 912)
✅ Epoch 19: New best model saved with val_loss = 0.5921
Epoch 19, accuracy: 0.7376
batch size: (910, 910)
Epoch 20, accuracy: 0.7368
Epoch 20, Train Loss: 0.1968, Val Loss: 0.5989
batch size: (898, 898)
Epoch 21, accuracy: 0.7348
batch size: (902, 902)
Epoch 22, accuracy: 0.7347
Epoch 22, Train Loss: 0.1631, Val Loss: 0.5965
batch size: (897, 897)
✅ Epoch 23: New best model saved with val_loss = 0.5885
Epoch 23, accuracy: 0.7330
batch size: (889, 889)
Epoch 24, accuracy: 0.7333
Epoch 24, Train Loss: 0.1505, Val Loss: 0.5897
batch size: (910, 910)
Epoch 25, accuracy: 0.7329
batch size: (886, 886)
Epoch 26, accuracy: 0.7328
Epoch 26, Train Loss: 0.1299, Val Loss: 0.6004
batch size: (888, 888)
Epoch 27, accuracy: 0.7307
batch size: (908, 908)
Epoch 28, accuracy: 0.7321
Epoch 28, Train Loss: 0.1054, Val Loss: 0.6060
batch size: (892, 892)
Epoch 29, accuracy: 0.7325
batch size: (892, 892)
Epoch 30, accuracy: 0.7315
Epoch 30, Train Loss: 0.0826, Val Loss: 0.6014
batch size: (885, 885)
Epoch 31, accuracy: 0.7339
batch size: (898, 898)
Epoch 32, accuracy: 0.7309
Epoch 32, Train Loss: 0.1033, Val Loss: 0.6006
batch size: (883, 883)
Epoch 33, accuracy: 0.7328
batch size: (906, 906)
Epoch 34, accuracy: 0.7324
Epoch 34, Train Loss: 0.0862, Val Loss: 0.6057
batch size: /root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
/root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
(911, 911)
Epoch 35, accuracy: 0.7316
batch size: (883, 883)
Epoch 36, accuracy: 0.7307
Epoch 36, Train Loss: 0.1001, Val Loss: 0.6083
batch size: (891, 891)
Epoch 37, accuracy: 0.7305
batch size: (901, 901)
Epoch 38, accuracy: 0.7311
Epoch 38, Train Loss: 0.0822, Val Loss: 0.6120
batch size: (927, 927)
Epoch 39, accuracy: 0.7316
batch size: (894, 894)
Epoch 40, accuracy: 0.7314
Epoch 40, Train Loss: 0.0834, Val Loss: 0.5954
batch size: (914, 914)
Epoch 41, accuracy: 0.7304
batch size: (883, 883)
Epoch 42, accuracy: 0.7324
Epoch 42, Train Loss: 0.0869, Val Loss: 0.6127
batch size: (905, 905)
Epoch 43, accuracy: 0.7313
batch size: (871, 871)
Epoch 44, accuracy: 0.7303
Epoch 44, Train Loss: 0.0804, Val Loss: 0.6131
batch size: (888, 888)
Epoch 45, accuracy: 0.7313
batch size: (906, 906)
Epoch 46, accuracy: 0.7328
Epoch 46, Train Loss: 0.0846, Val Loss: 0.6195
batch size: (891, 891)
Epoch 47, accuracy: 0.7319
batch size: (911, 911)
Epoch 48, accuracy: 0.7312
Epoch 48, Train Loss: 0.0859, Val Loss: 0.6135
batch size: (910, 910)
Epoch 49, accuracy: 0.7301
Loaded best model with val_loss = 0.5884548425674438
test :accuracy 0.7314, f1_macro: 0.7267, f1_micro: 0.7314, auc: 0.8870
Training GAT with 8 layers...
可训练参数: 1090447_GAT
不可训练参数: 0
batch size: (895, 895)
✅ Epoch 0: New best model saved with val_loss = 1.1022
Epoch 0, accuracy: 0.1631
Epoch 0, Train Loss: 1.0971, Val Loss: 1.1022
batch size: (897, 897)
✅ Epoch 1: New best model saved with val_loss = 1.0914
Epoch 1, accuracy: 0.4295
batch size: (907, 907)
Epoch 2, accuracy: 0.3145
Epoch 2, Train Loss: 1.1004, Val Loss: 1.1073
batch size: (898, 898)
Epoch 3, accuracy: 0.1656
batch size: (903, 903)
✅ Epoch 4: New best model saved with val_loss = 1.0493
Epoch 4, accuracy: 0.4329
Epoch 4, Train Loss: 1.0977, Val Loss: 1.0493
batch size: (910, 910)
Epoch 5, accuracy: 0.1795
batch size: (898, 898)
Epoch 6, accuracy: 0.1704
Epoch 6, Train Loss: 1.0813, Val Loss: 1.1333
batch size: (895, 895)
Epoch 7, accuracy: 0.2420
batch size: (897, 897)
✅ Epoch 8: New best model saved with val_loss = 1.0039
Epoch 8, accuracy: 0.6166
Epoch 8, Train Loss: 0.9949, Val Loss: 1.0039
batch size: (892, 892)
✅ Epoch 9: New best model saved with val_loss = 1.0033
Epoch 9, accuracy: 0.6346
batch size: (918, 918)
✅ Epoch 10: New best model saved with val_loss = 0.9247
Epoch 10, accuracy: 0.5091
Epoch 10, Train Loss: 0.7912, Val Loss: 0.9247
batch size: (897, 897)
Epoch 11, accuracy: 0.5390
batch size: (922, 922)
Epoch 12, accuracy: 0.6967
Epoch 12, Train Loss: 0.6262, Val Loss: 1.2724
batch size: (921, 921)
✅ Epoch 13: New best model saved with val_loss = 0.8576
Epoch 13, accuracy: 0.6935
batch size: (899, 899)
Epoch 14, accuracy: 0.6922
Epoch 14, Train Loss: 0.5154, Val Loss: 0.8577
batch size: (902, 902)
Epoch 15, accuracy: 0.5768
batch size: (906, 906)
Epoch 16, accuracy: 0.5906
Epoch 16, Train Loss: 0.8960, Val Loss: 1.0612
batch size: (893, 893)
✅ Epoch 17: New best model saved with val_loss = 0.8157
Epoch 17, accuracy: 0.6636
batch size: (916, 916)
✅ Epoch 18: New best model saved with val_loss = 0.7807
Epoch 18, accuracy: 0.7127
Epoch 18, Train Loss: 0.3907, Val Loss: 0.7807
batch size: (900, 900)
Epoch 19, accuracy: 0.6599
batch size: (891, 891)
Epoch 20, accuracy: 0.6339
Epoch 20, Train Loss: 0.2897, Val Loss: 1.0939
batch size: (898, 898)
Epoch 21, accuracy: 0.6393
batch size: (890, 890)
✅ Epoch 22: New best model saved with val_loss = 0.7286
Epoch 22, accuracy: 0.6756
Epoch 22, Train Loss: 0.3191, Val Loss: 0.7286
batch size: (895, 895)
Epoch 23, accuracy: 0.6672
batch size: (891, 891)
Epoch 24, accuracy: 0.6742
Epoch 24, Train Loss: 0.2901, Val Loss: 0.7830
batch size: (901, 901)
Epoch 25, accuracy: 0.6787
batch size: (889, 889)
Epoch 26, accuracy: 0.6709
Epoch 26, Train Loss: 0.1248, Val Loss: 0.8622
batch size: (916, 916)
Epoch 27, accuracy: 0.6595
batch size: (899, 899)
Epoch 28, accuracy: 0.6585
Epoch 28, Train Loss: 0.0988, Val Loss: 1.2650
batch size: (898, 898)
Epoch 29, accuracy: 0.6612
batch size: (908, 908)
Epoch 30, accuracy: 0.6662
Epoch 30, Train Loss: 0.0663, Val Loss: 1.1778
batch size: (896, 896)
Epoch 31, accuracy: 0.6738
batch size: (885, 885)
Epoch 32, accuracy: 0.6767
Epoch 32, Train Loss: 0.0715, Val Loss: 1.2042
batch size: (896, 896)
Epoch 33, accuracy: 0.6813
batch size: (904, 904)
Epoch 34, accuracy: 0.6818
Epoch 34, Train Loss: 0.0639, Val Loss: 1.0019
batch size: (893, 893)
Epoch 35, accuracy: 0.6813
batch size: (893, 893)
Epoch 36, accuracy: 0.6819
Epoch 36, Train Loss: 0.0354, Val Loss: 1.0778
batch size: (899, 899)
Epoch 37, accuracy: 0.6836
batch size: (891, 891)
Epoch 38, accuracy: 0.6844
Epoch 38, Train Loss: 0.0740, Val Loss: 0.9213
batch size: (895, 895)
Epoch 39, accuracy: 0.6828
batch size: (920, 920)
Epoch 40, accuracy: 0.6804
Epoch 40, Train Loss: 0.0612, Val Loss: 0.9897
batch size: (897, 897)
Epoch 41, accuracy: 0.6827
batch size: (886, 886)
Epoch 42, accuracy: 0.6832
Epoch 42, Train Loss: 0.0384, Val Loss: 1.0521
batch size: (920, 920)
Epoch 43, accuracy: 0.6821
batch size: (910, 910)
Epoch 44, accuracy: 0.6833
Epoch 44, Train Loss: 0.0556, Val Loss: 0.9853
batch size: (930, 930)
Epoch 45, accuracy: 0.6829
batch size: (920, 920)
Epoch 46, accuracy: 0.6824
Epoch 46, Train Loss: 0.0900, Val Loss: 0.9375
batch size: (888, 888)
Epoch 47, accuracy: 0.6827
batch size: (886, 886)
Epoch 48, accuracy: 0.6830
Epoch 48, Train Loss: 0.0236, Val Loss: 0.9679
batch size: (919, 919)
Epoch 49, accuracy: 0.6814
Loaded best model with val_loss = 0.7285940051078796
test :accuracy 0.6725, f1_macro: 0.6589, f1_micro: 0.6725, auc: 0.8096
Training GAT with 32 layers...
可训练参数: 4666255_GAT
不可训练参数: 0
batch size: (898, 898)
✅ Epoch 0: New best model saved with val_loss = 1.1050
Epoch 0, accuracy: 0.1644
Epoch 0, Train Loss: 1.0983, Val Loss: 1.1050
batch size: (916, 916)
✅ Epoch 1: New best model saved with val_loss = 1.0885
Epoch 1, accuracy: 0.4013
batch size: (896, 896)
Epoch 2, accuracy: 0.4046
Epoch 2, Train Loss: 1.1149, Val Loss: 1.0918
batch size: (910, 910)
Epoch 3, accuracy: 0.4030
batch size: (881, 881)
Epoch 4, accuracy: 0.1676
Epoch 4, Train Loss: 1.0993, Val Loss: 1.1020
batch size: (901, 901)
Epoch 5, accuracy: 0.1684
batch size: (888, 888)
Epoch 6, accuracy: 0.1700
Epoch 6, Train Loss: 1.0963, Val Loss: 1.1012
batch size: (907, 907)
Epoch 7, accuracy: 0.1657
batch size: (901, 901)
Epoch 8, accuracy: 0.1654
Epoch 8, Train Loss: 1.1124, Val Loss: 1.1042
batch size: (900, 900)
Epoch 9, accuracy: 0.1682
batch size: (906, 906)
Epoch 10, accuracy: 0.1675
Epoch 10, Train Loss: 1.0978, Val Loss: 1.1029
batch size: (888, 888)
Epoch 11, accuracy: 0.1681
batch size: (906, 906)
Epoch 12, accuracy: 0.1689
Epoch 12, Train Loss: 1.0934, Val Loss: 1.1008
batch size: (912, 912)
Epoch 13, accuracy: 0.1671
batch size: (906, 906)
Epoch 14, accuracy: 0.1652
Epoch 14, Train Loss: 1.0991, Val Loss: 1.0999
batch size: (912, 912)
Epoch 15, accuracy: 0.1646
batch size: (902, 902)
Epoch 16, accuracy: 0.1680
Epoch 16, Train Loss: 1.0992, Val Loss: 1.0997
batch size: (903, 903)
Epoch 17, accuracy: 0.1683
batch size: (893, 893)
Epoch 18, accuracy: 0.1697
Epoch 18, Train Loss: 1.0971, Val Loss: 1.0995
batch size: (881, 881)
Epoch 19, accuracy: 0.1669
batch size: (894, 894)
Epoch 20, accuracy: 0.1673
Epoch 20, Train Loss: 1.1030, Val Loss: 1.0994
batch size: (893, 893)
Epoch 21, accuracy: 0.1679
batch size: (893, 893)
Epoch 22, accuracy: 0.1703
Epoch 22, Train Loss: 1.1000, Val Loss: 1.0994
batch size: (899, 899)
Epoch 23, accuracy: 0.1689
batch size: (905, 905)
Epoch 24, accuracy: 0.1666
Epoch 24, Train Loss: 1.0988, Val Loss: 1.0994
batch size: (888, 888)
Epoch 25, accuracy: 0.1706
batch size: (906, 906)
Epoch 26, accuracy: 0.1693
Epoch 26, Train Loss: 1.1014, Val Loss: 1.0994
batch size: (886, 886)
Epoch 27, accuracy: 0.1660
batch size: (899, 899)
Epoch 28, accuracy: 0.1690
Epoch 28, Train Loss: 1.1010, Val Loss: 1.0994
batch size: (912, 912)
Epoch 29, accuracy: 0.1684
batch size: (887, 887)
Epoch 30, accuracy: 0.1665
Epoch 30, Train Loss: 1.1073, Val Loss: 1.0994
batch size: (897, 897)
Epoch 31, accuracy: 0.1681
batch size: (913, 913)
/root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
/root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
Epoch 32, accuracy: 0.1672
Epoch 32, Train Loss: 1.0986, Val Loss: 1.0994
batch size: (881, 881)
Epoch 33, accuracy: 0.1681
batch size: (908, 908)
Epoch 34, accuracy: 0.1658
Epoch 34, Train Loss: 1.1046, Val Loss: 1.0994
batch size: (890, 890)
Epoch 35, accuracy: 0.1683
batch size: (904, 904)
Epoch 36, accuracy: 0.1700
Epoch 36, Train Loss: 1.1080, Val Loss: 1.0994
batch size: (871, 871)
Epoch 37, accuracy: 0.1651
batch size: (897, 897)
Epoch 38, accuracy: 0.1683
Epoch 38, Train Loss: 1.0987, Val Loss: 1.0994
batch size: (882, 882)
Epoch 39, accuracy: 0.1665
batch size: (895, 895)
Epoch 40, accuracy: 0.1682
Epoch 40, Train Loss: 1.0892, Val Loss: 1.0994
batch size: (896, 896)
Epoch 41, accuracy: 0.1687
batch size: (919, 919)
Epoch 42, accuracy: 0.1672
Epoch 42, Train Loss: 1.1025, Val Loss: 1.0994
batch size: (894, 894)
Epoch 43, accuracy: 0.1660
batch size: (903, 903)
Epoch 44, accuracy: 0.1659
Epoch 44, Train Loss: 1.0970, Val Loss: 1.0994
batch size: (901, 901)
Epoch 45, accuracy: 0.1663
batch size: (897, 897)
Epoch 46, accuracy: 0.1687
Epoch 46, Train Loss: 1.1045, Val Loss: 1.0994
batch size: (892, 892)
Epoch 47, accuracy: 0.1668
batch size: (895, 895)
Epoch 48, accuracy: 0.1687
Epoch 48, Train Loss: 1.1072, Val Loss: 1.0994
batch size: (877, 877)
Epoch 49, accuracy: 0.1682
Loaded best model with val_loss = 1.0885281562805176
test :accuracy 0.4021, f1_macro: 0.1912, f1_micro: 0.4021, auc: 0.2978
Training JKNet with 2 layers...
可训练参数: 391942_JKNet
不可训练参数: 0
batch size: (892, 892)
✅ Epoch 0: New best model saved with val_loss = 1.1007
Epoch 0, accuracy: 0.1663
Epoch 0, Train Loss: 1.3121, Val Loss: 1.1007
batch size: (917, 917)
✅ Epoch 1: New best model saved with val_loss = 1.0919
Epoch 1, accuracy: 0.3827
batch size: (912, 912)
✅ Epoch 2: New best model saved with val_loss = 1.0814
Epoch 2, accuracy: 0.5243
Epoch 2, Train Loss: 0.1343, Val Loss: 1.0814
batch size: (898, 898)
✅ Epoch 3: New best model saved with val_loss = 1.0698
Epoch 3, accuracy: 0.4521
batch size: (888, 888)
✅ Epoch 4: New best model saved with val_loss = 1.0570
Epoch 4, accuracy: 0.4414
Epoch 4, Train Loss: 0.0186, Val Loss: 1.0570
batch size: (912, 912)
✅ Epoch 5: New best model saved with val_loss = 1.0453
Epoch 5, accuracy: 0.4385
batch size: (895, 895)
✅ Epoch 6: New best model saved with val_loss = 1.0348
Epoch 6, accuracy: 0.4348
Epoch 6, Train Loss: 0.0047, Val Loss: 1.0348
batch size: (899, 899)
✅ Epoch 7: New best model saved with val_loss = 1.0244
Epoch 7, accuracy: 0.4327
batch size: (901, 901)
✅ Epoch 8: New best model saved with val_loss = 1.0150
Epoch 8, accuracy: 0.4241
Epoch 8, Train Loss: 0.0016, Val Loss: 1.0150
batch size: (897, 897)
✅ Epoch 9: New best model saved with val_loss = 1.0082
Epoch 9, accuracy: 0.4155
batch size: (920, 920)
✅ Epoch 10: New best model saved with val_loss = 0.9996
Epoch 10, accuracy: 0.4215
Epoch 10, Train Loss: 0.0020, Val Loss: 0.9996
batch size: (889, 889)
✅ Epoch 11: New best model saved with val_loss = 0.9949
Epoch 11, accuracy: 0.4188
batch size: (901, 901)
✅ Epoch 12: New best model saved with val_loss = 0.9899
Epoch 12, accuracy: 0.4142
Epoch 12, Train Loss: 0.0015, Val Loss: 0.9899
batch size: (889, 889)
✅ Epoch 13: New best model saved with val_loss = 0.9868
Epoch 13, accuracy: 0.4147
batch size: (895, 895)
✅ Epoch 14: New best model saved with val_loss = 0.9826
Epoch 14, accuracy: 0.4122
Epoch 14, Train Loss: 0.0007, Val Loss: 0.9826
batch size: (890, 890)
✅ Epoch 15: New best model saved with val_loss = 0.9804
Epoch 15, accuracy: 0.4140
batch size: (903, 903)
✅ Epoch 16: New best model saved with val_loss = 0.9779
Epoch 16, accuracy: 0.4120
Epoch 16, Train Loss: 0.0008, Val Loss: 0.9779
batch size: (917, 917)
✅ Epoch 17: New best model saved with val_loss = 0.9752
Epoch 17, accuracy: 0.4101
batch size: (895, 895)
✅ Epoch 18: New best model saved with val_loss = 0.9749
Epoch 18, accuracy: 0.4151
Epoch 18, Train Loss: 0.0002, Val Loss: 0.9749
batch size: (907, 907)
✅ Epoch 19: New best model saved with val_loss = 0.9732
Epoch 19, accuracy: 0.4119
batch size: (902, 902)
✅ Epoch 20: New best model saved with val_loss = 0.9698
Epoch 20, accuracy: 0.4155
Epoch 20, Train Loss: 0.0005, Val Loss: 0.9698
batch size: (914, 914)
✅ Epoch 21: New best model saved with val_loss = 0.9697
Epoch 21, accuracy: 0.4203
batch size: (899, 899)
Epoch 22, accuracy: 0.4193
Epoch 22, Train Loss: 0.0001, Val Loss: 0.9697
batch size: (906, 906)
Epoch 23, accuracy: 0.4176
batch size: (905, 905)
Epoch 24, accuracy: 0.4177
Epoch 24, Train Loss: 0.0004, Val Loss: 0.9709
batch size: (885, 885)
Epoch 25, accuracy: 0.4176
batch size: (887, 887)
Epoch 26, accuracy: 0.4166
Epoch 26, Train Loss: 0.0000, Val Loss: 0.9703
batch size: (898, 898)
Epoch 27, accuracy: 0.4225
batch size: (894, 894)
Epoch 28, accuracy: 0.4146
Epoch 28, Train Loss: 0.0006, Val Loss: 0.9717
batch size: (892, 892)
Epoch 29, accuracy: 0.4220
batch size: (891, 891)
Epoch 30, accuracy: 0.4235
Epoch 30, Train Loss: 0.0000, Val Loss: 0.9704
batch size: (894, 894)
Epoch 31, accuracy: 0.4264
batch size: (909, 909)
Epoch 32, accuracy: 0.4240
Epoch 32, Train Loss: 0.0001, Val Loss: 0.9710
batch size: (894, 894)
Epoch 33, accuracy: 0.4254
batch size: (902, 902)
Epoch 34, accuracy: 0.4186
Epoch 34, Train Loss: 0.0000, Val Loss: 0.9724
batch size: (886, 886)
Epoch 35, accuracy: 0.4203
batch size: (909, 909)
Epoch 36, accuracy: 0.4236
Epoch 36, Train Loss: 0.0000, Val Loss: 0.9714
batch size: (903, 903)
Epoch 37, accuracy: 0.4227
batch size: (899, 899)
Epoch 38, accuracy: 0.4250
Epoch 38, Train Loss: 0.0000, Val Loss: 0.9714
batch size: (897, 897)
Epoch 39, accuracy: 0.4228
batch size: (902, 902)
Epoch 40, accuracy: 0.4229
Epoch 40, Train Loss: 0.0001, Val Loss: 0.9711
batch size: (896, 896)
Epoch 41, accuracy: 0.4288
batch size: (911, 911)
Epoch 42, accuracy: 0.4320
Epoch 42, Train Loss: 0.0000, Val Loss: 0.9702
batch size: (900, 900)
Epoch 43, accuracy: 0.4300
batch size: (883, 883)
Epoch 44, accuracy: 0.4274
Epoch 44, Train Loss: 0.0001, Val Loss: 0.9718
batch size: (880, 880)
Epoch 45, accuracy: 0.4202
batch size: (927, 927)
Epoch 46, accuracy: 0.4237
Epoch 46, Train Loss: 0.0001, Val Loss: 0.9721
batch size: (919, 919)
Epoch 47, accuracy: 0.4196
batch size: (905, 905)
Epoch 48, accuracy: 0.4255
Epoch 48, Train Loss: 0.0001, Val Loss: 0.9715
batch size: (915, 915)
Epoch 49, accuracy: 0.4225
Loaded best model with val_loss = 0.96971195936203
test :accuracy 0.4212, f1_macro: 0.2192, f1_micro: 0.4212, auc: 0.8006
Training JKNet with 8 layers...
可训练参数: 1184518_JKNet
不可训练参数: 0
batch size: (912, 912)
✅ Epoch 0: New best model saved with val_loss = 1.1434
Epoch 0, accuracy: 0.1638
Epoch 0, Train Loss: 1.3248, Val Loss: 1.1434
batch size: (899, 899)
✅ Epoch 1: New best model saved with val_loss = 1.0670
Epoch 1, accuracy: 0.4057
batch size: (880, 880)
Epoch 2, accuracy: 0.4290
Epoch 2, Train Loss: 2.8304, Val Loss: 1.1206
batch size: (894, 894)
✅ Epoch 3: New best model saved with val_loss = 1.0521
Epoch 3, accuracy: 0.4269
batch size: (900, 900)
✅ Epoch 4: New best model saved with val_loss = 1.0502
Epoch 4, accuracy: 0.3979
Epoch 4, Train Loss: 0.7972, Val Loss: 1.0502
batch size: (880, 880)
Epoch 5, accuracy: 0.4019
batch size: (920, 920)
Epoch 6, accuracy: 0.4072
Epoch 6, Train Loss: 0.2247, Val Loss: 1.1042
batch size: (919, 919)
Epoch 7, accuracy: 0.3553
batch size: (914, 914)
Epoch 8, accuracy: 0.3574
Epoch 8, Train Loss: 0.1492, Val Loss: 1.1383
batch size: (880, 880)
Epoch 9, accuracy: 0.3785
batch size: (870, 870)
Epoch 10, accuracy: 0.3699
Epoch 10, Train Loss: 0.0558, Val Loss: 1.1264
batch size: (895, 895)
Epoch 11, accuracy: 0.3539
batch size: (899, 899)
Epoch 12, accuracy: 0.3545
Epoch 12, Train Loss: 0.1661, Val Loss: 1.1219
batch size: (885, 885)
Epoch 13, accuracy: 0.3546
batch size: (872, 872)
Epoch 14, accuracy: 0.3560
Epoch 14, Train Loss: 0.0405, Val Loss: 1.1247
batch size: (898, 898)
Epoch 15, accuracy: 0.3576
batch size: (901, 901)
Epoch 16, accuracy: 0.3531
Epoch 16, Train Loss: 0.0915, Val Loss: 1.1204
batch size: (884, 884)
Epoch 17, accuracy: 0.3555
batch size: /root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
/root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
(911, 911)
Epoch 18, accuracy: 0.3531
Epoch 18, Train Loss: 0.0257, Val Loss: 1.1207
batch size: (888, 888)
Epoch 19, accuracy: 0.3536
batch size: (891, 891)
Epoch 20, accuracy: 0.3529
Epoch 20, Train Loss: 0.0177, Val Loss: 1.1201
batch size: (898, 898)
Epoch 21, accuracy: 0.3563
batch size: (903, 903)
Epoch 22, accuracy: 0.3569
Epoch 22, Train Loss: 0.0521, Val Loss: 1.1185
batch size: (894, 894)
Epoch 23, accuracy: 0.3566
batch size: (917, 917)
Epoch 24, accuracy: 0.3601
Epoch 24, Train Loss: 0.0392, Val Loss: 1.1202
batch size: (909, 909)
Epoch 25, accuracy: 0.3560
batch size: (915, 915)
Epoch 26, accuracy: 0.3545
Epoch 26, Train Loss: 0.0397, Val Loss: 1.1240
batch size: (913, 913)
Epoch 27, accuracy: 0.3550
batch size: (885, 885)
Epoch 28, accuracy: 0.3583
Epoch 28, Train Loss: 0.0181, Val Loss: 1.1196
batch size: (913, 913)
Epoch 29, accuracy: 0.3571
batch size: (889, 889)
Epoch 30, accuracy: 0.3558
Epoch 30, Train Loss: 0.0289, Val Loss: 1.1173
batch size: (899, 899)
Epoch 31, accuracy: 0.3544
batch size: (889, 889)
Epoch 32, accuracy: 0.3556
Epoch 32, Train Loss: 0.0215, Val Loss: 1.1194
batch size: (886, 886)
Epoch 33, accuracy: 0.3571
batch size: (908, 908)
Epoch 34, accuracy: 0.3560
Epoch 34, Train Loss: 0.0318, Val Loss: 1.1193
batch size: (915, 915)
Epoch 35, accuracy: 0.3576
batch size: (904, 904)
Epoch 36, accuracy: 0.3610
Epoch 36, Train Loss: 0.0177, Val Loss: 1.1155
batch size: (904, 904)
Epoch 37, accuracy: 0.3551
batch size: (902, 902)
Epoch 38, accuracy: 0.3560
Epoch 38, Train Loss: 0.0154, Val Loss: 1.1159
batch size: (898, 898)
Epoch 39, accuracy: 0.3560
batch size: (904, 904)
Epoch 40, accuracy: 0.3531
Epoch 40, Train Loss: 0.0170, Val Loss: 1.1194
batch size: (913, 913)
Epoch 41, accuracy: 0.3553
batch size: (901, 901)
Epoch 42, accuracy: 0.3559
Epoch 42, Train Loss: 0.0198, Val Loss: 1.1195
batch size: (904, 904)
Epoch 43, accuracy: 0.3543
batch size: (900, 900)
Epoch 44, accuracy: 0.3561
Epoch 44, Train Loss: 0.0122, Val Loss: 1.1234
batch size: (912, 912)
Epoch 45, accuracy: 0.3576
batch size: (914, 914)
Epoch 46, accuracy: 0.3527
Epoch 46, Train Loss: 0.0255, Val Loss: 1.1201
batch size: (900, 900)
Epoch 47, accuracy: 0.3542
batch size: (892, 892)
Epoch 48, accuracy: 0.3577
Epoch 48, Train Loss: 0.0216, Val Loss: 1.1171
batch size: (888, 888)
Epoch 49, accuracy: 0.3556
Loaded best model with val_loss = 1.0502490997314453
test :accuracy 0.4002, f1_macro: 0.1905, f1_micro: 0.4002, auc: 0.7322
Training JKNet with 32 layers...
可训练参数: 4354822_JKNet
不可训练参数: 0
batch size: (920, 920)
✅ Epoch 0: New best model saved with val_loss = 1.5780
Epoch 0, accuracy: 0.4306
Epoch 0, Train Loss: 1.3234, Val Loss: 1.5780
batch size: (900, 900)
✅ Epoch 1: New best model saved with val_loss = 1.2228
Epoch 1, accuracy: 0.4016
batch size: (904, 904)
Epoch 2, accuracy: 0.3571
Epoch 2, Train Loss: 2.3845, Val Loss: 1.2542
batch size: (891, 891)
✅ Epoch 3: New best model saved with val_loss = 1.1414
Epoch 3, accuracy: 0.3748
batch size: (916, 916)
✅ Epoch 4: New best model saved with val_loss = 1.1414
Epoch 4, accuracy: 0.4476
Epoch 4, Train Loss: 1.5864, Val Loss: 1.1414
batch size: (909, 909)
✅ Epoch 5: New best model saved with val_loss = 1.1361
Epoch 5, accuracy: 0.1703
batch size: (905, 905)
Epoch 6, accuracy: 0.1663
Epoch 6, Train Loss: 1.5595, Val Loss: 1.1599
batch size: (909, 909)
Epoch 7, accuracy: 0.1676
batch size: (894, 894)
✅ Epoch 8: New best model saved with val_loss = 1.1255
Epoch 8, accuracy: 0.1675
Epoch 8, Train Loss: 0.4096, Val Loss: 1.1255
batch size: (901, 901)
✅ Epoch 9: New best model saved with val_loss = 1.1150
Epoch 9, accuracy: 0.3846
batch size: (913, 913)
Epoch 10, accuracy: 0.3045
Epoch 10, Train Loss: 0.3177, Val Loss: 1.1219
batch size: (887, 887)
✅ Epoch 11: New best model saved with val_loss = 1.1150
Epoch 11, accuracy: 0.3548
batch size: (913, 913)
✅ Epoch 12: New best model saved with val_loss = 1.1142
Epoch 12, accuracy: 0.3576
Epoch 12, Train Loss: 0.1723, Val Loss: 1.1142
batch size: (901, 901)
✅ Epoch 13: New best model saved with val_loss = 1.1088
Epoch 13, accuracy: 0.3562
batch size: (884, 884)
✅ Epoch 14: New best model saved with val_loss = 1.1072
Epoch 14, accuracy: 0.3582
Epoch 14, Train Loss: 0.3056, Val Loss: 1.1072
batch size: (906, 906)
✅ Epoch 15: New best model saved with val_loss = 1.1038
Epoch 15, accuracy: 0.3582
batch size: (897, 897)
✅ Epoch 16: New best model saved with val_loss = 1.1025
Epoch 16, accuracy: 0.3584
Epoch 16, Train Loss: 0.0243, Val Loss: 1.1025
batch size: (877, 877)
✅ Epoch 17: New best model saved with val_loss = 1.0960
Epoch 17, accuracy: 0.4370
batch size: (900, 900)
✅ Epoch 18: New best model saved with val_loss = 1.0954
Epoch 18, accuracy: 0.4294
Epoch 18, Train Loss: 0.3929, Val Loss: 1.0954
batch size: (908, 908)
Epoch 19, accuracy: 0.4874
batch size: (907, 907)
Epoch 20, accuracy: 0.1885
Epoch 20, Train Loss: 0.0712, Val Loss: 1.1014
batch size: (904, 904)
Epoch 21, accuracy: 0.1667
batch size: (890, 890)
Epoch 22, accuracy: 0.1668
Epoch 22, Train Loss: 0.0073, Val Loss: 1.1070
batch size: (907, 907)
Epoch 23, accuracy: 0.1672
batch size: (905, 905)
Epoch 24, accuracy: 0.1674
Epoch 24, Train Loss: 0.0105, Val Loss: 1.1184
batch size: (918, 918)
Epoch 25, accuracy: 0.1685
batch size: (905, 905)
Epoch 26, accuracy: 0.1689
Epoch 26, Train Loss: 0.0126, Val Loss: 1.1167
batch size: (892, 892)
Epoch 27, accuracy: 0.1694
batch size: (899, 899)
Epoch 28, accuracy: 0.1645
Epoch 28, Train Loss: 0.0552, Val Loss: 1.1173
batch size: (904, 904)
Epoch 29, accuracy: 0.1670
batch size: (916, 916)
Epoch 30, accuracy: 0.1638
Epoch 30, Train Loss: 0.0051, Val Loss: 1.1178
batch size: (889, 889)
Epoch 31, accuracy: 0.1675
batch size: (891, 891)
Epoch 32, accuracy: 0.1679
Epoch 32, Train Loss: 0.0036, Val Loss: 1.1177
batch size: (896, 896)
Epoch 33, accuracy: 0.1666
batch size: (891, 891)
Epoch 34, accuracy: 0.1671
Epoch 34, Train Loss: 0.0026, Val Loss: 1.1144
batch size: (898, 898)
Epoch 35, accuracy: 0.1659
batch size: (896, 896)
Epoch 36, accuracy: 0.1674
Epoch 36, Train Loss: 0.0098, Val Loss: 1.1166
batch size: (906, 906)
Epoch 37, accuracy: 0.1669
batch size: (915, 915)
Epoch 38, accuracy: 0.1648
Epoch 38, Train Loss: 0.0046, Val Loss: 1.1143
batch size: (906, 906)
Epoch 39, accuracy: 0.1672
batch size: (908, 908)
Epoch 40, accuracy: 0.1693
Epoch 40, Train Loss: 0.1769, Val Loss: 1.1176
batch size: (896, 896)
Epoch 41, accuracy: 0.1659
batch size: (895, 895)
Epoch 42, accuracy: 0.1641
Epoch 42, Train Loss: 0.0064, Val Loss: 1.1144
batch size: (866, 866)
Epoch 43, accuracy: 0.1651
batch size: (901, 901)
Epoch 44, accuracy: 0.1676
Epoch 44, Train Loss: 0.0108, Val Loss: 1.1186
batch size: (910, 910)
Epoch 45, accuracy: 0.1687
batch size: (894, 894)
Epoch 46, accuracy: 0.1673
Epoch 46, Train Loss: 0.0044, Val Loss: 1.1149
batch size: (894, 894)
Epoch 47, accuracy: 0.1686
batch size: (893, 893)
Epoch 48, accuracy: 0.1663
Epoch 48, Train Loss: 0.0093, Val Loss: 1.1169
batch size: (906, 906)
Epoch 49, accuracy: 0.1688
Loaded best model with val_loss = 1.0953540802001953
test :accuracy 0.4296, f1_macro: 0.3273, f1_micro: 0.4296, auc: 0.7183
Training resGCN with 2 layers...
可训练参数: 132626_resGCN
不可训练参数: 0
batch size: (894, 894)
✅ Epoch 0: New best model saved with val_loss = 1.0922
Epoch 0, accuracy: 0.5069
Epoch 0, Train Loss: 1.0984, Val Loss: 1.0922
batch size: (902, 902)
✅ Epoch 1: New best model saved with val_loss = 1.0901
Epoch 1, accuracy: 0.5225
batch size: (923, 923)
✅ Epoch 2: New best model saved with val_loss = 1.0812
Epoch 2, accuracy: 0.6568
Epoch 2, Train Loss: 1.0909, Val Loss: 1.0812
batch size: (906, 906)
✅ Epoch 3: New best model saved with val_loss = 1.0604
Epoch 3, accuracy: 0.6056
batch size: (913, 913)
✅ Epoch 4: New best model saved with val_loss = 1.0393
Epoch 4, accuracy: 0.4838
Epoch 4, Train Loss: 1.0592, Val Loss: 1.0393
batch size: (908, 908)
✅ Epoch 5: New best model saved with val_loss = 1.0203
Epoch 5, accuracy: 0.4746
batch size: (907, 907)
✅ Epoch 6: New best model saved with val_loss = 1.0009
Epoch 6, accuracy: 0.4976
/root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
Epoch 6, Train Loss: 1.0280, Val Loss: 1.0009
batch size: (898, 898)
✅ Epoch 7: New best model saved with val_loss = 0.9816
Epoch 7, accuracy: 0.5820
batch size: (902, 902)
✅ Epoch 8: New best model saved with val_loss = 0.9652
Epoch 8, accuracy: 0.6258
Epoch 8, Train Loss: 0.9697, Val Loss: 0.9652
batch size: (896, 896)
✅ Epoch 9: New best model saved with val_loss = 0.9426
Epoch 9, accuracy: 0.6357
batch size: (895, 895)
✅ Epoch 10: New best model saved with val_loss = 0.9211
Epoch 10, accuracy: 0.6478
Epoch 10, Train Loss: 0.9177, Val Loss: 0.9211
batch size: (918, 918)
✅ Epoch 11: New best model saved with val_loss = 0.9003
Epoch 11, accuracy: 0.6555
batch size: (919, 919)
✅ Epoch 12: New best model saved with val_loss = 0.8741
Epoch 12, accuracy: 0.6479
Epoch 12, Train Loss: 0.8592, Val Loss: 0.8741
batch size: (898, 898)
✅ Epoch 13: New best model saved with val_loss = 0.8546
Epoch 13, accuracy: 0.6505
batch size: (900, 900)
✅ Epoch 14: New best model saved with val_loss = 0.8399
Epoch 14, accuracy: 0.6743
Epoch 14, Train Loss: 0.8822, Val Loss: 0.8399
batch size: (884, 884)
✅ Epoch 15: New best model saved with val_loss = 0.8195
Epoch 15, accuracy: 0.6950
batch size: (900, 900)
✅ Epoch 16: New best model saved with val_loss = 0.8033
Epoch 16, accuracy: 0.7023
Epoch 16, Train Loss: 0.8135, Val Loss: 0.8033
batch size: (903, 903)
✅ Epoch 17: New best model saved with val_loss = 0.7960
Epoch 17, accuracy: 0.7143
batch size: (884, 884)
✅ Epoch 18: New best model saved with val_loss = 0.7823
Epoch 18, accuracy: 0.7200
Epoch 18, Train Loss: 0.7419, Val Loss: 0.7823
batch size: (889, 889)
✅ Epoch 19: New best model saved with val_loss = 0.7661
Epoch 19, accuracy: 0.7288
batch size: (911, 911)
✅ Epoch 20: New best model saved with val_loss = 0.7528
Epoch 20, accuracy: 0.7279
Epoch 20, Train Loss: 0.7372, Val Loss: 0.7528
batch size: (903, 903)
✅ Epoch 21: New best model saved with val_loss = 0.7367
Epoch 21, accuracy: 0.7199
batch size: (895, 895)
✅ Epoch 22: New best model saved with val_loss = 0.7317
Epoch 22, accuracy: 0.7121
Epoch 22, Train Loss: 0.6794, Val Loss: 0.7317
batch size: (889, 889)
✅ Epoch 23: New best model saved with val_loss = 0.7229
Epoch 23, accuracy: 0.6951
batch size: (912, 912)
✅ Epoch 24: New best model saved with val_loss = 0.7189
Epoch 24, accuracy: 0.6902
Epoch 24, Train Loss: 0.7441, Val Loss: 0.7189
batch size: (916, 916)
✅ Epoch 25: New best model saved with val_loss = 0.7171
Epoch 25, accuracy: 0.6928
batch size: (893, 893)
✅ Epoch 26: New best model saved with val_loss = 0.7014
Epoch 26, accuracy: 0.7002
Epoch 26, Train Loss: 0.6304, Val Loss: 0.7014
batch size: (906, 906)
✅ Epoch 27: New best model saved with val_loss = 0.6897
Epoch 27, accuracy: 0.7102
batch size: (896, 896)
✅ Epoch 28: New best model saved with val_loss = 0.6859
Epoch 28, accuracy: 0.7125
Epoch 28, Train Loss: 0.5842, Val Loss: 0.6859
batch size: (897, 897)
✅ Epoch 29: New best model saved with val_loss = 0.6819
Epoch 29, accuracy: 0.7188
batch size: (901, 901)
Epoch 30, accuracy: 0.7148
Epoch 30, Train Loss: 0.5569, Val Loss: 0.6840
batch size: (915, 915)
✅ Epoch 31: New best model saved with val_loss = 0.6786
Epoch 31, accuracy: 0.7004
batch size: (906, 906)
✅ Epoch 32: New best model saved with val_loss = 0.6782
Epoch 32, accuracy: 0.6934
Epoch 32, Train Loss: 0.6054, Val Loss: 0.6782
batch size: (893, 893)
✅ Epoch 33: New best model saved with val_loss = 0.6781
Epoch 33, accuracy: 0.6941
batch size: (896, 896)
Epoch 34, accuracy: 0.7025
Epoch 34, Train Loss: 0.5826, Val Loss: 0.6851
batch size: (903, 903)
✅ Epoch 35: New best model saved with val_loss = 0.6731
Epoch 35, accuracy: 0.7144
batch size: (897, 897)
✅ Epoch 36: New best model saved with val_loss = 0.6644
Epoch 36, accuracy: 0.7235
Epoch 36, Train Loss: 0.5382, Val Loss: 0.6644
batch size: (890, 890)
Epoch 37, accuracy: 0.7218
batch size: (880, 880)
Epoch 38, accuracy: 0.7208
Epoch 38, Train Loss: 0.4449, Val Loss: 0.6703
batch size: (882, 882)
✅ Epoch 39: New best model saved with val_loss = 0.6635
Epoch 39, accuracy: 0.7183
batch size: (911, 911)
✅ Epoch 40: New best model saved with val_loss = 0.6630
Epoch 40, accuracy: 0.7176
Epoch 40, Train Loss: 0.5293, Val Loss: 0.6630
batch size: (914, 914)
Epoch 41, accuracy: 0.7136
batch size: (886, 886)
Epoch 42, accuracy: 0.7034
Epoch 42, Train Loss: 0.6046, Val Loss: 0.6756
batch size: (907, 907)
Epoch 43, accuracy: 0.6910
batch size: (915, 915)
Epoch 44, accuracy: 0.6736
Epoch 44, Train Loss: 0.3599, Val Loss: 0.6930
batch size: (899, 899)
Epoch 45, accuracy: 0.6685
batch size: (888, 888)
Epoch 46, accuracy: 0.6821
Epoch 46, Train Loss: 0.5081, Val Loss: 0.6820
batch size: (903, 903)
Epoch 47, accuracy: 0.6863
batch size: (898, 898)
Epoch 48, accuracy: 0.6864
Epoch 48, Train Loss: 0.4549, Val Loss: 0.6866
batch size: (894, 894)
Epoch 49, accuracy: 0.6909
Loaded best model with val_loss = 0.6629512906074524
test :accuracy 0.7156, f1_macro: 0.6890, f1_micro: 0.7156, auc: 0.8503
Training resGCN with 8 layers...
可训练参数: 531986_resGCN
不可训练参数: 0
batch size: (890, 890)
✅ Epoch 0: New best model saved with val_loss = 1.0992
Epoch 0, accuracy: 0.1668
Epoch 0, Train Loss: 1.1715, Val Loss: 1.0992
batch size: (906, 906)
Epoch 1, accuracy: 0.4274
batch size: (896, 896)
Epoch 2, accuracy: 0.4296
Epoch 2, Train Loss: 1.0986, Val Loss: 1.0998
batch size: (902, 902)
Epoch 3, accuracy: 0.4322
batch size: (910, 910)
Epoch 4, accuracy: 0.4288
Epoch 4, Train Loss: 1.0987, Val Loss: 1.1000
batch size: (914, 914)
Epoch 5, accuracy: 0.4271
batch size: (903, 903)
Epoch 6, accuracy: 0.4324
Epoch 6, Train Loss: 1.0987, Val Loss: 1.1000
batch size: (877, 877)
Epoch 7, accuracy: 0.4298
batch size: (908, 908)
Epoch 8, accuracy: 0.4278
Epoch 8, Train Loss: 1.0987, Val Loss: 1.1000
batch size: (918, 918)
Epoch 9, accuracy: 0.4258
batch size: (898, 898)
Epoch 10, accuracy: 0.4262
Epoch 10, Train Loss: 1.0987, Val Loss: 1.0999
batch size: (892, 892)
Epoch 11, accuracy: 0.4299
batch size: (902, 902)
Epoch 12, accuracy: 0.4263
Epoch 12, Train Loss: 1.0987, Val Loss: 1.0999
batch size: (895, 895)
Epoch 13, accuracy: 0.4303
batch size: (915, 915)
Epoch 14, accuracy: 0.4257
Epoch 14, Train Loss: 1.0987, Val Loss: 1.0999
batch size: (898, 898)
Epoch 15, accuracy: 0.4245
batch size: (895, 895)
Epoch 16, accuracy: 0.4303
Epoch 16, Train Loss: 1.0987, Val Loss: 1.0999
batch size: (906, 906)
Epoch 17, accuracy: 0.4305
batch size: (910, 910)
Epoch 18, accuracy: 0.4277
Epoch 18, Train Loss: 1.0987, Val Loss: 1.0999
batch size: (898, 898)
Epoch 19, accuracy: 0.4308
batch size: (907, 907)
Epoch 20, accuracy: 0.4263
Epoch 20, Train Loss: 1.0987, Val Loss: 1.0999
batch size: (900, 900)
Epoch 21, accuracy: 0.4305
batch size: (894, 894)
Epoch 22, accuracy: 0.4265
Epoch 22, Train Loss: 1.0987, Val Loss: 1.0999
batch size: (899, 899)
Epoch 23, accuracy: 0.4304
batch size: (909, 909)
Epoch 24, accuracy: 0.4265
Epoch 24, Train Loss: 1.0987, Val Loss: 1.0999
batch size: (892, 892)
Epoch 25, accuracy: 0.4320
batch size: (891, 891)
Epoch 26, accuracy: 0.4306
Epoch 26, Train Loss: 1.0987, Val Loss: 1.0999
batch size: (901, 901)
Epoch 27, accuracy: 0.4297
batch size: (907, 907)
Epoch 28, accuracy: 0.4310
Epoch 28, Train Loss: 1.0987, Val Loss: 1.0999
batch size: (899, 899)
Epoch 29, accuracy: 0.4318
batch size: (910, 910)
Epoch 30, accuracy: 0.4292
Epoch 30, Train Loss: 1.0987, Val Loss: 1.0999
batch size: (894, 894)
Epoch 31, accuracy: 0.4288
batch size: (899, 899)
Epoch 32, accuracy: 0.4290
Epoch 32, Train Loss: 1.0987, Val Loss: 1.0999
batch size: (872, 872)
Epoch 33, accuracy: 0.4302
batch size: (899, 899)
Epoch 34, accuracy: 0.4275
Epoch 34, Train Loss: 1.0987, Val Loss: 1.0999
batch size: (908, 908)
Epoch 35, accuracy: 0.4277
batch size: (907, 907)
Epoch 36, accuracy: 0.4286
Epoch 36, Train Loss: 1.0987, Val Loss: 1.0999
batch size: (910, 910)
Epoch 37, accuracy: 0.4288
batch size: (892, 892)
Epoch 38, accuracy: 0.4312
Epoch 38, Train Loss: 1.0987, Val Loss: 1.0999
batch size: (897, 897)
Epoch 39, accuracy: 0.4267
batch size: (877, 877)
Epoch 40, accuracy: 0.4289
/root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
/root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
Epoch 40, Train Loss: 1.0987, Val Loss: 1.0999
batch size: (890, 890)
Epoch 41, accuracy: 0.4289
batch size: (913, 913)
Epoch 42, accuracy: 0.4285
Epoch 42, Train Loss: 1.0987, Val Loss: 1.0999
batch size: (894, 894)
Epoch 43, accuracy: 0.4271
batch size: (902, 902)
Epoch 44, accuracy: 0.4301
Epoch 44, Train Loss: 1.0987, Val Loss: 1.0999
batch size: (906, 906)
Epoch 45, accuracy: 0.4311
batch size: (918, 918)
Epoch 46, accuracy: 0.4309
Epoch 46, Train Loss: 1.0987, Val Loss: 1.0999
batch size: (909, 909)
Epoch 47, accuracy: 0.4291
batch size: (890, 890)
Epoch 48, accuracy: 0.4288
Epoch 48, Train Loss: 1.0987, Val Loss: 1.0999
batch size: (876, 876)
Epoch 49, accuracy: 0.4292
Loaded best model with val_loss = 1.0991699695587158
test :accuracy 0.1666, f1_macro: 0.0952, f1_micro: 0.1666, auc: 0.5000
Training resGCN with 32 layers...
可训练参数: 2129426_resGCN
不可训练参数: 0
batch size: (899, 899)
✅ Epoch 0: New best model saved with val_loss = 1.9471
Epoch 0, accuracy: 0.4322
Epoch 0, Train Loss: 205699.2031, Val Loss: 1.9471
batch size: (912, 912)
✅ Epoch 1: New best model saved with val_loss = 1.1001
Epoch 1, accuracy: 0.1702
batch size: (897, 897)
Epoch 2, accuracy: 0.1673
Epoch 2, Train Loss: 1.0986, Val Loss: 1.1008
batch size: (927, 927)
Epoch 3, accuracy: 0.1679
batch size: (893, 893)
Epoch 4, accuracy: 0.1667
Epoch 4, Train Loss: 1.0987, Val Loss: 1.1018
batch size: (884, 884)
Epoch 5, accuracy: 0.1666
batch size: (904, 904)
Epoch 6, accuracy: 0.1658
Epoch 6, Train Loss: 1.0987, Val Loss: 1.1025
batch size: (915, 915)
Epoch 7, accuracy: 0.1699
batch size: (894, 894)
Epoch 8, accuracy: 0.1672
Epoch 8, Train Loss: 1.0987, Val Loss: 1.1029
batch size: (910, 910)
Epoch 9, accuracy: 0.1662
batch size: (894, 894)
Epoch 10, accuracy: 0.1632
Epoch 10, Train Loss: 1.0987, Val Loss: 1.1029
batch size: (905, 905)
Epoch 11, accuracy: 0.1643
batch size: (896, 896)
Epoch 12, accuracy: 0.1689
Epoch 12, Train Loss: 1.0987, Val Loss: 1.1029
batch size: (884, 884)
Epoch 13, accuracy: 0.1687
batch size: (903, 903)
Epoch 14, accuracy: 0.1700
Epoch 14, Train Loss: 1.0987, Val Loss: 1.1029
batch size: (916, 916)
Epoch 15, accuracy: 0.1678
batch size: (900, 900)
Epoch 16, accuracy: 0.1653
Epoch 16, Train Loss: 1.0987, Val Loss: 1.1029
batch size: (903, 903)
Epoch 17, accuracy: 0.1664
batch size: (882, 882)
Epoch 18, accuracy: 0.1656
Epoch 18, Train Loss: 1.0987, Val Loss: 1.1029
batch size: (904, 904)
Epoch 19, accuracy: 0.1664
batch size: (892, 892)
Epoch 20, accuracy: 0.1691
Epoch 20, Train Loss: 1.0987, Val Loss: 1.1029
batch size: (884, 884)
Epoch 21, accuracy: 0.1697
batch size: (887, 887)
Epoch 22, accuracy: 0.1698
Epoch 22, Train Loss: 1.0987, Val Loss: 1.1029
batch size: (894, 894)
Epoch 23, accuracy: 0.1673
batch size: (920, 920)
Epoch 24, accuracy: 0.1693
Epoch 24, Train Loss: 1.0987, Val Loss: 1.1029
batch size: (898, 898)
Epoch 25, accuracy: 0.1700
batch size: (902, 902)
Epoch 26, accuracy: 0.1646
Epoch 26, Train Loss: 1.0987, Val Loss: 1.1029
batch size: (900, 900)
Epoch 27, accuracy: 0.1668
batch size: (903, 903)
Epoch 28, accuracy: 0.1700
Epoch 28, Train Loss: 1.0987, Val Loss: 1.1029
batch size: (925, 925)
Epoch 29, accuracy: 0.1676
batch size: (902, 902)
Epoch 30, accuracy: 0.1693
Epoch 30, Train Loss: 1.0987, Val Loss: 1.1029
batch size: (890, 890)
Epoch 31, accuracy: 0.1668
batch size: (871, 871)
Epoch 32, accuracy: 0.1678
Epoch 32, Train Loss: 1.0987, Val Loss: 1.1029
batch size: (884, 884)
Epoch 33, accuracy: 0.1665
batch size: (910, 910)
Epoch 34, accuracy: 0.1690
Epoch 34, Train Loss: 1.0987, Val Loss: 1.1029
batch size: (901, 901)
Epoch 35, accuracy: 0.1661
batch size: (909, 909)
Epoch 36, accuracy: 0.1671
Epoch 36, Train Loss: 1.0987, Val Loss: 1.1029
batch size: (886, 886)
Epoch 37, accuracy: 0.1669
batch size: (890, 890)
Epoch 38, accuracy: 0.1662
Epoch 38, Train Loss: 1.0987, Val Loss: 1.1029
batch size: (884, 884)
Epoch 39, accuracy: 0.1675
batch size: (907, 907)
Epoch 40, accuracy: 0.1672
Epoch 40, Train Loss: 1.0987, Val Loss: 1.1029
batch size: (889, 889)
Epoch 41, accuracy: 0.1667
batch size: (906, 906)
Epoch 42, accuracy: 0.1681
Epoch 42, Train Loss: 1.0987, Val Loss: 1.1029
batch size: (904, 904)
Epoch 43, accuracy: 0.1667
batch size: (900, 900)
Epoch 44, accuracy: 0.1687
Epoch 44, Train Loss: 1.0987, Val Loss: 1.1029
batch size: (890, 890)
Epoch 45, accuracy: 0.1676
batch size: (878, 878)
Epoch 46, accuracy: 0.1685
Epoch 46, Train Loss: 1.0987, Val Loss: 1.1029
batch size: (885, 885)
Epoch 47, accuracy: 0.1649
batch size: (905, 905)
Epoch 48, accuracy: 0.1687
Epoch 48, Train Loss: 1.0987, Val Loss: 1.1029
batch size: (900, 900)
Epoch 49, accuracy: 0.1686
Loaded best model with val_loss = 1.1000608205795288
test :accuracy 0.1680, f1_macro: 0.0959, f1_micro: 0.1680, auc: 0.5000
Training GINConv with 2 layers...
可训练参数: 99979_GINConv
不可训练参数: 0
batch size: (886, 886)
✅ Epoch 0: New best model saved with val_loss = 1.1534
Epoch 0, accuracy: 0.1666
Epoch 0, Train Loss: 2.0400, Val Loss: 1.1534
batch size: (877, 877)
✅ Epoch 1: New best model saved with val_loss = 1.1279
Epoch 1, accuracy: 0.1672
batch size: (917, 917)
✅ Epoch 2: New best model saved with val_loss = 1.1125
Epoch 2, accuracy: 0.1665
Epoch 2, Train Loss: 0.8064, Val Loss: 1.1125
batch size: (888, 888)
✅ Epoch 3: New best model saved with val_loss = 1.0991
Epoch 3, accuracy: 0.2007
batch size: (901, 901)
✅ Epoch 4: New best model saved with val_loss = 1.0829
Epoch 4, accuracy: 0.2392
Epoch 4, Train Loss: 0.3976, Val Loss: 1.0829
batch size: (900, 900)
✅ Epoch 5: New best model saved with val_loss = 1.0601
Epoch 5, accuracy: 0.2573
batch size: (921, 921)
✅ Epoch 6: New best model saved with val_loss = 1.0318
Epoch 6, accuracy: 0.2661
Epoch 6, Train Loss: 0.1891, Val Loss: 1.0318
batch size: (890, 890)
✅ Epoch 7: New best model saved with val_loss = 0.9973
Epoch 7, accuracy: 0.2749
batch size: (918, 918)
✅ Epoch 8: New best model saved with val_loss = 0.9648
Epoch 8, accuracy: 0.2829
Epoch 8, Train Loss: 0.0895, Val Loss: 0.9648
batch size: (889, 889)
✅ Epoch 9: New best model saved with val_loss = 0.9304
Epoch 9, accuracy: 0.2974
batch size: (914, 914)
✅ Epoch 10: New best model saved with val_loss = 0.9010
Epoch 10, accuracy: 0.3540
Epoch 10, Train Loss: 0.0451, Val Loss: 0.9010
batch size: (893, 893)
✅ Epoch 11: New best model saved with val_loss = 0.8642
Epoch 11, accuracy: 0.4218
batch size: (910, 910)
✅ Epoch 12: New best model saved with val_loss = 0.8405
Epoch 12, accuracy: 0.4594
Epoch 12, Train Loss: 0.0236, Val Loss: 0.8405
batch size: (891, 891)
✅ Epoch 13: New best model saved with val_loss = 0.8120
Epoch 13, accuracy: 0.4890
batch size: (897, 897)
✅ Epoch 14: New best model saved with val_loss = 0.7898
Epoch 14, accuracy: 0.5130
Epoch 14, Train Loss: 0.0073, Val Loss: 0.7898
batch size: (893, 893)
✅ Epoch 15: New best model saved with val_loss = 0.7628
Epoch 15, accuracy: 0.5284
batch size: (906, 906)
✅ Epoch 16: New best model saved with val_loss = 0.7411
Epoch 16, accuracy: 0.5444
Epoch 16, Train Loss: 0.0047, Val Loss: 0.7411
batch size: (903, 903)
✅ Epoch 17: New best model saved with val_loss = 0.7296
Epoch 17, accuracy: 0.5676
batch size: (890, 890)
✅ Epoch 18: New best model saved with val_loss = 0.7109
Epoch 18, accuracy: 0.5835
Epoch 18, Train Loss: 0.0024, Val Loss: 0.7109
batch size: (892, 892)
Epoch 19, accuracy: 0.5993
batch size: (906, 906)
Epoch 20, accuracy: 0.6156
Epoch 20, Train Loss: 0.0009, Val Loss: 0.7123
batch size: (898, 898)
Epoch 21, accuracy: 0.6287
batch size: (909, 909)
Epoch 22, accuracy: 0.6417
Epoch 22, Train Loss: 0.0004, Val Loss: 0.7316
batch size: (892, 892)
Epoch 23, accuracy: 0.6479
batch size: (898, 898)
Epoch 24, accuracy: 0.6571
Epoch 24, Train Loss: 0.0002, Val Loss: 0.7357
batch size: (902, 902)
Epoch 25, accuracy: 0.6601
batch size: (905, 905)
Epoch 26, accuracy: 0.6648
Epoch 26, Train Loss: 0.0003, Val Loss: 0.7467
batch size: (911, 911)
Epoch 27, accuracy: 0.6697
batch size: (897, 897)
Epoch 28, accuracy: 0.6728
Epoch 28, Train Loss: 0.0008, Val Loss: 0.7755
batch size: (915, 915)
Epoch 29, accuracy: 0.6746
batch size: (887, 887)
/root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
/root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
Epoch 30, accuracy: 0.6770
Epoch 30, Train Loss: 0.0002, Val Loss: 0.8193
batch size: (905, 905)
Epoch 31, accuracy: 0.6785
batch size: (905, 905)
Epoch 32, accuracy: 0.6803
Epoch 32, Train Loss: 0.0002, Val Loss: 0.8226
batch size: (895, 895)
Epoch 33, accuracy: 0.6815
batch size: (887, 887)
Epoch 34, accuracy: 0.6843
Epoch 34, Train Loss: 0.0006, Val Loss: 0.8817
batch size: (899, 899)
Epoch 35, accuracy: 0.6885
batch size: (912, 912)
Epoch 36, accuracy: 0.6907
Epoch 36, Train Loss: 0.0002, Val Loss: 0.9607
batch size: (886, 886)
Epoch 37, accuracy: 0.6895
batch size: (903, 903)
Epoch 38, accuracy: 0.6927
Epoch 38, Train Loss: 0.0002, Val Loss: 1.0255
batch size: (883, 883)
Epoch 39, accuracy: 0.6909
batch size: (882, 882)
Epoch 40, accuracy: 0.6933
Epoch 40, Train Loss: 0.0001, Val Loss: 1.0567
batch size: (893, 893)
Epoch 41, accuracy: 0.6956
batch size: (902, 902)
Epoch 42, accuracy: 0.6976
Epoch 42, Train Loss: 0.0003, Val Loss: 1.0990
batch size: (895, 895)
Epoch 43, accuracy: 0.6969
batch size: (905, 905)
Epoch 44, accuracy: 0.6992
Epoch 44, Train Loss: 0.0002, Val Loss: 1.1802
batch size: (895, 895)
Epoch 45, accuracy: 0.6981
batch size: (917, 917)
Epoch 46, accuracy: 0.7041
Epoch 46, Train Loss: 0.0006, Val Loss: 1.2973
batch size: (904, 904)
Epoch 47, accuracy: 0.7027
batch size: (890, 890)
Epoch 48, accuracy: 0.7030
Epoch 48, Train Loss: 0.0003, Val Loss: 1.3018
batch size: (900, 900)
Epoch 49, accuracy: 0.7036
Loaded best model with val_loss = 0.7108989953994751
test :accuracy 0.5837, f1_macro: 0.5564, f1_micro: 0.5837, auc: 0.8471
Training GINConv with 8 layers...
可训练参数: 300427_GINConv
不可训练参数: 0
batch size: (919, 919)
✅ Epoch 0: New best model saved with val_loss = 1.1691
Epoch 0, accuracy: 0.3566
Epoch 0, Train Loss: 2.4529, Val Loss: 1.1691
batch size: (884, 884)
Epoch 1, accuracy: 0.4062
batch size: (897, 897)
Epoch 2, accuracy: 0.4027
Epoch 2, Train Loss: 1.8550, Val Loss: 1.8225
batch size: (872, 872)
Epoch 3, accuracy: 0.3541
batch size: (893, 893)
Epoch 4, accuracy: 0.3592
Epoch 4, Train Loss: 1.0138, Val Loss: 1.2722
batch size: (914, 914)
✅ Epoch 5: New best model saved with val_loss = 1.1501
Epoch 5, accuracy: 0.3560
batch size: (912, 912)
✅ Epoch 6: New best model saved with val_loss = 1.1138
Epoch 6, accuracy: 0.4009
Epoch 6, Train Loss: 0.9931, Val Loss: 1.1138
batch size: (911, 911)
✅ Epoch 7: New best model saved with val_loss = 1.1087
Epoch 7, accuracy: 0.4053
batch size: (920, 920)
✅ Epoch 8: New best model saved with val_loss = 1.1028
Epoch 8, accuracy: 0.3998
Epoch 8, Train Loss: 0.9568, Val Loss: 1.1028
batch size: (913, 913)
✅ Epoch 9: New best model saved with val_loss = 1.1023
Epoch 9, accuracy: 0.4012
batch size: (889, 889)
✅ Epoch 10: New best model saved with val_loss = 1.0976
Epoch 10, accuracy: 0.4025
Epoch 10, Train Loss: 0.8906, Val Loss: 1.0976
batch size: (904, 904)
Epoch 11, accuracy: 0.4029
batch size: (923, 923)
Epoch 12, accuracy: 0.4003
Epoch 12, Train Loss: 0.8286, Val Loss: 1.1054
batch size: (886, 886)
Epoch 13, accuracy: 0.4018
batch size: (906, 906)
Epoch 14, accuracy: 0.4029
Epoch 14, Train Loss: 0.8471, Val Loss: 1.1086
batch size: (894, 894)
Epoch 15, accuracy: 0.3964
batch size: (901, 901)
Epoch 16, accuracy: 0.4059
Epoch 16, Train Loss: 0.7419, Val Loss: 1.0997
batch size: (900, 900)
Epoch 17, accuracy: 0.3987
batch size: (896, 896)
Epoch 18, accuracy: 0.4010
Epoch 18, Train Loss: 0.7807, Val Loss: 1.1006
batch size: (911, 911)
✅ Epoch 19: New best model saved with val_loss = 1.0947
Epoch 19, accuracy: 0.4019
batch size: (917, 917)
Epoch 20, accuracy: 0.4013
Epoch 20, Train Loss: 0.6927, Val Loss: 1.1018
batch size: (909, 909)
✅ Epoch 21: New best model saved with val_loss = 1.0929
Epoch 21, accuracy: 0.4030
batch size: (903, 903)
Epoch 22, accuracy: 0.4018
Epoch 22, Train Loss: 0.7256, Val Loss: 1.0966
batch size: (908, 908)
Epoch 23, accuracy: 0.4031
batch size: (905, 905)
Epoch 24, accuracy: 0.3986
Epoch 24, Train Loss: 0.7375, Val Loss: 1.0956
batch size: (899, 899)
Epoch 25, accuracy: 0.4084
batch size: (896, 896)
Epoch 26, accuracy: 0.4045
Epoch 26, Train Loss: 0.7514, Val Loss: 1.0930
batch size: (880, 880)
Epoch 27, accuracy: 0.4001
batch size: (920, 920)
Epoch 28, accuracy: 0.4024
Epoch 28, Train Loss: 0.7581, Val Loss: 1.0931
batch size: (913, 913)
✅ Epoch 29: New best model saved with val_loss = 1.0915
Epoch 29, accuracy: 0.4016
batch size: (901, 901)
✅ Epoch 30: New best model saved with val_loss = 1.0896
Epoch 30, accuracy: 0.4035
Epoch 30, Train Loss: 0.7346, Val Loss: 1.0896
batch size: (901, 901)
✅ Epoch 31: New best model saved with val_loss = 1.0877
Epoch 31, accuracy: 0.3981
batch size: (904, 904)
Epoch 32, accuracy: 0.4026
Epoch 32, Train Loss: 0.7233, Val Loss: 1.0911
batch size: (920, 920)
Epoch 33, accuracy: 0.3992
batch size: (906, 906)
Epoch 34, accuracy: 0.4039
Epoch 34, Train Loss: 0.7457, Val Loss: 1.0946
batch size: (899, 899)
Epoch 35, accuracy: 0.3996
batch size: (912, 912)
Epoch 36, accuracy: 0.4022
Epoch 36, Train Loss: 0.7014, Val Loss: 1.0940
batch size: (888, 888)
Epoch 37, accuracy: 0.4023
batch size: (907, 907)
Epoch 38, accuracy: 0.4019
Epoch 38, Train Loss: 0.7126, Val Loss: 1.0907
batch size: (902, 902)
Epoch 39, accuracy: 0.3994
batch size: (907, 907)
Epoch 40, accuracy: 0.4007
Epoch 40, Train Loss: 0.7197, Val Loss: 1.0938
batch size: (882, 882)
Epoch 41, accuracy: 0.4007
batch size: (901, 901)
Epoch 42, accuracy: 0.4000
Epoch 42, Train Loss: 0.7246, Val Loss: 1.0891
batch size: (917, 917)
Epoch 43, accuracy: 0.3986
batch size: (911, 911)
Epoch 44, accuracy: 0.4032
Epoch 44, Train Loss: 0.7014, Val Loss: 1.0894
batch size: (900, 900)
Epoch 45, accuracy: 0.4069
batch size: (918, 918)
Epoch 46, accuracy: 0.4025
Epoch 46, Train Loss: 0.6914, Val Loss: 1.0959
batch size: (893, 893)
Epoch 47, accuracy: 0.4068
batch size: (897, 897)
Epoch 48, accuracy: 0.4025
Epoch 48, Train Loss: 0.7391, Val Loss: 1.0931
batch size: (898, 898)
Epoch 49, accuracy: 0.4010
Loaded best model with val_loss = 1.0876818895339966
test :accuracy 0.4059, f1_macro: 0.1940, f1_micro: 0.4059, auc: 0.6074
Training GINConv with 32 layers...
可训练参数: 1102219_GINConv
不可训练参数: 0
batch size: (887, 887)
✅ Epoch 0: New best model saved with val_loss = 5416.4790
Epoch 0, accuracy: 0.1646
Epoch 0, Train Loss: 1.7086, Val Loss: 5416.4790
batch size: (901, 901)
✅ Epoch 1: New best model saved with val_loss = 73.6786
Epoch 1, accuracy: 0.4307
batch size: (908, 908)
✅ Epoch 2: New best model saved with val_loss = 1.6710
Epoch 2, accuracy: 0.4300
Epoch 2, Train Loss: 2.1775, Val Loss: 1.6710
batch size: (902, 902)
✅ Epoch 3: New best model saved with val_loss = 1.5774
Epoch 3, accuracy: 0.4212
batch size: (901, 901)
Epoch 4, accuracy: 0.4054
Epoch 4, Train Loss: 1.7222, Val Loss: 2.4969
batch size: (882, 882)
✅ Epoch 5: New best model saved with val_loss = 1.1929
Epoch 5, accuracy: 0.4013
batch size: (908, 908)
Epoch 6, accuracy: 0.4057
Epoch 6, Train Loss: 1.4010, Val Loss: 1.4069
batch size: (898, 898)
Epoch 7, accuracy: 0.4021
batch size: (905, 905)
✅ Epoch 8: New best model saved with val_loss = 1.1506
Epoch 8, accuracy: 0.4014
Epoch 8, Train Loss: 1.1438, Val Loss: 1.1506
batch size: (918, 918)
Epoch 9, accuracy: 0.4016
batch size: (898, 898)
Epoch 10, accuracy: 0.4030
Epoch 10, Train Loss: 1.1949, Val Loss: 1.1632
batch size: (895, 895)
Epoch 11, accuracy: 0.3547
batch size: (877, 877)
Epoch 12, accuracy: 0.3558
Epoch 12, Train Loss: 1.1919, Val Loss: 1.1925
batch size: (903, 903)
Epoch 13, accuracy: 0.4003
batch size: (910, 910)
Epoch 14, accuracy: 0.4000
Epoch 14, Train Loss: 1.0728, Val Loss: 1.1665
batch size: (900, 900)
Epoch 15, accuracy: 0.4000
batch size: (904, 904)
✅ Epoch 16: New best model saved with val_loss = 1.1320
Epoch 16, accuracy: 0.4029
Epoch 16, Train Loss: 1.0657, Val Loss: 1.1320
batch size: (899, 899)
Epoch 17, accuracy: 0.4007
batch size: (887, 887)
Epoch 18, accuracy: 0.3978
Epoch 18, Train Loss: 1.0731, Val Loss: 1.1459
batch size: (917, 917)
Epoch 19, accuracy: 0.3998
batch size: (901, 901)
Epoch 20, accuracy: 0.4045
Epoch 20, Train Loss: 1.0953, Val Loss: 1.1503
/root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
/root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
batch size: (898, 898)
Epoch 21, accuracy: 0.4049
batch size: (909, 909)
Epoch 22, accuracy: 0.4007
Epoch 22, Train Loss: 1.0971, Val Loss: 1.1671
batch size: (896, 896)
Epoch 23, accuracy: 0.4027
batch size: (907, 907)
Epoch 24, accuracy: 0.3989
Epoch 24, Train Loss: 1.0835, Val Loss: 1.1640
batch size: (883, 883)
Epoch 25, accuracy: 0.4067
batch size: (901, 901)
Epoch 26, accuracy: 0.4044
Epoch 26, Train Loss: 1.1019, Val Loss: 1.1590
batch size: (912, 912)
Epoch 27, accuracy: 0.4041
batch size: (906, 906)
Epoch 28, accuracy: 0.3999
Epoch 28, Train Loss: 1.0622, Val Loss: 1.1656
batch size: (882, 882)
Epoch 29, accuracy: 0.4064
batch size: (900, 900)
Epoch 30, accuracy: 0.4028
Epoch 30, Train Loss: 1.0644, Val Loss: 1.1558
batch size: (899, 899)
Epoch 31, accuracy: 0.4033
batch size: (911, 911)
✅ Epoch 32: New best model saved with val_loss = 1.1257
Epoch 32, accuracy: 0.4010
Epoch 32, Train Loss: 1.1004, Val Loss: 1.1257
batch size: (914, 914)
Epoch 33, accuracy: 0.4031
batch size: (915, 915)
Epoch 34, accuracy: 0.4005
Epoch 34, Train Loss: 1.0751, Val Loss: 1.1447
batch size: (926, 926)
Epoch 35, accuracy: 0.4020
batch size: (900, 900)
Epoch 36, accuracy: 0.4038
Epoch 36, Train Loss: 1.1221, Val Loss: 1.1586
batch size: (920, 920)
Epoch 37, accuracy: 0.4034
batch size: (902, 902)
Epoch 38, accuracy: 0.4018
Epoch 38, Train Loss: 1.1182, Val Loss: 1.1366
batch size: (908, 908)
Epoch 39, accuracy: 0.3999
batch size: (883, 883)
Epoch 40, accuracy: 0.3980
Epoch 40, Train Loss: 1.0797, Val Loss: 1.1700
batch size: (892, 892)
Epoch 41, accuracy: 0.4031
batch size: (919, 919)
Epoch 42, accuracy: 0.4001
Epoch 42, Train Loss: 1.1077, Val Loss: 1.1609
batch size: (907, 907)
Epoch 43, accuracy: 0.4008
batch size: (929, 929)
Epoch 44, accuracy: 0.4036
Epoch 44, Train Loss: 1.1019, Val Loss: 1.1425
batch size: (881, 881)
Epoch 45, accuracy: 0.4044
batch size: (890, 890)
Epoch 46, accuracy: 0.3997
Epoch 46, Train Loss: 1.0827, Val Loss: 1.1548
batch size: (905, 905)
Epoch 47, accuracy: 0.4037
batch size: (901, 901)
Epoch 48, accuracy: 0.4053
Epoch 48, Train Loss: 1.1068, Val Loss: 1.1353
batch size: (902, 902)
Epoch 49, accuracy: 0.4044
Loaded best model with val_loss = 1.12566339969635
test :accuracy 0.4028, f1_macro: 0.1991, f1_micro: 0.4028, auc: 0.5037
Training mlp with 2 layers...
可训练参数: 83209_mlp
不可训练参数: 0
batch size: (878, 878)
✅ Epoch 0: New best model saved with val_loss = 1.0930
Epoch 0, accuracy: 0.4321
Epoch 0, Train Loss: 1.0999, Val Loss: 1.0930
batch size: (877, 877)
Epoch 1, accuracy: 0.6855
batch size: (907, 907)
Epoch 2, accuracy: 0.6125
Epoch 2, Train Loss: 1.0865, Val Loss: 1.0931
batch size: (889, 889)
✅ Epoch 3: New best model saved with val_loss = 1.0886
Epoch 3, accuracy: 0.6357
batch size: (883, 883)
✅ Epoch 4: New best model saved with val_loss = 1.0800
Epoch 4, accuracy: 0.6776
Epoch 4, Train Loss: 1.0546, Val Loss: 1.0800
batch size: (910, 910)
✅ Epoch 5: New best model saved with val_loss = 1.0676
Epoch 5, accuracy: 0.6930
batch size: (905, 905)
✅ Epoch 6: New best model saved with val_loss = 1.0527
Epoch 6, accuracy: 0.7034
Epoch 6, Train Loss: 0.9934, Val Loss: 1.0527
batch size: (902, 902)
✅ Epoch 7: New best model saved with val_loss = 1.0363
Epoch 7, accuracy: 0.7045
batch size: (867, 867)
✅ Epoch 8: New best model saved with val_loss = 1.0186
Epoch 8, accuracy: 0.7047
Epoch 8, Train Loss: 0.9001, Val Loss: 1.0186
batch size: (894, 894)
✅ Epoch 9: New best model saved with val_loss = 0.9993
Epoch 9, accuracy: 0.7023
batch size: (911, 911)
✅ Epoch 10: New best model saved with val_loss = 0.9780
Epoch 10, accuracy: 0.7014
Epoch 10, Train Loss: 0.7662, Val Loss: 0.9780
batch size: (911, 911)
✅ Epoch 11: New best model saved with val_loss = 0.9540
Epoch 11, accuracy: 0.6975
batch size: (906, 906)
✅ Epoch 12: New best model saved with val_loss = 0.9262
Epoch 12, accuracy: 0.7020
Epoch 12, Train Loss: 0.5936, Val Loss: 0.9262
batch size: (896, 896)
✅ Epoch 13: New best model saved with val_loss = 0.8951
Epoch 13, accuracy: 0.7037
batch size: (897, 897)
✅ Epoch 14: New best model saved with val_loss = 0.8639
Epoch 14, accuracy: 0.7044
Epoch 14, Train Loss: 0.4055, Val Loss: 0.8639
batch size: (893, 893)
✅ Epoch 15: New best model saved with val_loss = 0.8368
Epoch 15, accuracy: 0.7073
batch size: (906, 906)
✅ Epoch 16: New best model saved with val_loss = 0.8174
Epoch 16, accuracy: 0.7093
Epoch 16, Train Loss: 0.2378, Val Loss: 0.8174
batch size: (907, 907)
✅ Epoch 17: New best model saved with val_loss = 0.8075
Epoch 17, accuracy: 0.7086
batch size: (921, 921)
Epoch 18, accuracy: 0.7098
Epoch 18, Train Loss: 0.1161, Val Loss: 0.8076
batch size: (914, 914)
Epoch 19, accuracy: 0.7085
batch size: (908, 908)
Epoch 20, accuracy: 0.7111
Epoch 20, Train Loss: 0.0461, Val Loss: 0.8335
batch size: (880, 880)
Epoch 21, accuracy: 0.7036
batch size: (887, 887)
Epoch 22, accuracy: 0.7063
Epoch 22, Train Loss: 0.0155, Val Loss: 0.8794
batch size: (896, 896)
Epoch 23, accuracy: 0.7079
batch size: (908, 908)
Epoch 24, accuracy: 0.7061
Epoch 24, Train Loss: 0.0049, Val Loss: 0.9067
batch size: (896, 896)
Epoch 25, accuracy: 0.7064
batch size: (905, 905)
Epoch 26, accuracy: 0.7062
Epoch 26, Train Loss: 0.0045, Val Loss: 0.9098
batch size: (905, 905)
Epoch 27, accuracy: 0.7075
batch size: (902, 902)
Epoch 28, accuracy: 0.7061
Epoch 28, Train Loss: 0.0041, Val Loss: 0.9113
batch size: (907, 907)
Epoch 29, accuracy: 0.7054
batch size: (884, 884)
Epoch 30, accuracy: 0.7062
Epoch 30, Train Loss: 0.0038, Val Loss: 0.9116
batch size: (901, 901)
Epoch 31, accuracy: 0.7057
batch size: (883, 883)
Epoch 32, accuracy: 0.7042
Epoch 32, Train Loss: 0.0038, Val Loss: 0.9115
batch size: (890, 890)
Epoch 33, accuracy: 0.7063
batch size: (896, 896)
Epoch 34, accuracy: 0.7084
Epoch 34, Train Loss: 0.0038, Val Loss: 0.9113
batch size: (881, 881)
Epoch 35, accuracy: 0.7080
batch size: (897, 897)
Epoch 36, accuracy: 0.7024
Epoch 36, Train Loss: 0.0038, Val Loss: 0.9112
batch size: (895, 895)
Epoch 37, accuracy: 0.7052
batch size: (912, 912)
Epoch 38, accuracy: 0.7044
Epoch 38, Train Loss: 0.0038, Val Loss: 0.9112
batch size: (906, 906)
Epoch 39, accuracy: 0.7067
batch size: (897, 897)
Epoch 40, accuracy: 0.7058
Epoch 40, Train Loss: 0.0038, Val Loss: 0.9111
batch size: (913, 913)
Epoch 41, accuracy: 0.7076
batch size: (901, 901)
Epoch 42, accuracy: 0.7047
Epoch 42, Train Loss: 0.0038, Val Loss: 0.9111
batch size: (906, 906)
Epoch 43, accuracy: 0.7049
batch size: (890, 890)
Epoch 44, accuracy: 0.7036
Epoch 44, Train Loss: 0.0038, Val Loss: 0.9111
batch size: (893, 893)
Epoch 45, accuracy: 0.7071
batch size: (898, 898)
Epoch 46, accuracy: 0.7053
Epoch 46, Train Loss: 0.0038, Val Loss: 0.9111
batch size: (903, 903)
Epoch 47, accuracy: 0.7073
batch size: (903, 903)
Epoch 48, accuracy: 0.7074
Epoch 48, Train Loss: 0.0038, Val Loss: 0.9111
batch size: (913, 913)
Epoch 49, accuracy: 0.7070
Loaded best model with val_loss = 0.807518720626831
test :accuracy 0.7101, f1_macro: 0.7058, f1_micro: 0.7101, auc: 0.8486
Training mlp with 8 layers...
可训练参数: 184585_mlp
不可训练参数: 0
batch size: (903, 903)
✅ Epoch 0: New best model saved with val_loss = 1.1007
Epoch 0, accuracy: 0.4048
Epoch 0, Train Loss: 1.0988, Val Loss: 1.1007
batch size: (882, 882)
✅ Epoch 1: New best model saved with val_loss = 1.1004
Epoch 1, accuracy: 0.4054
batch size: (898, 898)
✅ Epoch 2: New best model saved with val_loss = 1.0988
Epoch 2, accuracy: 0.1646
Epoch 2, Train Loss: 1.0987, Val Loss: 1.0988
batch size: (899, 899)
✅ Epoch 3: New best model saved with val_loss = 1.0974
Epoch 3, accuracy: 0.4278
batch size: (904, 904)
✅ Epoch 4: New best model saved with val_loss = 1.0974
Epoch 4, accuracy: 0.4309
Epoch 4, Train Loss: 1.0987, Val Loss: 1.0974
batch size: (910, 910)
Epoch 5, accuracy: 0.4314
batch size: (900, 900)
Epoch 6, accuracy: 0.4347
Epoch 6, Train Loss: 1.0987, Val Loss: 1.0985
batch size: (890, 890)
Epoch 7, accuracy: 0.1682
batch size: (908, 908)
Epoch 8, accuracy: 0.4009
Epoch 8, Train Loss: 1.0986, Val Loss: 1.0991
batch size: (904, 904)
Epoch 9, accuracy: 0.4042
batch size: (903, 903)
/root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
/root/./pipeline/pipeline-Copy1.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
Epoch 10, accuracy: 0.4028
Epoch 10, Train Loss: 1.0986, Val Loss: 1.0991
batch size: (910, 910)
Epoch 11, accuracy: 0.4011
batch size: (892, 892)
Epoch 12, accuracy: 0.4035
Epoch 12, Train Loss: 1.0986, Val Loss: 1.0991
batch size: (875, 875)
Epoch 13, accuracy: 0.4010
batch size: (900, 900)
Epoch 14, accuracy: 0.4011
Epoch 14, Train Loss: 1.0986, Val Loss: 1.0991
batch size: (905, 905)
Epoch 15, accuracy: 0.4020
batch size: (909, 909)
Epoch 16, accuracy: 0.4002
Epoch 16, Train Loss: 1.0986, Val Loss: 1.0990
batch size: (882, 882)
Epoch 17, accuracy: 0.3996
batch size: (906, 906)
Epoch 18, accuracy: 0.4019
Epoch 18, Train Loss: 1.0986, Val Loss: 1.0990
batch size: (908, 908)
Epoch 19, accuracy: 0.4016
batch size: (903, 903)
Epoch 20, accuracy: 0.4006
Epoch 20, Train Loss: 1.0986, Val Loss: 1.0990
batch size: (917, 917)
Epoch 21, accuracy: 0.4010
batch size: (896, 896)
Epoch 22, accuracy: 0.4013
Epoch 22, Train Loss: 1.0986, Val Loss: 1.0990
batch size: (905, 905)
Epoch 23, accuracy: 0.4006
batch size: (908, 908)
Epoch 24, accuracy: 0.4067
Epoch 24, Train Loss: 1.0986, Val Loss: 1.0990
batch size: (907, 907)
Epoch 25, accuracy: 0.3995
batch size: (898, 898)
Epoch 26, accuracy: 0.4029
Epoch 26, Train Loss: 1.0986, Val Loss: 1.0990
batch size: (898, 898)
Epoch 27, accuracy: 0.4028
batch size: (893, 893)
Epoch 28, accuracy: 0.3995
Epoch 28, Train Loss: 1.0986, Val Loss: 1.0990
batch size: (877, 877)
Epoch 29, accuracy: 0.4043
batch size: (897, 897)
Epoch 30, accuracy: 0.4013
Epoch 30, Train Loss: 1.0986, Val Loss: 1.0990
batch size: (890, 890)
Epoch 31, accuracy: 0.4018
batch size: (913, 913)
Epoch 32, accuracy: 0.4026
Epoch 32, Train Loss: 1.0986, Val Loss: 1.0990
batch size: (902, 902)
Epoch 33, accuracy: 0.4014
batch size: (879, 879)
Epoch 34, accuracy: 0.3997
Epoch 34, Train Loss: 1.0986, Val Loss: 1.0990
batch size: (907, 907)
Epoch 35, accuracy: 0.4038
batch size: (915, 915)
Epoch 36, accuracy: 0.4033
Epoch 36, Train Loss: 1.0986, Val Loss: 1.0990
batch size: (894, 894)
Epoch 37, accuracy: 0.4017
batch size: (881, 881)
Epoch 38, accuracy: 0.4068
Epoch 38, Train Loss: 1.0986, Val Loss: 1.0990
batch size: (908, 908)
Epoch 39, accuracy: 0.3999
batch size: (912, 912)
Epoch 40, accuracy: 0.4047
Epoch 40, Train Loss: 1.0986, Val Loss: 1.0990
batch size: (884, 884)
Epoch 41, accuracy: 0.4035
batch size: (877, 877)
Epoch 42, accuracy: 0.4073
Epoch 42, Train Loss: 1.0986, Val Loss: 1.0990
batch size: (919, 919)
Epoch 43, accuracy: 0.4026
batch size: (901, 901)
Epoch 44, accuracy: 0.3998
Epoch 44, Train Loss: 1.0986, Val Loss: 1.0990
batch size: (912, 912)
Epoch 45, accuracy: 0.4044
batch size: (894, 894)
Epoch 46, accuracy: 0.4034
Epoch 46, Train Loss: 1.0986, Val Loss: 1.0990
batch size: (922, 922)
Epoch 47, accuracy: 0.3996
batch size: (896, 896)
Epoch 48, accuracy: 0.4038
Epoch 48, Train Loss: 1.0986, Val Loss: 1.0990
batch size: (891, 891)
Epoch 49, accuracy: 0.4035
Loaded best model with val_loss = 1.0973891019821167
test :accuracy 0.4318, f1_macro: 0.2010, f1_micro: 0.4318, auc: 0.4923
Training mlp with 32 layers...
可训练参数: 590089_mlp
不可训练参数: 0
batch size: (916, 916)
✅ Epoch 0: New best model saved with val_loss = 1.0945
Epoch 0, accuracy: 0.4301
Epoch 0, Train Loss: 1.1001, Val Loss: 1.0945
batch size: (906, 906)
✅ Epoch 1: New best model saved with val_loss = 1.0906
Epoch 1, accuracy: 0.3984
batch size: (881, 881)
Epoch 2, accuracy: 0.4016
Epoch 2, Train Loss: 1.0991, Val Loss: 1.0938
batch size: (904, 904)
Epoch 3, accuracy: 0.3995
batch size: (900, 900)
Epoch 4, accuracy: 0.1691
Epoch 4, Train Loss: 1.0986, Val Loss: 1.1014
batch size: (900, 900)
Epoch 5, accuracy: 0.1654
batch size: (893, 893)
Epoch 6, accuracy: 0.1679
Epoch 6, Train Loss: 1.0987, Val Loss: 1.1031
batch size: (885, 885)
Epoch 7, accuracy: 0.1665
batch size: (898, 898)
Epoch 8, accuracy: 0.1666
Epoch 8, Train Loss: 1.0987, Val Loss: 1.1022
batch size: (904, 904)
Epoch 9, accuracy: 0.1685
batch size: (904, 904)
Epoch 10, accuracy: 0.1663
Epoch 10, Train Loss: 1.0987, Val Loss: 1.1018
batch size: (910, 910)
Epoch 11, accuracy: 0.1673
batch size: (902, 902)
Epoch 12, accuracy: 0.1672
Epoch 12, Train Loss: 1.0987, Val Loss: 1.1013
batch size: (895, 895)
Epoch 13, accuracy: 0.1681
batch size: (898, 898)
Epoch 14, accuracy: 0.1690
Epoch 14, Train Loss: 1.0987, Val Loss: 1.1010
batch size: (912, 912)
Epoch 15, accuracy: 0.1676
batch size: (900, 900)
Epoch 16, accuracy: 0.1647
Epoch 16, Train Loss: 1.0987, Val Loss: 1.1010
batch size: (909, 909)
Epoch 17, accuracy: 0.1690
batch size: (904, 904)
Epoch 18, accuracy: 0.1680
Epoch 18, Train Loss: 1.0987, Val Loss: 1.1009
batch size: (899, 899)
Epoch 19, accuracy: 0.1685
batch size: (909, 909)
Epoch 20, accuracy: 0.1679
Epoch 20, Train Loss: 1.0987, Val Loss: 1.1009
batch size: (905, 905)
Epoch 21, accuracy: 0.1662
batch size: (910, 910)
Epoch 22, accuracy: 0.1685
Epoch 22, Train Loss: 1.0987, Val Loss: 1.1009
batch size: (915, 915)
Epoch 23, accuracy: 0.1658
batch size: (891, 891)
Epoch 24, accuracy: 0.1679
Epoch 24, Train Loss: 1.0987, Val Loss: 1.1009
batch size: (888, 888)
Epoch 25, accuracy: 0.1652
batch size: (899, 899)
Epoch 26, accuracy: 0.1669
Epoch 26, Train Loss: 1.0987, Val Loss: 1.1009
batch size: (904, 904)
Epoch 27, accuracy: 0.1685
batch size: (914, 914)
Epoch 28, accuracy: 0.1667
Epoch 28, Train Loss: 1.0987, Val Loss: 1.1009
batch size: (912, 912)
Epoch 29, accuracy: 0.1690
batch size: (889, 889)
Epoch 30, accuracy: 0.1688
Epoch 30, Train Loss: 1.0987, Val Loss: 1.1009
batch size: (887, 887)
Epoch 31, accuracy: 0.1677
batch size: (895, 895)
Epoch 32, accuracy: 0.1672
Epoch 32, Train Loss: 1.0987, Val Loss: 1.1009
batch size: (900, 900)
Epoch 33, accuracy: 0.1672
batch size: (883, 883)
Epoch 34, accuracy: 0.1696
Epoch 34, Train Loss: 1.0987, Val Loss: 1.1009
batch size: (892, 892)
Epoch 35, accuracy: 0.1702
batch size: (918, 918)
Epoch 36, accuracy: 0.1654
Epoch 36, Train Loss: 1.0987, Val Loss: 1.1009
batch size: (879, 879)
Epoch 37, accuracy: 0.1687
batch size: (892, 892)
Epoch 38, accuracy: 0.1701
Epoch 38, Train Loss: 1.0987, Val Loss: 1.1009
batch size: (907, 907)
Epoch 39, accuracy: 0.1688
batch size: (913, 913)
Epoch 40, accuracy: 0.1645
Epoch 40, Train Loss: 1.0987, Val Loss: 1.1009
batch size: (909, 909)
Epoch 41, accuracy: 0.1664
batch size: (907, 907)
Epoch 42, accuracy: 0.1698
Epoch 42, Train Loss: 1.0987, Val Loss: 1.1009
batch size: (896, 896)
Epoch 43, accuracy: 0.1661
batch size: (899, 899)
Epoch 44, accuracy: 0.1688
Epoch 44, Train Loss: 1.0987, Val Loss: 1.1009
batch size: (900, 900)
Epoch 45, accuracy: 0.1697
batch size: (917, 917)
Epoch 46, accuracy: 0.1675
Epoch 46, Train Loss: 1.0987, Val Loss: 1.1009
batch size: (898, 898)
Epoch 47, accuracy: 0.1651
batch size: (907, 907)
Epoch 48, accuracy: 0.1641
Epoch 48, Train Loss: 1.0987, Val Loss: 1.1009
batch size: (898, 898)
Epoch 49, accuracy: 0.1681
Loaded best model with val_loss = 1.0905513763427734
test :accuracy 0.4033, f1_macro: 0.1916, f1_micro: 0.4033, auc: 0.5000
Final Results: {'GCN_2_Pubmed': np.float64(0.720548921760827), 'GCN_8_Pubmed': np.float64(0.16834986474301172), 'GCN_32_Pubmed': np.float64(0.16651837352077586), 'GraphSAGE_2_Pubmed': np.float64(0.7150592973819646), 'GraphSAGE_8_Pubmed': np.float64(0.42872411489645956), 'GraphSAGE_32_Pubmed': np.float64(0.16520390070921986), 'GAT_2_Pubmed': np.float64(0.7314016531863834), 'GAT_8_Pubmed': np.float64(0.6724740216670352), 'GAT_32_Pubmed': np.float64(0.4021357063403782), 'JKNet_2_Pubmed': np.float64(0.42124277456647397), 'JKNet_8_Pubmed': np.float64(0.4002040725788563), 'JKNet_32_Pubmed': np.float64(0.4296107837886092), 'resGCN_2_Pubmed': np.float64(0.7155525846702318), 'resGCN_8_Pubmed': np.float64(0.16655618896106766), 'resGCN_32_Pubmed': np.float64(0.1679585398828301), 'GINConv_2_Pubmed': np.float64(0.5836568929352435), 'GINConv_8_Pubmed': np.float64(0.4058828725377617), 'GINConv_32_Pubmed': np.float64(0.4028146574614976), 'mlp_2_Pubmed': np.float64(0.7101190741649199), 'mlp_8_Pubmed': np.float64(0.4317848410757946), 'mlp_32_Pubmed': np.float64(0.4032568335346486)} ['133385_GCN_0', '532745_GCN_0', '2130185_GCN_0', '262153_GraphSAGE_0', '1054729_GraphSAGE_0', '4225033_GraphSAGE_0', '196495_GAT_0', '1090447_GAT_0', '4666255_GAT_0', '391942_JKNet_0', '1184518_JKNet_0', '4354822_JKNet_0', '132626_resGCN_0', '531986_resGCN_0', '2129426_resGCN_0', '99979_GINConv_0', '300427_GINConv_0', '1102219_GINConv_0', '83209_mlp_0', '184585_mlp_0', '590089_mlp_0']
GCN_2_Pubmed: Accuracy = 0.7180 ± 0.0060
GCN_8_Pubmed: Accuracy = 0.3430 ± 0.1512
GCN_32_Pubmed: Accuracy = 0.3183 ± 0.1370
GraphSAGE_2_Pubmed: Accuracy = 0.7139 ± 0.0023
GraphSAGE_8_Pubmed: Accuracy = 0.4031 ± 0.0237
GraphSAGE_32_Pubmed: Accuracy = 0.2539 ± 0.1326
GAT_2_Pubmed: Accuracy = 0.7362 ± 0.0042
GAT_8_Pubmed: Accuracy = 0.6973 ± 0.0215
GAT_32_Pubmed: Accuracy = 0.4123 ± 0.0156
JKNet_2_Pubmed: Accuracy = 0.4428 ± 0.0403
JKNet_8_Pubmed: Accuracy = 0.4125 ± 0.0169
JKNet_32_Pubmed: Accuracy = 0.4201 ± 0.0162
resGCN_2_Pubmed: Accuracy = 0.6278 ± 0.1441
resGCN_8_Pubmed: Accuracy = 0.3405 ± 0.1525
resGCN_32_Pubmed: Accuracy = 0.3317 ± 0.1429
GINConv_2_Pubmed: Accuracy = 0.6265 ± 0.0371
GINConv_8_Pubmed: Accuracy = 0.3458 ± 0.1136
GINConv_32_Pubmed: Accuracy = 0.3987 ± 0.0250
mlp_2_Pubmed: Accuracy = 0.7103 ± 0.0036
mlp_8_Pubmed: Accuracy = 0.4220 ± 0.0164
mlp_32_Pubmed: Accuracy = 0.4220 ± 0.0162
